{"prompt": ["I have a shell script in which I need to check whether two files contain the same data or not. I do this a for a lot of files, and in my script the diff command seems to be the performance bottleneck.Here's the line:diff -q $dst $new > /dev/null\n\nif ($status) then ...\nCould there be a faster way to compare the files, maybe a custom algorithm instead of the default diff?", "I have a shell script in which I need to check whether two files contain the same data or not. I do this a for a lot of files, and in my script the diff command seems to be the performance bottleneck.Here's the line:diff -q $dst $new > /dev/null\n\nif ($status) then ...\nCould there be a faster way to compare the files, maybe a custom algorithm instead of the default diff?", "I have a shell script in which I need to check whether two files contain the same data or not. I do this a for a lot of files, and in my script the diff command seems to be the performance bottleneck.Here's the line:diff -q $dst $new > /dev/null\n\nif ($status) then ...\nCould there be a faster way to compare the files, maybe a custom algorithm instead of the default diff?", "I have a shell script in which I need to check whether two files contain the same data or not. I do this a for a lot of files, and in my script the diff command seems to be the performance bottleneck.Here's the line:diff -q $dst $new > /dev/null\n\nif ($status) then ...\nCould there be a faster way to compare the files, maybe a custom algorithm instead of the default diff?", "I have a shell script in which I need to check whether two files contain the same data or not. I do this a for a lot of files, and in my script the diff command seems to be the performance bottleneck.Here's the line:diff -q $dst $new > /dev/null\n\nif ($status) then ...\nCould there be a faster way to compare the files, maybe a custom algorithm instead of the default diff?", "I have a shell script in which I need to check whether two files contain the same data or not. I do this a for a lot of files, and in my script the diff command seems to be the performance bottleneck.Here's the line:diff -q $dst $new > /dev/null\n\nif ($status) then ...\nCould there be a faster way to compare the files, maybe a custom algorithm instead of the default diff?", "I have a shell script in which I need to check whether two files contain the same data or not. I do this a for a lot of files, and in my script the diff command seems to be the performance bottleneck.Here's the line:diff -q $dst $new > /dev/null\n\nif ($status) then ...\nCould there be a faster way to compare the files, maybe a custom algorithm instead of the default diff?", "I have a shell script in which I need to check whether two files contain the same data or not. I do this a for a lot of files, and in my script the diff command seems to be the performance bottleneck.Here's the line:diff -q $dst $new > /dev/null\n\nif ($status) then ...\nCould there be a faster way to compare the files, maybe a custom algorithm instead of the default diff?", "I have a shell script in which I need to check whether two files contain the same data or not. I do this a for a lot of files, and in my script the diff command seems to be the performance bottleneck.Here's the line:diff -q $dst $new > /dev/null\n\nif ($status) then ...\nCould there be a faster way to compare the files, maybe a custom algorithm instead of the default diff?", "I have this code , how to improve itdiff  -b -i -w  out.txt out2.txt  \n | grep '^>' \n | sed 's/^>//g' \n | sed ':a;N;$!ba;s/\\n/ /g' \nexample data (out.txt)abc def ghk\nabc def2 ghk\nabc def ghk\n\n123 333 555\n566 3423 23\n566 3423 3542\nexample data (out2.txt)abc def2 ghk\nabc def ghk\nabc def ghk\n\n123 555 555\nfsdjhfsda sd\n566 3423 3542\nexpected result :abc def ghk  123 555 555  fsdjhfsda sd\n", "I have this code , how to improve itdiff  -b -i -w  out.txt out2.txt  \n | grep '^>' \n | sed 's/^>//g' \n | sed ':a;N;$!ba;s/\\n/ /g' \nexample data (out.txt)abc def ghk\nabc def2 ghk\nabc def ghk\n\n123 333 555\n566 3423 23\n566 3423 3542\nexample data (out2.txt)abc def2 ghk\nabc def ghk\nabc def ghk\n\n123 555 555\nfsdjhfsda sd\n566 3423 3542\nexpected result :abc def ghk  123 555 555  fsdjhfsda sd\n", "I have this code , how to improve itdiff  -b -i -w  out.txt out2.txt  \n | grep '^>' \n | sed 's/^>//g' \n | sed ':a;N;$!ba;s/\\n/ /g' \nexample data (out.txt)abc def ghk\nabc def2 ghk\nabc def ghk\n\n123 333 555\n566 3423 23\n566 3423 3542\nexample data (out2.txt)abc def2 ghk\nabc def ghk\nabc def ghk\n\n123 555 555\nfsdjhfsda sd\n566 3423 3542\nexpected result :abc def ghk  123 555 555  fsdjhfsda sd\n", "I have a large file A (consisting of emails), one line for each mail. I also have another file B that contains another set of mails.Which command would I use to remove all the addresses that appear in file B from the file A.So, if file A contained:A\nB\nC\nand file B contained:B    \nD\nE\nThen file A should be left with:A\nC\nNow I know this is a question that might have been asked more often, but I only found one command online that gave me an error with a bad delimiter.Any help would be much appreciated! Somebody will surely come up with a clever one-liner, but I'm not the shell expert.", "I have a large file A (consisting of emails), one line for each mail. I also have another file B that contains another set of mails.Which command would I use to remove all the addresses that appear in file B from the file A.So, if file A contained:A\nB\nC\nand file B contained:B    \nD\nE\nThen file A should be left with:A\nC\nNow I know this is a question that might have been asked more often, but I only found one command online that gave me an error with a bad delimiter.Any help would be much appreciated! Somebody will surely come up with a clever one-liner, but I'm not the shell expert.", "I have a large file A (consisting of emails), one line for each mail. I also have another file B that contains another set of mails.Which command would I use to remove all the addresses that appear in file B from the file A.So, if file A contained:A\nB\nC\nand file B contained:B    \nD\nE\nThen file A should be left with:A\nC\nNow I know this is a question that might have been asked more often, but I only found one command online that gave me an error with a bad delimiter.Any help would be much appreciated! Somebody will surely come up with a clever one-liner, but I'm not the shell expert.", "I have a large file A (consisting of emails), one line for each mail. I also have another file B that contains another set of mails.Which command would I use to remove all the addresses that appear in file B from the file A.So, if file A contained:A\nB\nC\nand file B contained:B    \nD\nE\nThen file A should be left with:A\nC\nNow I know this is a question that might have been asked more often, but I only found one command online that gave me an error with a bad delimiter.Any help would be much appreciated! Somebody will surely come up with a clever one-liner, but I'm not the shell expert.", "I have a large file A (consisting of emails), one line for each mail. I also have another file B that contains another set of mails.Which command would I use to remove all the addresses that appear in file B from the file A.So, if file A contained:A\nB\nC\nand file B contained:B    \nD\nE\nThen file A should be left with:A\nC\nNow I know this is a question that might have been asked more often, but I only found one command online that gave me an error with a bad delimiter.Any help would be much appreciated! Somebody will surely come up with a clever one-liner, but I'm not the shell expert.", "I have a large file A (consisting of emails), one line for each mail. I also have another file B that contains another set of mails.Which command would I use to remove all the addresses that appear in file B from the file A.So, if file A contained:A\nB\nC\nand file B contained:B    \nD\nE\nThen file A should be left with:A\nC\nNow I know this is a question that might have been asked more often, but I only found one command online that gave me an error with a bad delimiter.Any help would be much appreciated! Somebody will surely come up with a clever one-liner, but I'm not the shell expert.", "I have a large file A (consisting of emails), one line for each mail. I also have another file B that contains another set of mails.Which command would I use to remove all the addresses that appear in file B from the file A.So, if file A contained:A\nB\nC\nand file B contained:B    \nD\nE\nThen file A should be left with:A\nC\nNow I know this is a question that might have been asked more often, but I only found one command online that gave me an error with a bad delimiter.Any help would be much appreciated! Somebody will surely come up with a clever one-liner, but I'm not the shell expert.", "I have a large file A (consisting of emails), one line for each mail. I also have another file B that contains another set of mails.Which command would I use to remove all the addresses that appear in file B from the file A.So, if file A contained:A\nB\nC\nand file B contained:B    \nD\nE\nThen file A should be left with:A\nC\nNow I know this is a question that might have been asked more often, but I only found one command online that gave me an error with a bad delimiter.Any help would be much appreciated! Somebody will surely come up with a clever one-liner, but I'm not the shell expert.", "I have a large file A (consisting of emails), one line for each mail. I also have another file B that contains another set of mails.Which command would I use to remove all the addresses that appear in file B from the file A.So, if file A contained:A\nB\nC\nand file B contained:B    \nD\nE\nThen file A should be left with:A\nC\nNow I know this is a question that might have been asked more often, but I only found one command online that gave me an error with a bad delimiter.Any help would be much appreciated! Somebody will surely come up with a clever one-liner, but I'm not the shell expert.", "I have a large file A (consisting of emails), one line for each mail. I also have another file B that contains another set of mails.Which command would I use to remove all the addresses that appear in file B from the file A.So, if file A contained:A\nB\nC\nand file B contained:B    \nD\nE\nThen file A should be left with:A\nC\nNow I know this is a question that might have been asked more often, but I only found one command online that gave me an error with a bad delimiter.Any help would be much appreciated! Somebody will surely come up with a clever one-liner, but I'm not the shell expert.", "I have a large file A (consisting of emails), one line for each mail. I also have another file B that contains another set of mails.Which command would I use to remove all the addresses that appear in file B from the file A.So, if file A contained:A\nB\nC\nand file B contained:B    \nD\nE\nThen file A should be left with:A\nC\nNow I know this is a question that might have been asked more often, but I only found one command online that gave me an error with a bad delimiter.Any help would be much appreciated! Somebody will surely come up with a clever one-liner, but I'm not the shell expert.", "I'm comparing two files using sdiff to get side by side difference but I want the difference to be color highlighted.\nEx:\nFile A:\nHello There! General Kenobi!\nMagicFile B:\nHello World! Hola\nMagicNow the output from sdiff will be:\nHello There! General Kenobi! | Hello World! HolaI want the diff highlighted like (couldn't color code so, bold and italics)\nHello There! General Kenobi! | Hello World! HolaI can't use GUI based or colordiff command etc.\nI tried using sed and last option is to pipe the sdiff output through a script, but I'm thinking there might be a better way.", "Is there any way to perform diff operetion on two files in two zips without extracting them? If not - any other workaround to compare them without extracting? Thanks.", "Is there any way to perform diff operetion on two files in two zips without extracting them? If not - any other workaround to compare them without extracting? Thanks.", "Is there any way to perform diff operetion on two files in two zips without extracting them? If not - any other workaround to compare them without extracting? Thanks.", "Is there any way to perform diff operetion on two files in two zips without extracting them? If not - any other workaround to compare them without extracting? Thanks.", "Is there any way to perform diff operetion on two files in two zips without extracting them? If not - any other workaround to compare them without extracting? Thanks.", "Is there any way to perform diff operetion on two files in two zips without extracting them? If not - any other workaround to compare them without extracting? Thanks.", "Is there any way to perform diff operetion on two files in two zips without extracting them? If not - any other workaround to compare them without extracting? Thanks.", "Is there any way to perform diff operetion on two files in two zips without extracting them? If not - any other workaround to compare them without extracting? Thanks.", "Is there any way to perform diff operetion on two files in two zips without extracting them? If not - any other workaround to compare them without extracting? Thanks.", "I'm working on a bash script, with the main objective is to create a .conf file, in which the content is the subtraction of file 2 from file 1.\n\nExample : \nFile 1ready   serv1   FBgn001bKJ\nready   serv2   FBgn003mLo  \nready   serv3   FBgn002lPx  \nready   serv4   FBgn000Pas  \nFile 2ready   serv1   FBgn001bKJ\nready   serv4   FBgn000Pas\nResultready   serv2   FBgn003mLo  \nready   serv3   FBgn002lPx\nI've tried to use this function but it doesn't give any result :COMPARE_FILES() {\nawk '\n    NR==FNR {a[FNR]=$0; next}\n    {\n        b=$0; gsub(/[0-9]+/,\"\",b)\n        c=a[FNR]; gsub(/[0-9]+/,\"\",c)\n        if (b != c) {printf \"< %s\\n> %s\\n\", $0, a[FNR]}\n    }' \"$1\" \"$2\"\n}\nAny suggestion of how i can make it work !\nPS : The whitespace between the two files can be different!", "I'm working on a bash script, with the main objective is to create a .conf file, in which the content is the subtraction of file 2 from file 1.\n\nExample : \nFile 1ready   serv1   FBgn001bKJ\nready   serv2   FBgn003mLo  \nready   serv3   FBgn002lPx  \nready   serv4   FBgn000Pas  \nFile 2ready   serv1   FBgn001bKJ\nready   serv4   FBgn000Pas\nResultready   serv2   FBgn003mLo  \nready   serv3   FBgn002lPx\nI've tried to use this function but it doesn't give any result :COMPARE_FILES() {\nawk '\n    NR==FNR {a[FNR]=$0; next}\n    {\n        b=$0; gsub(/[0-9]+/,\"\",b)\n        c=a[FNR]; gsub(/[0-9]+/,\"\",c)\n        if (b != c) {printf \"< %s\\n> %s\\n\", $0, a[FNR]}\n    }' \"$1\" \"$2\"\n}\nAny suggestion of how i can make it work !\nPS : The whitespace between the two files can be different!", "I have two files which contain similar data but in different formats (JSON/TXT).file-A.json        {\n        \"Name\": \"www.mydomain.com.\",\n        \"Type\": \"A\",\n        \"TTL\": 600,\n        \"ResourceRecords\": [\n            {\n                \"Value\": \"8.8.8.8\"\n            }\n        ]\n    },\n    {\n        \"Name\": \"other.domain.com.\",\n        \"Type\": \"NS\",\n        \"TTL\": 1800,\n        \"ResourceRecords\": [\n            {\n                \"Value\": \"123.reg.\"\n            }\n        ]\n    }\n]\n}file-B.txtwww.mydomain.com 600 IN A 8.8.8.8\nother.domain.com 1800 IN NS 123.reg.\nI'm trying to figure out the best method to diff both files so i can see if those records exist/match. However, as they are in different formats i'm not sure this is possible, so my idea was to parse both files to have an identical format then run diff on them but i don't know how to even start.I've been able to parse the json using jq to obtain specific recordscat file-B.json | jq '.ResourceRecordSets[] | {\"Name\": .Name,\"ResourceRecords\": .[]}' \nbut starting to think this is not even the best approach.", "I am using an alpine 3.11 to build my image, everything goes well during the build the dockefile is here below :FROM alpine:3.11\nLABEL version=\"1.0\"\nARG UID=\"110\"\n\nARG PYTHON_VERSION=\"3.8.10-r0\"\nARG ANSIBLE_VERSION=\"5.0.1\"\nARG AWSCLI_VERSION=\"1.22.56\"\n  \n  # Create jenkins user with sudo privileges\nRUN adduser -u ${UID} -D -h /home/jenkins/ jenkins\nRUN echo 'jenkins ALL=(ALL) NOPASSWD:ALL' >> /etc/sudoers\nRUN mkdir -p /tmp/.ansible\nRUN chown -R jenkins:jenkins /tmp/.ansible\n  \n  # Install minimal packages\nRUN apk --update --no-cache add bash bind-tools curl gcc git libffi-dev libpq make mysql-client openssl postgresql-client sudo unzip wget coreutils\n  #RUN apk --update --no-cache add py-mysqldb\nRUN apk --update --no-cache add python3=${PYTHON_VERSION} python3-dev py3-pip py3-cryptography\n  \n  # Install JQ from sources\nRUN wget https://github.com/stedolan/jq/releases/download/jq-1.5/jq-linux64\nRUN mv jq-linux64 /usr/bin/jq\nRUN chmod +x /usr/bin/jq\n  # Install ansible and awscli with python package manager\nRUN pip3 install --upgrade pip\nRUN pip3 install yq --ignore-installed PyYAML\nRUN pip3 install ansible==${ANSIBLE_VERSION}\nRUN pip3 install awscli==${AWSCLI_VERSION} boto boto3 botocore s3cmd pywinrm pymysql 'python-dateutil<2.8.1'\n  # Clean cache\nRUN rm -rf /var/cache/apk/*\n  # Display packages versions\nRUN python3 --version && \\\npip3 --version && \\\nansible --version && \\\naws --version\nthis image is later used to lunch some jenkins jobs nothing unusual.But when i try to use the diff command in of these jobs I have the following error :diff: unrecognized option: c  BusyBox v1.31.1 () multi-call binary\nthat's why i tried to install the coreutils package but still the \"-c\" option is still unrecognized which is weird.So my question is there a way to add the -c option for the diff command because in the manual of GNU this should be available automatically but apparently not on Alpine ? if there is a way could anyone please share it.P.S : In case you are wondering why am I using the diff command it is just to compare two json files and the -c is necessary for me in this context."], "chosen": ["\nI like @Alex Howansky have used 'cmp --silent' for this.  But I need both positive and negative response so I use:\ncmp --silent file1 file2 && echo '### SUCCESS: Files Are Identical! ###' || echo '### WARNING: Files Are Different! ###'\n\nI can then run this in the terminal or with a ssh to check files against a constant file.\n", "\nI believe cmp will stop at the first byte difference:\ncmp --silent $old $new || echo \"files are different\"\n\n", "\nTo quickly and safely compare any two files:\nif cmp --silent -- \"$FILE1\" \"$FILE2\"; then\n  echo \"files contents are identical\"\nelse\n  echo \"files differ\"\nfi\n\nIt's readable, efficient, and works for any file names including \"` $()\n", "\nBecause I suck and don't have enough reputation points I can't add this tidbit in as a comment.\nBut, if you are going to use the cmp command (and don't need/want to be verbose) you can just grab the exit status. Per the cmp man page:\n\nIf  a FILE is '-' or missing, read standard input.  Exit status is 0\nif inputs are the same, 1 if different, 2 if trouble.\n\nSo, you could do something like:\nSTATUS=\"$(cmp --silent $FILE1 $FILE2; echo $?)\"  # \"$?\" gives exit status for each comparison\n\nif [[ $STATUS -ne 0 ]]; then  # if status isn't equal to 0, then execute code\n    DO A COMMAND ON $FILE1\nelse\n    DO SOMETHING ELSE\nfi\n\nEDIT: Thanks for the comments everyone! I updated the test syntax here. However, I would suggest you use Vasili's answer if you are looking for something similar to this answer in readability, style, and syntax.\n", "\nYou can compare by checksum algorithm like sha256\nsha256sum oldFile > oldFile.sha256\n\necho \"$(cat oldFile.sha256) newFile\" | sha256sum --check\n\nnewFile: OK\n\nif the files are distinct the result will be\nnewFile: FAILED\nsha256sum: WARNING: 1 computed checksum did NOT match\n\n", "\nFor files that are not different, any method will require having read both files entirely, even if the read was in the past.\nThere is no alternative.  So creating hashes or checksums at some point in time requires reading the whole file. Big files take time.\nFile metadata retrieval is much faster than reading a large file.\nSo, is there any file metadata you can use to establish that the files are different?\nFile size ?  or even results of the file command which does just read a small portion of the file?\nFile size example code fragment:\n  ls -l $1 $2 | \n  awk 'NR==1{a=$5} NR==2{b=$5} \n       END{val=(a==b)?0 :1; exit( val) }'\n       \n[ $? -eq 0 ] && echo 'same' || echo 'different'  \n\nIf the files are the same size then you are stuck with full file reads.\n", "\nTry also to use the cksum command:\nchk1=`cksum <file1> | awk -F\" \" '{print $1}'`\nchk2=`cksum <file2> | awk -F\" \" '{print $1}'`\n\nif [ $chk1 -eq $chk2 ]\nthen\n  echo \"File is identical\"\nelse\n  echo \"File is not identical\"\nfi\n\nThe cksum command will output the byte count of a file. See 'man cksum'.\n", "\nDoing some testing with a Raspberry Pi 3B+ (I'm using an overlay file system, and need to sync periodically), I ran a comparison of my own for diff -q and cmp -s; note that this is a log from inside /dev/shm, so disk access speeds are a non-issue:\n[root@mypi shm]# dd if=/dev/urandom of=test.file bs=1M count=100 ; time diff -q test.file test.copy && echo diff true || echo diff false ; time cmp -s test.file test.copy && echo cmp true || echo cmp false ; cp -a test.file test.copy ; time diff -q test.file test.copy && echo diff true || echo diff false; time cmp -s test.file test.copy && echo cmp true || echo cmp false\n100+0 records in\n100+0 records out\n104857600 bytes (105 MB) copied, 6.2564 s, 16.8 MB/s\nFiles test.file and test.copy differ\n\nreal    0m0.008s\nuser    0m0.008s\nsys     0m0.000s\ndiff false\n\nreal    0m0.009s\nuser    0m0.007s\nsys     0m0.001s\ncmp false\ncp: overwrite \u00e2test.copy\u00e2? y\n\nreal    0m0.966s\nuser    0m0.447s\nsys     0m0.518s\ndiff true\n\nreal    0m0.785s\nuser    0m0.211s\nsys     0m0.573s\ncmp true\n[root@mypi shm]# pico /root/rwbscripts/utils/squish.sh\n\nI ran it a couple of times.  cmp -s consistently had slightly shorter times on the test box I was using.  So if you want to use cmp -s to do things between two files....\nidentical (){\n  echo \"$1\" and \"$2\" are the same.\n  echo This is a function, you can put whatever you want in here.\n}\ndifferent () {\n  echo \"$1\" and \"$2\" are different.\n  echo This is a function, you can put whatever you want in here, too.\n}\ncmp -s \"$FILEA\" \"$FILEB\" && identical \"$FILEA\" \"$FILEB\" || different \"$FILEA\" \"$FILEB\"\n\n", "\nIf you are looking for more customizable diff for this, then git diff can be used.\nif (git diff --no-index --quiet old.txt new.txt) then\n  echo \"files contents are identical\"\nelse\n  echo \"files differ\"\nfi\n\n\n--quiet\nDisable all output of the program. Implies --exit-code.\n\n\n--exit-code\nMake the program exit with codes similar to diff(1). That is, it exits with 1 if there were differences and 0 means no differences.\n\n\nAlso, there are various algorithms and settings to choose from: [ref]\n\n--diff-algorithm={patience|minimal|histogram|myers}\nChoose a diff algorithm. The variants are as follows:\ndefault, myers The basic greedy diff algorithm. Currently, this is the\ndefault.\nminimal Spend extra time to make sure the smallest possible diff is\nproduced.\npatience Use \"patience diff\" algorithm when generating patches.\nhistogram This algorithm extends the patience algorithm to \"support\nlow-occurrence common elements\".\n\n", "\nHere's one simple way:\necho `diff -biw out.txt out2.txt | sed -n 's/^> //p'`\n\nIf you want to use use grep alone -- and if you can take advantage of GNU grep's formatting features -- you could use this:\ndiff --unchanged-group-format= --changed-group-format=%\\> \\\n  --new-line-format='%l ' -biw out.txt out2.txt\n\nwhich is probably the fastest method, and it doesn't require a large memory buffer when your files are big. (Both your original sed solution and the echo solution would keep lines in memory until the end, but this will spit them out as it goes.) The command itself is pretty verbose, though. Note also that it leaves one extra space at the end of the output.\n", "\nLooks like comm + tr is similar:\ncomm --nocheck-order -13 out.txt out2.txt | tr '\\n' ' '\n\nAlso you can put all sed and grep into one sed:\ndiff  -b -i -w out.txt out2.txt | sed '/^>/!{d};:a;N;$!ba;s/\\n>/ /g;s/^>//'\n\n\n $ diff  -b -i -w  out.txt out2.txt | grep '^>' | sed 's/^>//g' | sed ':a;N;$!ba;s/\\n/ /g'\n123 555 555  fsdjhfsda sd  566 3423 3542\n $ diff  -b -i -w out.txt out2.txt | sed '/^>/!{d};:a;N;$!ba;s/\\n>/  /g;s/^>//'\n123 555 555   fsdjhfsda sd   566 3423 3542\n $ comm --nocheck-order -13 out.txt out2.txt | tr '\\n' '  '\n123 555 555 fsdjhfsda sd 566 3423 3542 \n\n", "\nThis might work for you:\ndiff  -b -i -w out.txt out2.txt | sed '/^>/H;$!d;g;s/\\n>/ /g;s/^ *//'\n\n", "\ngrep -Fvxf <lines-to-remove> <all-lines>\n\nworks on non-sorted files (unlike comm)\nmaintains the order\nis POSIX\n\nExample:\ncat <<EOF > A\nb\n1\na\n0\n01\nb\n1\nEOF\n\ncat <<EOF > B\n0\n1\nEOF\n\ngrep -Fvxf B A\n\nOutput:\nb\na\n01\nb\n\nExplanation:\n\n-F: use literal strings instead of the default BRE\n-x: only consider matches that match the entire line\n-v: print non-matching\n-f file: take patterns from the given file\n\nThis method is slower on pre-sorted files than other methods, since it is more general. If speed matters as well, see: Fast way of finding lines in one file that are not in another?\nHere's a quick bash automation for in-line operation:\nremove-lines() (\n  remove_lines=\"$1\"\n  all_lines=\"$2\"\n  tmp_file=\"$(mktemp)\"\n  grep -Fvxf \"$remove_lines\" \"$all_lines\" > \"$tmp_file\"\n  mv \"$tmp_file\" \"$all_lines\"\n)\n\nGitHub upstream.\nusage:\nremove-lines lines-to-remove remove-from-this-file\n\nSee also: https://unix.stackexchange.com/questions/28158/is-there-a-tool-to-get-the-lines-in-one-file-that-are-not-in-another\n", "\nIf the files are sorted (they are in your example):\ncomm -23 file1 file2\n\n-23 suppresses the lines that are in both files, or only in file 2. If the files are not sorted, pipe them through sort first...\nSee the man page here\n", "\nawk to the rescue!\nThis solution doesn't require sorted inputs.  You have to provide fileB first.\nawk 'NR==FNR{a[$0];next} !($0 in a)' fileB fileA\n\nreturns\nA\nC\n\nHow does it work?\n\nNR==FNR{a[$0];next} idiom is for storing the first file in an associative array as keys for a later \"contains\" test.\nNR==FNR is checking whether we're scanning the first file, where the global line counter (NR) equals to the current file line counter (FNR).\na[$0] adds the current line to the associative array as key, note that this behaves like a set, where there won't be any duplicate values (keys)\n!($0 in a) we're now in the next file(s),  in is a contains test, here it's checking whether current line is in the set we populated in the first step from the first file, ! negates the condition.  What is missing here is the action, which by default is {print} and usually not written explicitly.\n\nNote that this can now be used to remove blacklisted words.\n$ awk '...' badwords allwords > goodwords\n\nwith a slight change it can clean multiple lists and create cleaned versions.\n$ awk 'NR==FNR{a[$0];next} !($0 in a){print > FILENAME\".clean\"}' bad file1 file2 file3 ...\n\n", "\nAnother way to do the same thing (also requires sorted input):\njoin -v 1 fileA fileB\n\nIn Bash, if the files are not pre-sorted:\njoin -v 1 <(sort fileA) <(sort fileB)\n\n", "\nYou can do this unless your files are sorted\ndiff file-a file-b --new-line-format=\"\" --old-line-format=\"%L\" --unchanged-line-format=\"\" > file-a\n\n--new-line-format is for lines that are in file b but not in a\n--old-.. is for lines that are in file a but not in b\n--unchanged-.. is for lines that are in both. \n%L makes it so the line is printed exactly.\nman diff\n\nfor more details\n", "\nThis refinement of @karakfa's nice answer may be noticeably faster for very large files. As with that answer, neither file need be sorted, but speed is assured by virtue of awk's associative arrays.  Only the lookup file is held in memory.\nThis formulation also allows for the possibility that only one particular field ($N) in the input file is to be used in the comparison.\n# Print lines in the input unless the value in column $N\n# appears in a lookup file, $LOOKUP;\n# if $N is 0, then the entire line is used for comparison.\n\nawk -v N=$N -v lookup=\"$LOOKUP\" '\n  BEGIN { while ( getline < lookup ) { dictionary[$0]=$0 } }\n  !($N in dictionary) {print}'\n\n(Another advantage of this approach is that it is easy to modify the comparison criterion, e.g. to trim leading and trailing white space.)\n", "\nYou can use Python:\npython -c '\nlines_to_remove = set()\nwith open(\"file B\", \"r\") as f:\n    for line in f.readlines():\n        lines_to_remove.add(line.strip())\n\nwith open(\"file A\", \"r\") as f:\n    for line in [line.strip() for line in f.readlines()]:\n        if line not in lines_to_remove:\n            print(line)\n'\n\n", "\nYou can use - \ndiff fileA fileB | grep \"^>\" | cut -c3- > fileA\nThis will work for files that are not sorted as well.\n", "\nJust to add to the Python answer to the user above, here is a faster solution:\n    python -c '\nlines_to_remove = None\nwith open(\"partial file\") as f:\n    lines_to_remove = {line.rstrip() for line in f.readlines()}\n\nremaining_lines = None\nwith open(\"full file\") as f:\n    remaining_lines = {line.rstrip() for line in f.readlines()} - lines_to_remove\n\nwith open(\"output file\", \"w\") as f:\n    for line in remaining_lines:\n        f.write(line + \"\\n\")\n    '\n\nRaising the power of set subtraction.\n", "\nTo get the file after removing the lines which appears on another file\ncomm -23 <(sort bigFile.txt) <(sort smallfile.txt) > diff.txt\n", "\nHere is a one liner that pipes the output of a website and removes the navigation elements using grep and lynx!  you can replace lynx with cat FileA and unwanted-elements.txt with FileB.\nlynx -dump -accept_all_cookies -nolist -width 1000 https://stackoverflow.com/ | grep -Fxvf unwanted-elements.txt\n\n", "\ncsdiff is a small wrapper script to colorize the output of sdiff.\nIt works well for colorizing the side-by-side diff, but it doesn't work with sdiff's interactive mode (-o).\nYou can also just use diff --color=always --side-by-side for similar results, or icdiff.\n", "\nCombining the responses so far, the following bash function will compare the file listings from the zip files. The listings include verbose output (unzip -v), so checksums can be compared. Output is sorted by filename (sort -k8) to allow side by side comparison and the diff output expanded (W200) so the filenames are visible in the side by side view.\nfunction zipdiff() { diff -W200 -y <(unzip -vql \"$1\" | sort -k8) <(unzip -vql \"$2\" | sort -k8); }\n\nThis can be added to your ~/.bashrc file to be used from any console. It can be used with zipdiff a.zip b.zip. Piping the output to less or redirecting to a file is helpful for large zip files.\n", "\nunzip -l will list the contents of a zip file. You can then pass that to diff in the normal manner as mentioned here: https://askubuntu.com/questions/229447/how-do-i-diff-the-output-of-two-commands\nSo for example if you had two zip files:\nfoo.zip\nbar.zip\n\nYou could run diff -y <(unzip -l foo.zip) <(unzip -l bar.zip) to do a side-by-side diff of the contents of the two files.\nHope that helps!\n", "\nCompressed File Contents Only\nTL;DR\nThe command to diff 2 zipfiles (a.zip and b.zip) is\ndiff \\\n  <(unzip -vqq a.zip  | awk '{$2=\"\"; $3=\"\"; $4=\"\"; $5=\"\"; $6=\"\"; print}' | sort -k3 -f) \\\n  <(unzip -vqq b.zip  | awk '{$2=\"\"; $3=\"\"; $4=\"\"; $5=\"\"; $6=\"\"; print}' | sort -k3 -f)\n\nExplanation\nI was looking for a way to compare the contents of the files stored in the zipfile, but not other metadata.  Consider the following:\n$ echo foo > foo.txt\n$ zip now.zip foo.txt\n  adding: foo.txt (stored 0%)\n$ zip later.zip foo.txt\n  adding: foo.txt (stored 0%)\n$ diff now.zip later.zip \nBinary files now.zip and later.zip differ\n\nConceptually, this makes no sense; I ran the same command on the same inputs and got 2 different outputs!  The difference is the metadata, which stores the date the file was added!\n$ unzip -v now.zip \nArchive:  now.zip\n Length   Method    Size  Cmpr    Date    Time   CRC-32   Name\n--------  ------  ------- ---- ---------- ----- --------  ----\n       4  Stored        4   0% 04-08-2020 23:27 7e3265a8  foo.txt\n--------          -------  ---                            -------\n       4                4   0%                            1 file\n$ unzip -v later.zip\nArchive:  later.zip\n Length   Method    Size  Cmpr    Date    Time   CRC-32   Name\n--------  ------  ------- ---- ---------- ----- --------  ----\n       4  Stored        4   0% 04-08-2020 23:28 7e3265a8  foo.txt\n--------          -------  ---                            -------\n       4                4   0%                            1 file\n\n\nNote: I manually edited the time of the second file here from 23:27 to 23:28 for clarity.  The field in the file itself stores the value of seconds (which, in my case, differed -- a binary diff would still fail) even though they are not represented in the command's output.\n\nSo to diff the files only, we must ignore the date fields.  unzip -vqq will get us a better summary:\n$ unzip -vqq now.zip\n       4  Stored        4   0% 04-08-2020 23:27 7e3265a8  foo.txt\n\nSo let's mask out the fields (we don't care about dates or compression metrics) and sort the files:\n$ unzip -vqq now.zip  | awk '{$2=\"\"; $3=\"\"; $4=\"\"; $5=\"\"; $6=\"\"; print}' | sort -k3 -f\n4      7e3265a8 foo.txt\n\n", "\nI wanted the actual diff between the files in the zips in a readable format. Here is a bash function that I wrote for this purpose which makes use of git. This has a good UX if you already use git as part of your normal workflow and can read git diffs.\n# usage: zipdiff before.zip after.zip\nfunction zipdiff {\n  current=$(pwd)\n  before=\"$current/$1\"\n  after=\"$current/$2\"\n  tempdir=$(mktemp -d)\n  cd \"$tempdir\"\n  git init &> /dev/null\n  unzip -qq \"$before\" *\n  git add . &> /dev/null\n  git commit -m \"before\" &> /dev/null\n  rm -rf \"$tempdir/*\"  \n  yes | unzip -qq \"$after\" * &> /dev/null\n  git add .\n  git diff --cached\n  cd \"$current\"\n  rm -rf \"$tempdir\"\n}\n\n\n", "\nIf you want to diff two files (as in see the difference) you have to extract them - even if only to memory!\nIn order to see the diff of two files in two zips you can do something like this (no error checking or whatsoever):\n# define a little bash function\nfunction zipdiff () { diff -u <(unzip -p $1 $2) <(unzip -p $3 $4); }\n\n# test it: create a.zip and b.zip, each with a different file.txt\necho hello >file.txt; zip a.zip file.txt\necho world >file.txt; zip b.zip file.txt\n\nzipdiff a.zip file.txt b.zip file.txt\n--- /dev/fd/63  2016-02-23 18:18:09.000000000 +0100\n+++ /dev/fd/62  2016-02-23 18:18:09.000000000 +0100\n@@ -1 +1 @@\n-hello\n+world\n\nNote: unzip -p extracts files to pipe (stdout).\nIf you only want to know if the files are different you can inspect their checksums using \nunzip -v -l zipfile [file_to_inspect]\n\nNote: -v means verbose and -llist contents)\nunzip -v -l a.zip \nArchive:  a.zip\n Length   Method    Size  Cmpr    Date    Time   CRC-32   Name\n--------  ------  ------- ---- ---------- ----- --------  ----\n       6  Stored        6   0% 2016-02-23 18:23 363a3020  file.txt\n--------          -------  ---                            -------\n       6                6   0%                            1 file\n\nunzip -v -l b.zip \nArchive:  b.zip\n Length   Method    Size  Cmpr    Date    Time   CRC-32   Name\n--------  ------  ------- ---- ---------- ----- --------  ----\n       6  Stored        6   0% 2016-02-23 18:23 dd3861a8  file.txt\n--------          -------  ---                            -------\n       6                6   0%                            1 file \n\nIn the example above you can see that the checksums (CRC-32) are different.\nYou might also be interested in this project: \nhttps://github.com/nhnb/zipdiff\n", "\nBy postprocessing the output of zipcmp, you can recurse through the archives to obtain a more detailed summary of the differences between them.\n#!/bin/bash\n\n# process zipcmp's output to do true diffs of archive contents\n# 1. grep removes the '+++' and '---' from zipcmp's output\n# 2. awk prints the final column of output\n# 3. sort | uniq to dedupe\nfor badfile in $(zipcmp ${1?No first zip} ${2?No second zip} \\\n    | grep -Ev '^[+-]{3}' \\\n    | awk '{print $NF}' \\\n    | sort | uniq);\ndo\n    echo \"diffing $badfile\"\n    diff <(unzip -p $1 $badfile) <(unzip -p $2 $badfile) ;\ndone;\n\n\n", "\nIf you need just to check if files are equal you can compare CRC32 checksums, which are stored in archive local header fields/central directory.\n", "\nThe comp_zip tool in the open-source library Zip-Ada (available here or here) performs a comparison without extraction: contents, files of a.zip missing in b.zip and integrity check of both.\n", "\nWeb-tools such as https://www.diffnow.com/compare-files offer a quite nice visual information which files in the zip have changed:\n\nThis works very convenient for not too big zip-files without the need to install anything. This works not only for Linux but also for other operating systems including Windows and Mac.\nThe tools discussed in the other answers offer obviously more advanced options and can be faster for larger zip files.\n", "\nWhy not a with simple grep?\ngrep -vxFf file2 file1\n\n\nupdate:\nHandling heterogeneous white spaces:\n#!/bin/bash\n\nnormalize_spaces() {\n    sed -e 's/^[[:space:]]\\+//' \\\n        -e 's/[[:space:]]\\+$//' \\\n        -e 's/[[:space:]]\\+/ /g' \\\n        -- \"$@\"\n}\n\ngrep -vxFf <(normalize_spaces file2) <(normalize_spaces file1)\n\n", "\nAssuming the files you are comparing are sorted, diff may also be an option:\n$ diff --unchanged-group-format=\"\" --new-group-format=\"%>\" f1.txt f2.txt \nready   serv2   FBgn003mLo   \nready   serv3   FBgn002lPx\n\n(I noted the extra white space in the OP's data as mentioned in the answer by @markp-fuso, but that did not affect my diff results)\n", "\nIn addtional to L\u00e9a's answer this also worked by converting the json to a similar zonefile\njq -jr '.ResourceRecordSets[] | \"\\(.Name) \\t\\(.TTL) \\t\\(.Type) \\t\\(.ResourceRecords[]?.Value)\\n\"' file-A.json\n\nwww.mydomain.com. 600 IN A 8.8.8.8\nother.domain.com. 1800 IN NS 123.reg.\n\nI could then export the output to a file and do a diff OR just pipe it directly to a diff as L\u00e9a demonstrated. We could also sort this if needed to get accurate diff but not sure it's needed.\n", "\nIn spite of it being required in the POSIX diff specification it looks like the BusyBox implementation of diff doesn't support the -c option.\nOne thing you could do is change your diff invocation to use unified context diff format.  Again, BusyBox diff appears to not support -u, so you need to use an explicit -U option with the number of lines of context\ndiff -U3 file.orig file.new\n\nIn general, the Alpine environment has many small differences like this.  If you're installing the GNU versions of these tools anyways \u2013 your Dockerfile already installs GNU bash and coreutils \u2013 you'll probably find minimal to no space savings from using an Alpine base image, and using a Debian or Ubuntu base that already includes the GNU versions of these tools will be easier.\nFROM ubuntu:20.04 # not Alpine\n...\nRUN apt-get update \\\n && DEBIAN_FRONTEND=noninteractive \\\n    apt-get install --no-install-recommends --assume-yes \\\n      bind9-utils \\\n      build-essential \\\n      curl \\\n      git-core \\\n      ...\n\nYou may need to search on https://packages.debian.org/ to find equivalent Debian packages.  build-essential is a metapackage that includes the entire C toolchain (gcc, make, et al.); bash, coreutils, and diffutils would typically be installed as part of the base distribution image.\n"], "rejected": ["\nYou could compare hashes, e.g. SHA-256 or MD5.\nsame-contents() {\n    echo \"$(sha256sum \"$1\" | sed 's/ .*//') $2\" | sha256sum --check 1>/dev/null 2>&1\n}\nalias same-file=\"same-contents\" # Technically the same \"file\" has the same inode\n\nif same-contents file1.txt file2.txt; then \n    echo true\nelse\n    echo false\nfi\n\nThat is essentially what was suggested in this answer, but they overcomplicate things by storing the hash in a file first. The sed call trims off the filename to leave only the hash.\nYou should likely still prefer cmp because it is purpose-built for this and can compare byte-by-byte, whereas hashing necessitates reading the entire files, but I thought this was an interesting script.\n", "\nYou could compare hashes, e.g. SHA-256 or MD5.\nsame-contents() {\n    echo \"$(sha256sum \"$1\" | sed 's/ .*//') $2\" | sha256sum --check 1>/dev/null 2>&1\n}\nalias same-file=\"same-contents\" # Technically the same \"file\" has the same inode\n\nif same-contents file1.txt file2.txt; then \n    echo true\nelse\n    echo false\nfi\n\nThat is essentially what was suggested in this answer, but they overcomplicate things by storing the hash in a file first. The sed call trims off the filename to leave only the hash.\nYou should likely still prefer cmp because it is purpose-built for this and can compare byte-by-byte, whereas hashing necessitates reading the entire files, but I thought this was an interesting script.\n", "\nYou could compare hashes, e.g. SHA-256 or MD5.\nsame-contents() {\n    echo \"$(sha256sum \"$1\" | sed 's/ .*//') $2\" | sha256sum --check 1>/dev/null 2>&1\n}\nalias same-file=\"same-contents\" # Technically the same \"file\" has the same inode\n\nif same-contents file1.txt file2.txt; then \n    echo true\nelse\n    echo false\nfi\n\nThat is essentially what was suggested in this answer, but they overcomplicate things by storing the hash in a file first. The sed call trims off the filename to leave only the hash.\nYou should likely still prefer cmp because it is purpose-built for this and can compare byte-by-byte, whereas hashing necessitates reading the entire files, but I thought this was an interesting script.\n", "\nYou could compare hashes, e.g. SHA-256 or MD5.\nsame-contents() {\n    echo \"$(sha256sum \"$1\" | sed 's/ .*//') $2\" | sha256sum --check 1>/dev/null 2>&1\n}\nalias same-file=\"same-contents\" # Technically the same \"file\" has the same inode\n\nif same-contents file1.txt file2.txt; then \n    echo true\nelse\n    echo false\nfi\n\nThat is essentially what was suggested in this answer, but they overcomplicate things by storing the hash in a file first. The sed call trims off the filename to leave only the hash.\nYou should likely still prefer cmp because it is purpose-built for this and can compare byte-by-byte, whereas hashing necessitates reading the entire files, but I thought this was an interesting script.\n", "\nYou could compare hashes, e.g. SHA-256 or MD5.\nsame-contents() {\n    echo \"$(sha256sum \"$1\" | sed 's/ .*//') $2\" | sha256sum --check 1>/dev/null 2>&1\n}\nalias same-file=\"same-contents\" # Technically the same \"file\" has the same inode\n\nif same-contents file1.txt file2.txt; then \n    echo true\nelse\n    echo false\nfi\n\nThat is essentially what was suggested in this answer, but they overcomplicate things by storing the hash in a file first. The sed call trims off the filename to leave only the hash.\nYou should likely still prefer cmp because it is purpose-built for this and can compare byte-by-byte, whereas hashing necessitates reading the entire files, but I thought this was an interesting script.\n", "\nYou could compare hashes, e.g. SHA-256 or MD5.\nsame-contents() {\n    echo \"$(sha256sum \"$1\" | sed 's/ .*//') $2\" | sha256sum --check 1>/dev/null 2>&1\n}\nalias same-file=\"same-contents\" # Technically the same \"file\" has the same inode\n\nif same-contents file1.txt file2.txt; then \n    echo true\nelse\n    echo false\nfi\n\nThat is essentially what was suggested in this answer, but they overcomplicate things by storing the hash in a file first. The sed call trims off the filename to leave only the hash.\nYou should likely still prefer cmp because it is purpose-built for this and can compare byte-by-byte, whereas hashing necessitates reading the entire files, but I thought this was an interesting script.\n", "\nYou could compare hashes, e.g. SHA-256 or MD5.\nsame-contents() {\n    echo \"$(sha256sum \"$1\" | sed 's/ .*//') $2\" | sha256sum --check 1>/dev/null 2>&1\n}\nalias same-file=\"same-contents\" # Technically the same \"file\" has the same inode\n\nif same-contents file1.txt file2.txt; then \n    echo true\nelse\n    echo false\nfi\n\nThat is essentially what was suggested in this answer, but they overcomplicate things by storing the hash in a file first. The sed call trims off the filename to leave only the hash.\nYou should likely still prefer cmp because it is purpose-built for this and can compare byte-by-byte, whereas hashing necessitates reading the entire files, but I thought this was an interesting script.\n", "\nYou could compare hashes, e.g. SHA-256 or MD5.\nsame-contents() {\n    echo \"$(sha256sum \"$1\" | sed 's/ .*//') $2\" | sha256sum --check 1>/dev/null 2>&1\n}\nalias same-file=\"same-contents\" # Technically the same \"file\" has the same inode\n\nif same-contents file1.txt file2.txt; then \n    echo true\nelse\n    echo false\nfi\n\nThat is essentially what was suggested in this answer, but they overcomplicate things by storing the hash in a file first. The sed call trims off the filename to leave only the hash.\nYou should likely still prefer cmp because it is purpose-built for this and can compare byte-by-byte, whereas hashing necessitates reading the entire files, but I thought this was an interesting script.\n", "\nYou could compare hashes, e.g. SHA-256 or MD5.\nsame-contents() {\n    echo \"$(sha256sum \"$1\" | sed 's/ .*//') $2\" | sha256sum --check 1>/dev/null 2>&1\n}\nalias same-file=\"same-contents\" # Technically the same \"file\" has the same inode\n\nif same-contents file1.txt file2.txt; then \n    echo true\nelse\n    echo false\nfi\n\nThat is essentially what was suggested in this answer, but they overcomplicate things by storing the hash in a file first. The sed call trims off the filename to leave only the hash.\nYou should likely still prefer cmp because it is purpose-built for this and can compare byte-by-byte, whereas hashing necessitates reading the entire files, but I thought this was an interesting script.\n", "\nuser@computer:~$ cat out.txt\nabc def ghk\nabc def2 ghk\nabc def ghk\n\n123 333 555\n566 3423 23\n566 3423 3542\n\nuser@computer:~$ cat out2.txt\nabc def2 ghk\nabc def ghk\nabc def ghk\n\n123 555 555\nfsdjhfsda sd\n566 3423 3542\n\nuser@computer:~$ diff out.txt out2.txt | grep '^>' | cut -d\" \" -f2-\nabc def ghk\n123 555 555\nfsdjhfsda sd\n\nUse grep '^<' to list identical lines.\nFor output on single line, pipe further to xargs\n... | xargs echo\n\n", "\nuser@computer:~$ cat out.txt\nabc def ghk\nabc def2 ghk\nabc def ghk\n\n123 333 555\n566 3423 23\n566 3423 3542\n\nuser@computer:~$ cat out2.txt\nabc def2 ghk\nabc def ghk\nabc def ghk\n\n123 555 555\nfsdjhfsda sd\n566 3423 3542\n\nuser@computer:~$ diff out.txt out2.txt | grep '^>' | cut -d\" \" -f2-\nabc def ghk\n123 555 555\nfsdjhfsda sd\n\nUse grep '^<' to list identical lines.\nFor output on single line, pipe further to xargs\n... | xargs echo\n\n", "\nuser@computer:~$ cat out.txt\nabc def ghk\nabc def2 ghk\nabc def ghk\n\n123 333 555\n566 3423 23\n566 3423 3542\n\nuser@computer:~$ cat out2.txt\nabc def2 ghk\nabc def ghk\nabc def ghk\n\n123 555 555\nfsdjhfsda sd\n566 3423 3542\n\nuser@computer:~$ diff out.txt out2.txt | grep '^>' | cut -d\" \" -f2-\nabc def ghk\n123 555 555\nfsdjhfsda sd\n\nUse grep '^<' to list identical lines.\nFor output on single line, pipe further to xargs\n... | xargs echo\n\n", "\nTo remove common lines between two files you can use grep, comm or join command.\n\ngrep only works for small files. Use -v along with -f.\n\ngrep -vf file2 file1 \n\nThis displays lines from file1 that do not match any line in file2.\n\ncomm is a utility command that works on lexically sorted files. It\n  takes two files as input and produces three text columns as output:\n  lines only in the first file; lines only in the second file; and lines\n  in both files. You can suppress printing of any column by using -1, -2\n  or -3 option accordingly.\n\ncomm -1 -3 file2 file1\n\nThis displays lines from file1 that do not match any line in file2.\n\nFinally, there is join, a utility command that performs an equality\n  join on the specified files. Its -v option also allows to remove\n  common lines between two files.\n\njoin -v1 -v2 file1 file2\n\n", "\nTo remove common lines between two files you can use grep, comm or join command.\n\ngrep only works for small files. Use -v along with -f.\n\ngrep -vf file2 file1 \n\nThis displays lines from file1 that do not match any line in file2.\n\ncomm is a utility command that works on lexically sorted files. It\n  takes two files as input and produces three text columns as output:\n  lines only in the first file; lines only in the second file; and lines\n  in both files. You can suppress printing of any column by using -1, -2\n  or -3 option accordingly.\n\ncomm -1 -3 file2 file1\n\nThis displays lines from file1 that do not match any line in file2.\n\nFinally, there is join, a utility command that performs an equality\n  join on the specified files. Its -v option also allows to remove\n  common lines between two files.\n\njoin -v1 -v2 file1 file2\n\n", "\nTo remove common lines between two files you can use grep, comm or join command.\n\ngrep only works for small files. Use -v along with -f.\n\ngrep -vf file2 file1 \n\nThis displays lines from file1 that do not match any line in file2.\n\ncomm is a utility command that works on lexically sorted files. It\n  takes two files as input and produces three text columns as output:\n  lines only in the first file; lines only in the second file; and lines\n  in both files. You can suppress printing of any column by using -1, -2\n  or -3 option accordingly.\n\ncomm -1 -3 file2 file1\n\nThis displays lines from file1 that do not match any line in file2.\n\nFinally, there is join, a utility command that performs an equality\n  join on the specified files. Its -v option also allows to remove\n  common lines between two files.\n\njoin -v1 -v2 file1 file2\n\n", "\nTo remove common lines between two files you can use grep, comm or join command.\n\ngrep only works for small files. Use -v along with -f.\n\ngrep -vf file2 file1 \n\nThis displays lines from file1 that do not match any line in file2.\n\ncomm is a utility command that works on lexically sorted files. It\n  takes two files as input and produces three text columns as output:\n  lines only in the first file; lines only in the second file; and lines\n  in both files. You can suppress printing of any column by using -1, -2\n  or -3 option accordingly.\n\ncomm -1 -3 file2 file1\n\nThis displays lines from file1 that do not match any line in file2.\n\nFinally, there is join, a utility command that performs an equality\n  join on the specified files. Its -v option also allows to remove\n  common lines between two files.\n\njoin -v1 -v2 file1 file2\n\n", "\nTo remove common lines between two files you can use grep, comm or join command.\n\ngrep only works for small files. Use -v along with -f.\n\ngrep -vf file2 file1 \n\nThis displays lines from file1 that do not match any line in file2.\n\ncomm is a utility command that works on lexically sorted files. It\n  takes two files as input and produces three text columns as output:\n  lines only in the first file; lines only in the second file; and lines\n  in both files. You can suppress printing of any column by using -1, -2\n  or -3 option accordingly.\n\ncomm -1 -3 file2 file1\n\nThis displays lines from file1 that do not match any line in file2.\n\nFinally, there is join, a utility command that performs an equality\n  join on the specified files. Its -v option also allows to remove\n  common lines between two files.\n\njoin -v1 -v2 file1 file2\n\n", "\nTo remove common lines between two files you can use grep, comm or join command.\n\ngrep only works for small files. Use -v along with -f.\n\ngrep -vf file2 file1 \n\nThis displays lines from file1 that do not match any line in file2.\n\ncomm is a utility command that works on lexically sorted files. It\n  takes two files as input and produces three text columns as output:\n  lines only in the first file; lines only in the second file; and lines\n  in both files. You can suppress printing of any column by using -1, -2\n  or -3 option accordingly.\n\ncomm -1 -3 file2 file1\n\nThis displays lines from file1 that do not match any line in file2.\n\nFinally, there is join, a utility command that performs an equality\n  join on the specified files. Its -v option also allows to remove\n  common lines between two files.\n\njoin -v1 -v2 file1 file2\n\n", "\nTo remove common lines between two files you can use grep, comm or join command.\n\ngrep only works for small files. Use -v along with -f.\n\ngrep -vf file2 file1 \n\nThis displays lines from file1 that do not match any line in file2.\n\ncomm is a utility command that works on lexically sorted files. It\n  takes two files as input and produces three text columns as output:\n  lines only in the first file; lines only in the second file; and lines\n  in both files. You can suppress printing of any column by using -1, -2\n  or -3 option accordingly.\n\ncomm -1 -3 file2 file1\n\nThis displays lines from file1 that do not match any line in file2.\n\nFinally, there is join, a utility command that performs an equality\n  join on the specified files. Its -v option also allows to remove\n  common lines between two files.\n\njoin -v1 -v2 file1 file2\n\n", "\nTo remove common lines between two files you can use grep, comm or join command.\n\ngrep only works for small files. Use -v along with -f.\n\ngrep -vf file2 file1 \n\nThis displays lines from file1 that do not match any line in file2.\n\ncomm is a utility command that works on lexically sorted files. It\n  takes two files as input and produces three text columns as output:\n  lines only in the first file; lines only in the second file; and lines\n  in both files. You can suppress printing of any column by using -1, -2\n  or -3 option accordingly.\n\ncomm -1 -3 file2 file1\n\nThis displays lines from file1 that do not match any line in file2.\n\nFinally, there is join, a utility command that performs an equality\n  join on the specified files. Its -v option also allows to remove\n  common lines between two files.\n\njoin -v1 -v2 file1 file2\n\n", "\nTo remove common lines between two files you can use grep, comm or join command.\n\ngrep only works for small files. Use -v along with -f.\n\ngrep -vf file2 file1 \n\nThis displays lines from file1 that do not match any line in file2.\n\ncomm is a utility command that works on lexically sorted files. It\n  takes two files as input and produces three text columns as output:\n  lines only in the first file; lines only in the second file; and lines\n  in both files. You can suppress printing of any column by using -1, -2\n  or -3 option accordingly.\n\ncomm -1 -3 file2 file1\n\nThis displays lines from file1 that do not match any line in file2.\n\nFinally, there is join, a utility command that performs an equality\n  join on the specified files. Its -v option also allows to remove\n  common lines between two files.\n\njoin -v1 -v2 file1 file2\n\n", "\nTo remove common lines between two files you can use grep, comm or join command.\n\ngrep only works for small files. Use -v along with -f.\n\ngrep -vf file2 file1 \n\nThis displays lines from file1 that do not match any line in file2.\n\ncomm is a utility command that works on lexically sorted files. It\n  takes two files as input and produces three text columns as output:\n  lines only in the first file; lines only in the second file; and lines\n  in both files. You can suppress printing of any column by using -1, -2\n  or -3 option accordingly.\n\ncomm -1 -3 file2 file1\n\nThis displays lines from file1 that do not match any line in file2.\n\nFinally, there is join, a utility command that performs an equality\n  join on the specified files. Its -v option also allows to remove\n  common lines between two files.\n\njoin -v1 -v2 file1 file2\n\n", "\nTo remove common lines between two files you can use grep, comm or join command.\n\ngrep only works for small files. Use -v along with -f.\n\ngrep -vf file2 file1 \n\nThis displays lines from file1 that do not match any line in file2.\n\ncomm is a utility command that works on lexically sorted files. It\n  takes two files as input and produces three text columns as output:\n  lines only in the first file; lines only in the second file; and lines\n  in both files. You can suppress printing of any column by using -1, -2\n  or -3 option accordingly.\n\ncomm -1 -3 file2 file1\n\nThis displays lines from file1 that do not match any line in file2.\n\nFinally, there is join, a utility command that performs an equality\n  join on the specified files. Its -v option also allows to remove\n  common lines between two files.\n\njoin -v1 -v2 file1 file2\n\n", "\nThe emacs command ediff-buffers produces colourised output. But you have to be using emacs :-)\n", "\nSome command line tools exists:\n\ndiffzips.pl written in Perl.\nzipdiff written in Java.\nzipdiff port to .NET of the previous one.\nzipcmp written in C, from libzip library\nzcmp and zdiff from gzip, can be used on zip files.\n\nI am an happy user of diffzips.pl to compare the content of epub files. diffzips.pl has also the advantage to be recursive, comparing zip file inside the parent zip.\n", "\nSome command line tools exists:\n\ndiffzips.pl written in Perl.\nzipdiff written in Java.\nzipdiff port to .NET of the previous one.\nzipcmp written in C, from libzip library\nzcmp and zdiff from gzip, can be used on zip files.\n\nI am an happy user of diffzips.pl to compare the content of epub files. diffzips.pl has also the advantage to be recursive, comparing zip file inside the parent zip.\n", "\nSome command line tools exists:\n\ndiffzips.pl written in Perl.\nzipdiff written in Java.\nzipdiff port to .NET of the previous one.\nzipcmp written in C, from libzip library\nzcmp and zdiff from gzip, can be used on zip files.\n\nI am an happy user of diffzips.pl to compare the content of epub files. diffzips.pl has also the advantage to be recursive, comparing zip file inside the parent zip.\n", "\nSome command line tools exists:\n\ndiffzips.pl written in Perl.\nzipdiff written in Java.\nzipdiff port to .NET of the previous one.\nzipcmp written in C, from libzip library\nzcmp and zdiff from gzip, can be used on zip files.\n\nI am an happy user of diffzips.pl to compare the content of epub files. diffzips.pl has also the advantage to be recursive, comparing zip file inside the parent zip.\n", "\nSome command line tools exists:\n\ndiffzips.pl written in Perl.\nzipdiff written in Java.\nzipdiff port to .NET of the previous one.\nzipcmp written in C, from libzip library\nzcmp and zdiff from gzip, can be used on zip files.\n\nI am an happy user of diffzips.pl to compare the content of epub files. diffzips.pl has also the advantage to be recursive, comparing zip file inside the parent zip.\n", "\nSome command line tools exists:\n\ndiffzips.pl written in Perl.\nzipdiff written in Java.\nzipdiff port to .NET of the previous one.\nzipcmp written in C, from libzip library\nzcmp and zdiff from gzip, can be used on zip files.\n\nI am an happy user of diffzips.pl to compare the content of epub files. diffzips.pl has also the advantage to be recursive, comparing zip file inside the parent zip.\n", "\nSome command line tools exists:\n\ndiffzips.pl written in Perl.\nzipdiff written in Java.\nzipdiff port to .NET of the previous one.\nzipcmp written in C, from libzip library\nzcmp and zdiff from gzip, can be used on zip files.\n\nI am an happy user of diffzips.pl to compare the content of epub files. diffzips.pl has also the advantage to be recursive, comparing zip file inside the parent zip.\n", "\nSome command line tools exists:\n\ndiffzips.pl written in Perl.\nzipdiff written in Java.\nzipdiff port to .NET of the previous one.\nzipcmp written in C, from libzip library\nzcmp and zdiff from gzip, can be used on zip files.\n\nI am an happy user of diffzips.pl to compare the content of epub files. diffzips.pl has also the advantage to be recursive, comparing zip file inside the parent zip.\n", "\nSome command line tools exists:\n\ndiffzips.pl written in Perl.\nzipdiff written in Java.\nzipdiff port to .NET of the previous one.\nzipcmp written in C, from libzip library\nzcmp and zdiff from gzip, can be used on zip files.\n\nI am an happy user of diffzips.pl to compare the content of epub files. diffzips.pl has also the advantage to be recursive, comparing zip file inside the parent zip.\n", "\nAssumptions:\n\neach line within a file is unique (ie, no duplicate lines exist within a given file)\nmatching lines are 100% identical (this actually isn't the case with OP's data as I found a variable number of trailing spaces in some lines; I manually removed all trailing spaces before running the following solutions)\n\nOne comm idea:\n$ comm -23 file1 file2\nready   serv2   FBgn003mLo\nready   serv3   FBgn002lPx\n\nNOTE: comm requires input files are already sorted (as per OP's sample)\nAs for an awk solution:\n$ awk 'FNR==NR {a[$0];next} !($0 in a)' file2 file1\nready   serv2   FBgn003mLo\nready   serv3   FBgn002lPx\n\nNOTE: the 1st file fed to awk is file2\n\nModifying to remove trailing white space:\n$ comm -23 <(sed 's/[[:space:]]*$//' file1) <(sed 's/[[:space:]]*$//' file2)\nready   serv2   FBgn003mLo\nready   serv3   FBgn002lPx\n\n$ awk '{sub(/[[:space:]]*$/,\"\")} FNR==NR {a[$0];next} !($0 in a)' file2 file1\nready   serv2   FBgn003mLo\nready   serv3   FBgn002lPx\n\n", "\nAssumptions:\n\neach line within a file is unique (ie, no duplicate lines exist within a given file)\nmatching lines are 100% identical (this actually isn't the case with OP's data as I found a variable number of trailing spaces in some lines; I manually removed all trailing spaces before running the following solutions)\n\nOne comm idea:\n$ comm -23 file1 file2\nready   serv2   FBgn003mLo\nready   serv3   FBgn002lPx\n\nNOTE: comm requires input files are already sorted (as per OP's sample)\nAs for an awk solution:\n$ awk 'FNR==NR {a[$0];next} !($0 in a)' file2 file1\nready   serv2   FBgn003mLo\nready   serv3   FBgn002lPx\n\nNOTE: the 1st file fed to awk is file2\n\nModifying to remove trailing white space:\n$ comm -23 <(sed 's/[[:space:]]*$//' file1) <(sed 's/[[:space:]]*$//' file2)\nready   serv2   FBgn003mLo\nready   serv3   FBgn002lPx\n\n$ awk '{sub(/[[:space:]]*$/,\"\")} FNR==NR {a[$0];next} !($0 in a)' file2 file1\nready   serv2   FBgn003mLo\nready   serv3   FBgn002lPx\n\n", "\nThe main approach is to get both data in the same format.\nSo lets convert the JSON file to the same format as that of the text file with the help of jq:\njq -r '\n# For all array entries\n.[] | \n  # Concatenates values to compose a flat DNS zone text file\n  .Name +\n  \" \" +\n  (.TTL|tostring) +\n  \" IN \" +\n  .Type +\n  \" \" +\n  .ResourceRecords[0].Value\n' \\\nfile-A.json |\n  diff - file-B.txt\n\n", "\nWell I just had to add the diffutils package to the list after installing it everything works well\n"]}