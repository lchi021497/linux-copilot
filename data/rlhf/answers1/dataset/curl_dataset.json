{"prompt": ["I hope all is well with you.I need a solution to a time-out problem when web scraping a URL.\nThe program is running in the cloud, at Hetzner.This effect can be simulated with the curl command below:curl https://www.fnde.gov.br/distribuicaosimadnet/confirmarCancelarFailure Message:curl https://www.fnde.gov.br/distribuicaosimadnet/confirmarCancelar\ncurl: (28) Failed to connect to www.fnde.gov.br port 443 after 131364 ms: Connection timed outThe curious thing is that this access works correctly in our local machine and in AWS, both on Linux.Another fact that draws attention is that the access below, via curl, can work on Hetzner:curl https://www.fnde.gov.br/distribuicaosimadnet/selecionar?numeroEntidade=000001406302&anoPrograma=2023&codigoPrograma=01&ufSeleciona=AC&criterios=The original application is written in Python, but I used curl as an alternative to simulate the problem.", "I use Arch Linux and this problem appears when trying to push on my rip \nerror: RPC failed; curl 56 OpenSSL SSL_read: error:140943FC:SSL routines:ssl3_read_bytes:sslv3 alert bad record mac, errno 0\nthis issue when writing\n\ngit push origin master \n\n\nCounting objects: 65, done.\nDelta compression using up to 4 threads.\nCompressing objects: 100% (56/56), done.\nWriting objects: 100% (65/65), 76.27 KiB | 1.00 MiB/s, done.\nTotal 65 (delta 32), reused 0 (delta 0)\nerror: RPC failed; curl 56 OpenSSL SSL_read: error:140943FC:SSL routines:ssl3_read_bytes:sslv3 alert bad record mac, errno 0\nfatal: The remote end hung up unexpectedly\nfatal: The remote end hung up unexpectedly\nEverything up-to-date\ni'm change my buffer size and upgrade git, curl, openssl but doesn't work .so any help pleas.", "I use Arch Linux and this problem appears when trying to push on my rip \nerror: RPC failed; curl 56 OpenSSL SSL_read: error:140943FC:SSL routines:ssl3_read_bytes:sslv3 alert bad record mac, errno 0\nthis issue when writing\n\ngit push origin master \n\n\nCounting objects: 65, done.\nDelta compression using up to 4 threads.\nCompressing objects: 100% (56/56), done.\nWriting objects: 100% (65/65), 76.27 KiB | 1.00 MiB/s, done.\nTotal 65 (delta 32), reused 0 (delta 0)\nerror: RPC failed; curl 56 OpenSSL SSL_read: error:140943FC:SSL routines:ssl3_read_bytes:sslv3 alert bad record mac, errno 0\nfatal: The remote end hung up unexpectedly\nfatal: The remote end hung up unexpectedly\nEverything up-to-date\ni'm change my buffer size and upgrade git, curl, openssl but doesn't work .so any help pleas.", "I use Arch Linux and this problem appears when trying to push on my rip \nerror: RPC failed; curl 56 OpenSSL SSL_read: error:140943FC:SSL routines:ssl3_read_bytes:sslv3 alert bad record mac, errno 0\nthis issue when writing\n\ngit push origin master \n\n\nCounting objects: 65, done.\nDelta compression using up to 4 threads.\nCompressing objects: 100% (56/56), done.\nWriting objects: 100% (65/65), 76.27 KiB | 1.00 MiB/s, done.\nTotal 65 (delta 32), reused 0 (delta 0)\nerror: RPC failed; curl 56 OpenSSL SSL_read: error:140943FC:SSL routines:ssl3_read_bytes:sslv3 alert bad record mac, errno 0\nfatal: The remote end hung up unexpectedly\nfatal: The remote end hung up unexpectedly\nEverything up-to-date\ni'm change my buffer size and upgrade git, curl, openssl but doesn't work .so any help pleas.", "I use Arch Linux and this problem appears when trying to push on my rip \nerror: RPC failed; curl 56 OpenSSL SSL_read: error:140943FC:SSL routines:ssl3_read_bytes:sslv3 alert bad record mac, errno 0\nthis issue when writing\n\ngit push origin master \n\n\nCounting objects: 65, done.\nDelta compression using up to 4 threads.\nCompressing objects: 100% (56/56), done.\nWriting objects: 100% (65/65), 76.27 KiB | 1.00 MiB/s, done.\nTotal 65 (delta 32), reused 0 (delta 0)\nerror: RPC failed; curl 56 OpenSSL SSL_read: error:140943FC:SSL routines:ssl3_read_bytes:sslv3 alert bad record mac, errno 0\nfatal: The remote end hung up unexpectedly\nfatal: The remote end hung up unexpectedly\nEverything up-to-date\ni'm change my buffer size and upgrade git, curl, openssl but doesn't work .so any help pleas.", "I use Arch Linux and this problem appears when trying to push on my rip \nerror: RPC failed; curl 56 OpenSSL SSL_read: error:140943FC:SSL routines:ssl3_read_bytes:sslv3 alert bad record mac, errno 0\nthis issue when writing\n\ngit push origin master \n\n\nCounting objects: 65, done.\nDelta compression using up to 4 threads.\nCompressing objects: 100% (56/56), done.\nWriting objects: 100% (65/65), 76.27 KiB | 1.00 MiB/s, done.\nTotal 65 (delta 32), reused 0 (delta 0)\nerror: RPC failed; curl 56 OpenSSL SSL_read: error:140943FC:SSL routines:ssl3_read_bytes:sslv3 alert bad record mac, errno 0\nfatal: The remote end hung up unexpectedly\nfatal: The remote end hung up unexpectedly\nEverything up-to-date\ni'm change my buffer size and upgrade git, curl, openssl but doesn't work .so any help pleas.", "I use Arch Linux and this problem appears when trying to push on my rip \nerror: RPC failed; curl 56 OpenSSL SSL_read: error:140943FC:SSL routines:ssl3_read_bytes:sslv3 alert bad record mac, errno 0\nthis issue when writing\n\ngit push origin master \n\n\nCounting objects: 65, done.\nDelta compression using up to 4 threads.\nCompressing objects: 100% (56/56), done.\nWriting objects: 100% (65/65), 76.27 KiB | 1.00 MiB/s, done.\nTotal 65 (delta 32), reused 0 (delta 0)\nerror: RPC failed; curl 56 OpenSSL SSL_read: error:140943FC:SSL routines:ssl3_read_bytes:sslv3 alert bad record mac, errno 0\nfatal: The remote end hung up unexpectedly\nfatal: The remote end hung up unexpectedly\nEverything up-to-date\ni'm change my buffer size and upgrade git, curl, openssl but doesn't work .so any help pleas.", "I know the library requests, but I don't want to use it for different reasons.So what I am trying is to make a Post request with formdata with curl from Python.The command looks something like this:command = \"curl --insecure POST --form file1='@path_to_file' --form file2='@path_to_file2' --form config='{\"key1\": {\"key11\": \"value11\", \"key12\": \"value12\"}, \"key2\": {\"key21\": \"value21\", \"key22\": \"value22\"}' <REST API Adress>\"\nSo if I copy this code manually into the linux terminal it works perfectly fine, but when I am trying to automate that with python subprocess there are backslashs added everywhere in the command. I think that is the reason why it always fails. The code looks like this:p = Popen([command], cwd=<some path>, stdout=PIPE, stderr=PIPE)\nprocess_output, process_error = p.communicate()\nIt just fails and prints me a command that looks like this:command = \"curl --insecure POST --form file1=\\'@path_to_file\\' --form file2=\\'@path_to_file2\\' --form config=\\'{\"key1\": {\"key11\": \"value11\", \"key12\": \"value12\"}, \"key2\": {\"key21\": \"value21\", \"key22\": \"value22\"}\\' <REST API Adress>\"\nI mean I get it. It is because of the single quotes, but how can I avoid this? Like how can I actually execute the correct command without backslashs?", "I am using the below command to install curl in one of the pods:$ apt-get install curl\nBut , I am getting below error:E: Could not open lock file /var/lib/dpkg/lock-frontend - open (13: Permission denied)\nE: Unable to acquire the dpkg frontend lock (/var/lib/dpkg/lock-frontend), are you root?\nWhen I am trying to remove the file /var/lib/dpkg/lock-frontend$ rm /var/lib/dpkg/lock-frontend\nrm: remove write-protected regular empty file '/var/lib/dpkg/lock-frontend'? y\nrm: cannot remove '/var/lib/dpkg/lock-frontend': Permission denied\nI can't use sudo command also :$ sudo rm /var/lib/dpkg/lock-frontend\nbash: sudo: command not found\nPlease help, as I am new to Kubernetes and Pods.", "I have a base image called docker-base which has a Dockerfile as shown below:FROM nginx:latest\n\n# Create app directory\nWORKDIR /var/www/app\n\nRUN rm /etc/nginx/conf.d/default.conf\n\n# Install app dependencies\nCOPY app-nginx.conf /etc/nginx/conf.d\n\nCOPY motd /etc/motd\n\nRUN chmod 0644 /etc/motd; echo '[ ! -z \"$TERM\" -a -r /etc/motd ] && cat /etc/motd' >> /etc/bash.bashrc\n\nCOPY usersessiontimout.sh /etc/profile.d/usersessiontimout.sh\n\nRUN chmod +x /etc/profile.d/usersessiontimout.sh\n\nEXPOSE 8000\nIt uses the latest node version and the image is built using debain bookworm as shown below when I run the container from the imageroot@e4f1d0771272:/var/www/app# cat /etc/os-release\nPRETTY_NAME=\"Debian GNU/Linux 12 (bookworm)\"\nNAME=\"Debian GNU/Linux\"\nVERSION_ID=\"12\"\nVERSION=\"12 (bookworm)\"\nVERSION_CODENAME=bookworm\nID=debian\nHOME_URL=\"https://www.debian.org/\"\nSUPPORT_URL=\"https://www.debian.org/support\"\nBUG_REPORT_URL=\"https://bugs.debian.org/\"\nBut it shows version of curl and libcurl as belowdocker exec e4f1d0771272 dpkg -l | grep curl\nii  curl                      7.88.1-10+deb12u4              arm64        command line tool for transferring data with URL syntax\nii  libcurl4:arm64            7.88.1-10+deb12u4              arm64        easy-to-use client-side URL transfer library (OpenSSL flavour)\nI tried updating it to version (>=8.0), but as per the official document the latest curl version in debian packages which nginx uses is 7.88.1.I tried removing the curl and libcurl from the base image by adding the followuing in the above Dockerfile.RUN apt-get remove -y --auto-remove curl libcurl\nBut when I built my dependent image using the base and ran the container it keeps restarting.\nMy dependent image Dockerfile as below:# Stage 1: Build stage\nFROM node:12.3.1-alpine AS build\n\n# Use different mirrors\nRUN sed -i -e 's/dl-cdn.alpinelinux.org/mirrors.aliyun.com/g' /etc/apk/repositories\n\n# Install necessary packages using the 'apk' package manager\nRUN apk update && \\\n    apk add --no-cache wget build-base openssl-dev\n\n# Set the source folder\nARG SOURCE_FOLDER=\"./\"\nARG BUILD_VERSION\nARG NPM_TOKEN\n\n# Create app directory\nWORKDIR /var/www/app\n\n# Bundle app source\nCOPY ${SOURCE_FOLDER} .\n\nRUN apk update && apk upgrade && \\\n    apk add --no-cache bash git openssh && \\\n    npm config set unsafe-perm true && \\\n    echo \"//registry.npmjs.org/:_authToken=$NPM_TOKEN\" > .npmrc && \\\n    npm i -g @myorg/lsc && \\\n    npm i --quiet --cache=./npm-cache\n\n# Build the application\nRUN NODE_OPTIONS=--max_old_space_size=4096 lsc build site --output-hashing all --buildVersion=$BUILD_VERSION && \\\n    rm -f .npmrc\n\n# Stage 2: Final stage\nFROM myorg/docker-base\n\n# Copy only the necessary artifacts from the build stage\nCOPY --from=build /var/www/app/dist/ngx-rsc-app /var/www/app\n\n\n# Install necessary packages using 'apt-get' package manager\nRUN apt-get update \n\n\n# Switch back to app directory\nWORKDIR /var/www/app\nThis is the error from the container logs of the dependendent image that was builtroot@ip:~# docker logs -f 77666b51984a\nexec /docker-entrypoint.sh: exec format error\nexec /docker-entrypoint.sh: exec format error\nexec /docker-entrypoint.sh: exec format error\nexec /docker-entrypoint.sh: exec format error\nAny idea why its throwing this error and possible resolution? Also, is there a better way to remove the the existing curl and libcurl and also keep the container healthy? Or update it to a version >=8.0?", "Whenever I use curl and get error 60 (SSL certificate problem) it also shows me big wall of text:\ncurl performs SSL certificate verification by default, using a \"bundle\" of Certificate Authority (CA) public keys (CA certs). If the default bundle file isn't adequate, you can specify an alternate file using the --cacert option.\nIf this HTTPS server uses a certificate signed by a CA represented in the bundle, the certificate verification probably failed due to a problem with the certificate (it might be expired, or the name might not match the domain name in the URL).\nIf you'd like to turn off curl's verification of the certificate, use the -k (or --insecure) option.\nHow can i hide only this wall of text?", "This is he code I am using to send email from my Linux OS to Gmail. It works really well, except the subject is still shown as no subject in my gmail inbox.\n[![No Subject in GMAIL[1]][1]curl --ssl-reqd \\\n--url 'smtps://smtp.gmail.com:465' \\\n--user $EMAIL_SENDING_FROM:$GMAIL_APP_PASSWORD \\\n--mail-from $EMAIL_SENDING_FROM \\\n--mail-rcpt $EMAIL_SENDING_TO \\\n--header \"Subject: The files you requested\" \\\n--upload-file $PROCESS_LOG```\n\n\n  [1]: https://i.stack.imgur.com/74wLW.png\n", "This is he code I am using to send email from my Linux OS to Gmail. It works really well, except the subject is still shown as no subject in my gmail inbox.\n[![No Subject in GMAIL[1]][1]curl --ssl-reqd \\\n--url 'smtps://smtp.gmail.com:465' \\\n--user $EMAIL_SENDING_FROM:$GMAIL_APP_PASSWORD \\\n--mail-from $EMAIL_SENDING_FROM \\\n--mail-rcpt $EMAIL_SENDING_TO \\\n--header \"Subject: The files you requested\" \\\n--upload-file $PROCESS_LOG```\n\n\n  [1]: https://i.stack.imgur.com/74wLW.png\n", "I'm learning shell scripting! for the same I've tried downloading the facebook page using curl on ubuntu terminal.t.sh contentvi@vi-Dell-7537(Desktop) $ cat t.sh \ncurlCmd=\"curl \\\"https://www.facebook.com/vivekkumar27june88\\\"\"\necho $curlCmd\n($curlCmd) > ~/Desktop/fb.html\nGetting error when running the script asvi@vi-Dell-7537(Desktop) $ ./t.sh \ncurl \"https://www.facebook.com/vivekkumar27june88\"\ncurl: (1) Protocol \"https not supported or disabled in libcurl\nBut if the run the command directly then it is working fine.vi@vi-Dell-7537(Desktop) $ curl \"https://www.facebook.com/vivekkumar27june88\"\n<!DOCTYPE html>\n<html lang=\"hi\" id=\"facebook\" class=\"no_js\">\n<head><meta chars.....\nI will appreciate if anyone let me know the mistake I am doing in the script.I've verified that curl library have ssl enabled.", "I'm learning shell scripting! for the same I've tried downloading the facebook page using curl on ubuntu terminal.t.sh contentvi@vi-Dell-7537(Desktop) $ cat t.sh \ncurlCmd=\"curl \\\"https://www.facebook.com/vivekkumar27june88\\\"\"\necho $curlCmd\n($curlCmd) > ~/Desktop/fb.html\nGetting error when running the script asvi@vi-Dell-7537(Desktop) $ ./t.sh \ncurl \"https://www.facebook.com/vivekkumar27june88\"\ncurl: (1) Protocol \"https not supported or disabled in libcurl\nBut if the run the command directly then it is working fine.vi@vi-Dell-7537(Desktop) $ curl \"https://www.facebook.com/vivekkumar27june88\"\n<!DOCTYPE html>\n<html lang=\"hi\" id=\"facebook\" class=\"no_js\">\n<head><meta chars.....\nI will appreciate if anyone let me know the mistake I am doing in the script.I've verified that curl library have ssl enabled.", "I'm learning shell scripting! for the same I've tried downloading the facebook page using curl on ubuntu terminal.t.sh contentvi@vi-Dell-7537(Desktop) $ cat t.sh \ncurlCmd=\"curl \\\"https://www.facebook.com/vivekkumar27june88\\\"\"\necho $curlCmd\n($curlCmd) > ~/Desktop/fb.html\nGetting error when running the script asvi@vi-Dell-7537(Desktop) $ ./t.sh \ncurl \"https://www.facebook.com/vivekkumar27june88\"\ncurl: (1) Protocol \"https not supported or disabled in libcurl\nBut if the run the command directly then it is working fine.vi@vi-Dell-7537(Desktop) $ curl \"https://www.facebook.com/vivekkumar27june88\"\n<!DOCTYPE html>\n<html lang=\"hi\" id=\"facebook\" class=\"no_js\">\n<head><meta chars.....\nI will appreciate if anyone let me know the mistake I am doing in the script.I've verified that curl library have ssl enabled.", "I'm learning shell scripting! for the same I've tried downloading the facebook page using curl on ubuntu terminal.t.sh contentvi@vi-Dell-7537(Desktop) $ cat t.sh \ncurlCmd=\"curl \\\"https://www.facebook.com/vivekkumar27june88\\\"\"\necho $curlCmd\n($curlCmd) > ~/Desktop/fb.html\nGetting error when running the script asvi@vi-Dell-7537(Desktop) $ ./t.sh \ncurl \"https://www.facebook.com/vivekkumar27june88\"\ncurl: (1) Protocol \"https not supported or disabled in libcurl\nBut if the run the command directly then it is working fine.vi@vi-Dell-7537(Desktop) $ curl \"https://www.facebook.com/vivekkumar27june88\"\n<!DOCTYPE html>\n<html lang=\"hi\" id=\"facebook\" class=\"no_js\">\n<head><meta chars.....\nI will appreciate if anyone let me know the mistake I am doing in the script.I've verified that curl library have ssl enabled.", "when I try to load a web page to terminal it gives curl: (6) Could not resolve host error. I have internet in my PC and trying from my home internet connection. So as I there is no any proxy involve here. [root@localhost kevin]# curl http://google.com\ncurl: (6) Could not resolve host: google.com; Name or service not known\nclean all and tried again but no lucky. But if I use IP instead of the domain name, it works fine. [root@localhost kevin]# curl http://173.194.46.0any clue please?", "when I try to load a web page to terminal it gives curl: (6) Could not resolve host error. I have internet in my PC and trying from my home internet connection. So as I there is no any proxy involve here. [root@localhost kevin]# curl http://google.com\ncurl: (6) Could not resolve host: google.com; Name or service not known\nclean all and tried again but no lucky. But if I use IP instead of the domain name, it works fine. [root@localhost kevin]# curl http://173.194.46.0any clue please?", "when I try to load a web page to terminal it gives curl: (6) Could not resolve host error. I have internet in my PC and trying from my home internet connection. So as I there is no any proxy involve here. [root@localhost kevin]# curl http://google.com\ncurl: (6) Could not resolve host: google.com; Name or service not known\nclean all and tried again but no lucky. But if I use IP instead of the domain name, it works fine. [root@localhost kevin]# curl http://173.194.46.0any clue please?", "when I try to load a web page to terminal it gives curl: (6) Could not resolve host error. I have internet in my PC and trying from my home internet connection. So as I there is no any proxy involve here. [root@localhost kevin]# curl http://google.com\ncurl: (6) Could not resolve host: google.com; Name or service not known\nclean all and tried again but no lucky. But if I use IP instead of the domain name, it works fine. [root@localhost kevin]# curl http://173.194.46.0any clue please?", "when I try to load a web page to terminal it gives curl: (6) Could not resolve host error. I have internet in my PC and trying from my home internet connection. So as I there is no any proxy involve here. [root@localhost kevin]# curl http://google.com\ncurl: (6) Could not resolve host: google.com; Name or service not known\nclean all and tried again but no lucky. But if I use IP instead of the domain name, it works fine. [root@localhost kevin]# curl http://173.194.46.0any clue please?", "when I try to load a web page to terminal it gives curl: (6) Could not resolve host error. I have internet in my PC and trying from my home internet connection. So as I there is no any proxy involve here. [root@localhost kevin]# curl http://google.com\ncurl: (6) Could not resolve host: google.com; Name or service not known\nclean all and tried again but no lucky. But if I use IP instead of the domain name, it works fine. [root@localhost kevin]# curl http://173.194.46.0any clue please?", "when I try to load a web page to terminal it gives curl: (6) Could not resolve host error. I have internet in my PC and trying from my home internet connection. So as I there is no any proxy involve here. [root@localhost kevin]# curl http://google.com\ncurl: (6) Could not resolve host: google.com; Name or service not known\nclean all and tried again but no lucky. But if I use IP instead of the domain name, it works fine. [root@localhost kevin]# curl http://173.194.46.0any clue please?", "when I try to load a web page to terminal it gives curl: (6) Could not resolve host error. I have internet in my PC and trying from my home internet connection. So as I there is no any proxy involve here. [root@localhost kevin]# curl http://google.com\ncurl: (6) Could not resolve host: google.com; Name or service not known\nclean all and tried again but no lucky. But if I use IP instead of the domain name, it works fine. [root@localhost kevin]# curl http://173.194.46.0any clue please?", "when I try to load a web page to terminal it gives curl: (6) Could not resolve host error. I have internet in my PC and trying from my home internet connection. So as I there is no any proxy involve here. [root@localhost kevin]# curl http://google.com\ncurl: (6) Could not resolve host: google.com; Name or service not known\nclean all and tried again but no lucky. But if I use IP instead of the domain name, it works fine. [root@localhost kevin]# curl http://173.194.46.0any clue please?", "I'm trying to download .EAR file from jFrog artifactory using curl command and save it on to the server.curl -k -b \"/appl/webappl/server/cookie.txt\" \"https://jfrog.dev.com/ui/v1/download?repoKey=key&path=path%252Ffile.ear\" -o \"/appl/webappl/server/file.ear\"\nQuestions:\nHow to select this specific url from dev tools on browser \"https://jfrog.dev.com/ui/v1/download\"\nHow to choose repoKey and the path\nWhy can't we use direct url to the file\n", "I have a web page that has a very simple HTML table. The HTML code of the webpage is as below. The HTML will always remain same, only the data values will change.<!DOCTYPE html>\n    <html lang=\"en\">\n      <head>\n        <meta charset=\"utf-8\">\n        <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n        <title>Demo Page Results</title>\n        <link rel=\"stylesheet\" href=\"/static/styles.css\">\n      </head>\n      <body id=\"particles\">\n          <div class=\"container\">\n            <h1>Demo Page Results</h1>\n            <table>\n              <tr>\n                <td>\n                  Examiner:\n                </td>\n                <td class=\"marked\">\n                  Person\n                </td>\n              </tr>\n\n              <tr>\n                <td>\n                  Qualification:\n                </td>\n                <td class=\"marked\">\n                  Teacher\n                </td>\n              </tr>\n              <tr>\n                <td>\n                  Nation:\n                </td>\n                <td class=\"marked\">\n                  Any\n                </td>\n              </tr>\n\n            </table>\n\n          </div>\n\n        <script src=\"/static/jrf.min.js\"></script>\n        <script src=\"/static/scripts.js\"></script>\n      </body>\n    </html>\nThe output of the code is as belowDemo Page ResultsExaminer: PersonQualification: TeacherNation: AnyI need to use bash scripting to get the contents of the table as followsExaminer: Person\n\nQualification: Teacher\n\nNation: Any\nI am using the following bash script#!/bin/bash\n# URL of the webpage\n# containing the HTML\n# table\nURL=\"http://thewebpageurl\"\n# Use curl to fetch the\n# HTML content of the\n# webpage\nHTML=$(curl -s \"$URL\")\n#echo $HTML\n# Use grep and sed to\n# extract the table\n# content\nTABLE_HTML=$(echo \"$HTML\" | grep -o '\\<table\\[^\\>\\]\\*\\>.\\*\\</table\\>' | sed 's/\\<\\\\/table.\\*//')\necho $TABLE_HTML\n# Use awk to parse and\n# print the table data\necho \"$TABLE_HTML\" | awk -F\"\\</tr\\>\" '{ for (i=1; i\\<=NF;i++) { sub(/.\\*\\<td\\[^\\>\\]\\*\\>/, \"\", $i); sub(/\\<\\\\/td\\>.\\*/, \"\", $i); printf \"%s \", $i; } printf \"\\\\n\"; }'\nBut sadly this is not showing any results.Kindly help and guide me to fix the bash script.\nThanks\nNeha", "I have a web page that has a very simple HTML table. The HTML code of the webpage is as below. The HTML will always remain same, only the data values will change.<!DOCTYPE html>\n    <html lang=\"en\">\n      <head>\n        <meta charset=\"utf-8\">\n        <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n        <title>Demo Page Results</title>\n        <link rel=\"stylesheet\" href=\"/static/styles.css\">\n      </head>\n      <body id=\"particles\">\n          <div class=\"container\">\n            <h1>Demo Page Results</h1>\n            <table>\n              <tr>\n                <td>\n                  Examiner:\n                </td>\n                <td class=\"marked\">\n                  Person\n                </td>\n              </tr>\n\n              <tr>\n                <td>\n                  Qualification:\n                </td>\n                <td class=\"marked\">\n                  Teacher\n                </td>\n              </tr>\n              <tr>\n                <td>\n                  Nation:\n                </td>\n                <td class=\"marked\">\n                  Any\n                </td>\n              </tr>\n\n            </table>\n\n          </div>\n\n        <script src=\"/static/jrf.min.js\"></script>\n        <script src=\"/static/scripts.js\"></script>\n      </body>\n    </html>\nThe output of the code is as belowDemo Page ResultsExaminer: PersonQualification: TeacherNation: AnyI need to use bash scripting to get the contents of the table as followsExaminer: Person\n\nQualification: Teacher\n\nNation: Any\nI am using the following bash script#!/bin/bash\n# URL of the webpage\n# containing the HTML\n# table\nURL=\"http://thewebpageurl\"\n# Use curl to fetch the\n# HTML content of the\n# webpage\nHTML=$(curl -s \"$URL\")\n#echo $HTML\n# Use grep and sed to\n# extract the table\n# content\nTABLE_HTML=$(echo \"$HTML\" | grep -o '\\<table\\[^\\>\\]\\*\\>.\\*\\</table\\>' | sed 's/\\<\\\\/table.\\*//')\necho $TABLE_HTML\n# Use awk to parse and\n# print the table data\necho \"$TABLE_HTML\" | awk -F\"\\</tr\\>\" '{ for (i=1; i\\<=NF;i++) { sub(/.\\*\\<td\\[^\\>\\]\\*\\>/, \"\", $i); sub(/\\<\\\\/td\\>.\\*/, \"\", $i); printf \"%s \", $i; } printf \"\\\\n\"; }'\nBut sadly this is not showing any results.Kindly help and guide me to fix the bash script.\nThanks\nNeha", "I have a web page that has a very simple HTML table. The HTML code of the webpage is as below. The HTML will always remain same, only the data values will change.<!DOCTYPE html>\n    <html lang=\"en\">\n      <head>\n        <meta charset=\"utf-8\">\n        <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n        <title>Demo Page Results</title>\n        <link rel=\"stylesheet\" href=\"/static/styles.css\">\n      </head>\n      <body id=\"particles\">\n          <div class=\"container\">\n            <h1>Demo Page Results</h1>\n            <table>\n              <tr>\n                <td>\n                  Examiner:\n                </td>\n                <td class=\"marked\">\n                  Person\n                </td>\n              </tr>\n\n              <tr>\n                <td>\n                  Qualification:\n                </td>\n                <td class=\"marked\">\n                  Teacher\n                </td>\n              </tr>\n              <tr>\n                <td>\n                  Nation:\n                </td>\n                <td class=\"marked\">\n                  Any\n                </td>\n              </tr>\n\n            </table>\n\n          </div>\n\n        <script src=\"/static/jrf.min.js\"></script>\n        <script src=\"/static/scripts.js\"></script>\n      </body>\n    </html>\nThe output of the code is as belowDemo Page ResultsExaminer: PersonQualification: TeacherNation: AnyI need to use bash scripting to get the contents of the table as followsExaminer: Person\n\nQualification: Teacher\n\nNation: Any\nI am using the following bash script#!/bin/bash\n# URL of the webpage\n# containing the HTML\n# table\nURL=\"http://thewebpageurl\"\n# Use curl to fetch the\n# HTML content of the\n# webpage\nHTML=$(curl -s \"$URL\")\n#echo $HTML\n# Use grep and sed to\n# extract the table\n# content\nTABLE_HTML=$(echo \"$HTML\" | grep -o '\\<table\\[^\\>\\]\\*\\>.\\*\\</table\\>' | sed 's/\\<\\\\/table.\\*//')\necho $TABLE_HTML\n# Use awk to parse and\n# print the table data\necho \"$TABLE_HTML\" | awk -F\"\\</tr\\>\" '{ for (i=1; i\\<=NF;i++) { sub(/.\\*\\<td\\[^\\>\\]\\*\\>/, \"\", $i); sub(/\\<\\\\/td\\>.\\*/, \"\", $i); printf \"%s \", $i; } printf \"\\\\n\"; }'\nBut sadly this is not showing any results.Kindly help and guide me to fix the bash script.\nThanks\nNeha", "I have a web page that has a very simple HTML table. The HTML code of the webpage is as below. The HTML will always remain same, only the data values will change.<!DOCTYPE html>\n    <html lang=\"en\">\n      <head>\n        <meta charset=\"utf-8\">\n        <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n        <title>Demo Page Results</title>\n        <link rel=\"stylesheet\" href=\"/static/styles.css\">\n      </head>\n      <body id=\"particles\">\n          <div class=\"container\">\n            <h1>Demo Page Results</h1>\n            <table>\n              <tr>\n                <td>\n                  Examiner:\n                </td>\n                <td class=\"marked\">\n                  Person\n                </td>\n              </tr>\n\n              <tr>\n                <td>\n                  Qualification:\n                </td>\n                <td class=\"marked\">\n                  Teacher\n                </td>\n              </tr>\n              <tr>\n                <td>\n                  Nation:\n                </td>\n                <td class=\"marked\">\n                  Any\n                </td>\n              </tr>\n\n            </table>\n\n          </div>\n\n        <script src=\"/static/jrf.min.js\"></script>\n        <script src=\"/static/scripts.js\"></script>\n      </body>\n    </html>\nThe output of the code is as belowDemo Page ResultsExaminer: PersonQualification: TeacherNation: AnyI need to use bash scripting to get the contents of the table as followsExaminer: Person\n\nQualification: Teacher\n\nNation: Any\nI am using the following bash script#!/bin/bash\n# URL of the webpage\n# containing the HTML\n# table\nURL=\"http://thewebpageurl\"\n# Use curl to fetch the\n# HTML content of the\n# webpage\nHTML=$(curl -s \"$URL\")\n#echo $HTML\n# Use grep and sed to\n# extract the table\n# content\nTABLE_HTML=$(echo \"$HTML\" | grep -o '\\<table\\[^\\>\\]\\*\\>.\\*\\</table\\>' | sed 's/\\<\\\\/table.\\*//')\necho $TABLE_HTML\n# Use awk to parse and\n# print the table data\necho \"$TABLE_HTML\" | awk -F\"\\</tr\\>\" '{ for (i=1; i\\<=NF;i++) { sub(/.\\*\\<td\\[^\\>\\]\\*\\>/, \"\", $i); sub(/\\<\\\\/td\\>.\\*/, \"\", $i); printf \"%s \", $i; } printf \"\\\\n\"; }'\nBut sadly this is not showing any results.Kindly help and guide me to fix the bash script.\nThanks\nNeha", "I've been combing through Microsoft's documentation on the REST API to manipulate files in our SharePoint Online document tree. I'm ALMOST to my solution but having an issue.I'm running CURL commands on a Linux server. And in the /tmp directory on Linux I have a file 'a.txt'. I can create a new file on SharePoint online using CURL, but I cannot upload an existing file using the same command.When I specify \"Content-Length: 0\", this command successfully creates a new file on our SharePointcurl -X POST -i -H \"Authorization: Bearer tokenabc\" -H \"Content-Length: 0\" -s \"https://tenant.sharepoint.com/teams/testSite/_api/web/GetFolderByServerRelativeUrl('%20Shared%20Documents')/Files/add(url='a.txt',overwrite=true)\"\nBut when I try to actually UPLOAD my file from the /tmp directory, (I run the CURL command in the /tmp directory, I change \"Content-Length: 4000\"), I get no response whatsoever and no file is created.curl -X POST -i -H \"Authorization: Bearer tokenabc\" -H \"Content-Length: 4000\" -s \"https://tenant.sharepoint.com/teams/testSite/_api/web/GetFolderByServerRelativeUrl('%20Shared%20Documents')/Files/add(url='a.txt',overwrite=true)\"\nI cannot seem to figure out how to upload my file from the Linux server itself using this CURL REST API command"], "chosen": ["\nIt seems to me that www.fnde.gov.br site admin restricted the access of this website outside the country (Brazil here). This happens with many countries restricting their websites for access.\nI assume the Hetzner VM is somewhere in Germany same as where I am. The traceroute command fails after few hops. You could verify the same from ping.eu\nNevertheless, traceroute works from perfops.net Brazil nodes. Their web application seems to be running when I checked with pingdom tools. Test results for you here.\nAs far as the timeouts are concerned, it may not work for you from Hetzner infrastructure as it's either based in Europe & North America only.\nAnother option could be using vpn/Cloudflare ZTNA connecting to a server located in Brazil\n", "\nJust switch to mobile hotspot and push.\n", "\nSo I ran into the same issue and contacted github.com/contact. In the end, they gave the hint that solved it for me. I needed to change the git config to use TLSv1.2 instead of SSLv3:\ngit config http.sslVersion tlsv1.2\n\nAs GitHub support told me, in the beginning, the issue could be related to a change which they deployed a few months ago, that disables support for deprecated legacy TLS and SSH algorithms, including those that were used in older versions of some Git clients. You can find more information and advice here:\nhttps://githubengineering.com/crypto-removal-notice/\n", "\nAs R.singh said I changed my internet connection to Mobile hotspot and it worked for me like a magic !\n", "\nThis is the final answer:\ngit config --global http.postBuffer 1048576000\n\n", "\nI had a similar issue and solved it by updating Git.\nIf you're on Windows run Command Prompt as Administrator and execute\ngit update-git-for-windows\n\n", "\nin my case, these commands work\n1. git config http.postBuffer 524288000\n2. git push\nif git push is not working then use this one\n1. git push origin branch-name\n", "\nI'm on windows, so i can't test, but i have better experience using the quotation marks the other way around, maybe this helps you too. So in your example:\ncommand = 'curl --insecure POST --form file1=\"@path_to_file\" --form file2=\"@path_to_file2\" --form config=\"{\"key1\": {\"key11\": \"value11\", \"key12\": \"value12\"}, \"key2\": {\"key21\": \"value21\", \"key22\": \"value22\"}\" <REST API Adress>'\n\n", "\nIf you are trying to troubleshoot from the container, you can try to leverage bash's built-in TCP/UDP socket support, for example:\nHOSTNAME=google.com; PORT=80\necho >/dev/tcp/$HOSTNAME/$PORT && echo \"Open\" || echo \"Closed\"\n\nIf your pod/container has a programming language installed, Python, Ruby, or Node you can use a single bash line to test as well. Take a look at the different options I prepared here https://go.rebelion.la/uSTroubleshooting\n", "\nThe solution that worked was using nginx based on alpine image, which doesn't have curl and libcurl packages installed. I retained the nginx configurations from myorg/docker-base. Here is the complete solution:\nDockerfile of my docker-base image\nFROM nginx:latest\n\n# Create app directory\nWORKDIR /var/www/app\n\nRUN rm /etc/nginx/conf.d/default.conf\n\n# Install app dependencies\nCOPY app-nginx.conf /etc/nginx/conf.d\n\nCOPY motd /etc/motd\n\nRUN chmod 0644 /etc/motd; echo '[ ! -z \"$TERM\" -a -r /etc/motd ] && cat /etc/motd' >> /etc/bash.bashrc\n\nCOPY usersessiontimout.sh /etc/profile.d/usersessiontimout.sh\n\nRUN chmod +x /etc/profile.d/usersessiontimout.sh\n\nEXPOSE 8000\n\n\nDockerfile of my dependent image\n# Stage 1: Build stage\nFROM node:12.3.1-alpine AS build\n\n# Use different mirrors\nRUN sed -i -e 's/dl-cdn.alpinelinux.org/mirrors.aliyun.com/g' /etc/apk/repositories\n\n# Install necessary packages using the 'apk' package manager\nRUN apk update && \\\n    apk add --no-cache wget build-base openssl-dev\n\n# Set the source folder\nARG SOURCE_FOLDER=\"./\"\nARG BUILD_VERSION\nARG NPM_TOKEN\n\n# Create app directory\nWORKDIR /var/www/app\n\n# Bundle app source\nCOPY ${SOURCE_FOLDER} .\n\nRUN apk update && apk upgrade && \\\n    apk add --no-cache bash git openssh && \\\n    npm config set unsafe-perm true && \\\n    echo \"//registry.npmjs.org/:_authToken=$NPM_TOKEN\" > .npmrc && \\\n    npm i -g @myorg/lsc && \\\n    npm i --quiet --cache=./npm-cache\n\n# Build the application\nRUN NODE_OPTIONS=--max_old_space_size=4096 lsc build site --output-hashing all --buildVersion=$BUILD_VERSION && \\\n    rm -f .npmrc\n\n# Stage 2: Nginx configuration stage\nFROM myorg/docker-base:latest AS nginx-conf\n\n# Stage 3: Final nginx image\nFROM nginx:stable-alpine-slim\n\n# Copy the build output and nginx configuration\nCOPY --from=build /var/www/app/dist/ngx-rsc-app /var/www/app\nCOPY --from=nginx-conf /etc/nginx/conf.d/app-nginx.conf /etc/nginx/conf.d\n\n# Set ownership and permissions for NGINX directories, files and create the Nginx process ID file\nRUN chown -R nginx:nginx /var/www/app /var/cache/nginx /var/log/nginx /etc/nginx \\\n    && touch /var/run/nginx.pid \\\n    && chown nginx:nginx /var/run/nginx.pid \\\n    && rm /etc/nginx/conf.d/default.conf\n\n# Install net-tools to provide network diagnostic tools\nRUN apk add --no-cache net-tools\n\n# Set the Nginx user\nUSER 101\n\n# Run Nginx with the command \"nginx -g daemon off;\"\nCMD [\"nginx\",\"-g\",\"daemon off;\"]\n\nThe container logs of the dependent image that was built, doesn't show any curl or libcurl anymore.\n", "\nIf you want only to supress the warning, use the flag:\n-s, --silent\nIf you want to connect to the server despite the certificate issues, use the following flag:\n-k (or --insecure)\n", "\nThe file $PROCESS_LOG should contain a line at the top with Subject:\nFor instance:\nSubject: The file you requested\n\nThis is a log\n...\n...\n\n", "\nI think --Header should be replaced with --data-binary with data, try:\ncurl --ssl-reqd \\\n--url 'smtps://smtp.gmail.com:465' \\\n--user $EMAIL_SENDING_FROM:$GMAIL_APP_PASSWORD \\\n--mail-from $EMAIL_SENDING_FROM \\\n--mail-rcpt $EMAIL_SENDING_TO \\\n--data-binary \"Subject: The files you requested\\n\\nThe files you requested are attached.\" \\\n--upload-file $PROCESS_LOG\n\n\n\n", "\nCreate your script t.sh as this single line only:\ncurl -k \"https://www.facebook.com/vivekkumar27june88\" -o ~/Desktop/fb.html\n\nAs per man curl:\n-k, --insecure\n(SSL) This option explicitly allows curl to perform \"insecure\" SSL connections transfers.  \nAll  SSL  connections  are  attempted  to be made secure by using the CA certificate bundle\ninstalled by default. This makes all connections considered \"insecure\" fail unless -k,\n--insecure is used.\n\n-o file\nStore output in the given filename.\n\n", "\nA command embedded within a parenthesis runs as a sub-shell so your environment variables will be missing.\nTry eval:\ncurlCmd=\"curl 'https://www.facebook.com/vivekkumar27june88' > ~/Desktop/fb.html\"\neval $curlCmd\n\n", "\nAs @Chepner said, go read BashFAQ #50: I'm trying to put a command in a variable, but the complex cases always fail!. To summarize, how you should do things like this depends on what your goal is.\n\nIf you don't need to store the command, don't! Storing commands is difficult to get right, so if you don't need to, just skip that mess and execute it directly:\ncurl \"https://www.facebook.com/vivekkumar27june88\" > ~/Desktop/fb.html\n\nIf you want to hide the details of the command, or are going to use it a lot and don't want to write it out each time, use a function:\ncurlCmd() {\n    curl \"https://www.facebook.com/vivekkumar27june88\"\n}\n\ncurlCmd > ~/Desktop/fb.html\n\nIf you need to build the command piece-by-piece, use an array instead of a plain string variable:\ncurlCmd=(curl \"https://www.facebook.com/vivekkumar27june88\")\nfor header in \"${extraHeaders[@]}\"; do\n    curlCmd+=(-H \"$header\")   # Add header options to the command\ndone\nif [[ \"$useSilentMode\" = true ]]; then\n    curlCmd+=(-s)\nfi\n\n\"${curlCmd[@]}\" > ~/Desktop/fb.html    # This is the standard idiom to expand an array\n\nIf you want to print the command, the best way to do it is usually with set -x:\nset -x\ncurl \"https://www.facebook.com/vivekkumar27june88\" > ~/Desktop/fb.html\nset +x\n...but you can also do something similar with the array approach if you need to:\nprintf \"%q \" \"${curlCmd[@]}\"    # Print the array, quoting as needed\nprintf \"\\n\"\n\"${curlCmd[@]}\" > ~/Desktop/fb.html\n\n\n", "\nInstall following softwares in ubuntu 14.04\n\nsudo apt-get install php5-curl\nsudo apt-get install curl\n\nthen run sudo service apache2 restart\ncheck your phpinfo() is enable with curl \"cURL support: enabled\"\nThen check your command in shell script\nRESULT=curl -L \"http://sitename.com/dashboard/?show=api&action=queue_proc&key=$JOBID\" 2>/dev/null\necho $RESULT\nYou will get response;\nThanks you.\n", "\nThere is no need to disable IPv6 as the answer suggests. The reason curl fails is simply because the DNS resolution is missing.\nThere is one liner solution to this.\nIf you care about what is inside /etc/resolv.conf then append it:\necho 'nameserver 1.1.1.1' | sudo tee -a /etc/resolv.conf >/dev/null\n\nI usually don't care and just replace the content of the file:\necho 'nameserver 1.1.1.1' | sudo tee /etc/resolv.conf >/dev/null\n\n", "\nIssues were:\n\nIPV6 enabled\nWrong DNS server \n\nHere is how I fixed it:\nIPV6 Disabling\n\nOpen Terminal\nType su and enter to log in as the super user\nEnter the root password\nType cd /etc/modprobe.d/ to change directory to /etc/modprobe.d/\nType vi disableipv6.conf to create a new file there\nPress Esc + i to insert data to file\nType install ipv6 /bin/true on the file to avoid loading IPV6 related modules\nType Esc + : and then wq for save and exit\nType reboot to restart fedora\nAfter reboot open terminal and type lsmod | grep ipv6\nIf no result, it means you properly disabled IPV6\n\nAdd Google DNS server\n\nOpen Terminal\nType su and enter to log in as the super user\nEnter the root password\nType cat /etc/resolv.conf to check what DNS server your Fedora using. Mostly this will be your Modem IP address.\nNow we have to Find a powerful DNS server. Luckily there is a open DNS server maintain by  Google.\nGo to this page and find out what are the \"Google Public DNS IP addresses\"\nToday those are 8.8.8.8 and 8.8.4.4. But in future those may change.\nType vi /etc/resolv.conf to edit the resolv.conf file\nPress Esc + i for insert data to file\nComment all the things in the file by inserting # at the begin of the each line. Do not   delete anything because can be useful in future.\nType below two lines in the file\nnameserver 8.8.8.8\nnameserver 8.8.4.4\n-Type Esc + : and then wq for save and exit\nNow you are done and everything works fine (Not necessary to restart).\nBut every time when you restart the computer your  /etc/resolv.conf will be replaced by default. So I'll let you find a way to avoid that. \n\nHere is my blog post about this:\nhttp://codeketchup.blogspot.sg/2014/07/how-to-fix-curl-6-could-not-resolve.html\n", "\nPerhaps you have some very weird and restrictive SELinux rules in place?\nIf not, try strace -o /tmp/wtf -fF curl -v google.com and try to spot from /tmp/wtf output file what's going on.\n", "\nI have today similar problem. But weirder.\n\nhost - works host pl.archive.ubuntu.com\ndig - works on default and on all other DNS's dig pl.archive.ubuntu.com, dig @127.0.1.1 pl.archive.ubuntu.com\ncurl - doesn't work! but for some addresses it does. WEIRD! Same in Ruby, APT and many more.\n\n$ curl -v http://google.com/\n*   Trying 172.217.18.78...\n* Connected to google.com (172.217.18.78) port 80 (#0)\n> GET / HTTP/1.1\n> Host: google.com\n> User-Agent: curl/7.47.0\n> Accept: */*\n>\n< HTTP/1.1 302 Found\n< Cache-Control: private\n< Content-Type: text/html; charset=UTF-8\n< Referrer-Policy: no-referrer\n< Location: http://www.google.pl/?gfe_rd=cr&ei=pt9UWfqXL4uBX_W5n8gB\n< Content-Length: 256\n< Date: Thu, 29 Jun 2017 11:08:22 GMT\n<\n<HTML><HEAD><meta http-equiv=\"content-type\" content=\"text/html;charset=utf-8\">\n<TITLE>302 Moved</TITLE></HEAD><BODY>\n<H1>302 Moved</H1>\nThe document has moved\n<A HREF=\"http://www.google.pl/?gfe_rd=cr&ei=pt9UWfqXL4uBX_W5n8gB\">here</A>.\n</BODY></HTML>\n* Connection #0 to host google.com left intact\n\n$ curl -v http://pl.archive.ubuntu.com/\n* Could not resolve host: pl.archive.ubuntu.com\n* Closing connection 0\ncurl: (6) Could not resolve host: pl.archive.ubuntu.com\n\nRevelation\nEventually I used strace on curl and found that it was connection to nscd deamon.\nconnect(4, {sa_family=AF_LOCAL, sun_path=\"/var/run/nscd/socket\"}, 110) = 0\n\nSolution\nI've restarted the nscd service (Name Service Cache Daemon) and it helped to solve this issue!\nsystemctl restart nscd.service\n\n", "\nTry nslookup google.com to determine if there's a DNS issue. \n192.168.1.254 is your local network address and it looks like your system is using it as a DNS server. Is this your gateway/modem router as well? \nWhat happens when you try ping google.com. Can you browse to it on a Internet web browser? \n", "\nIn Our case, the command was passed through mail/skype and the person who needs to execute copied an extra space.\nwe found that extra space after an hour and removing that made it work.\n", "\nI had an issue with IPV6 that suddenly showed up in wordpress admin where curl failed to connect to wordpress.org etc giving\n\nAn unexpected error occurred. Something may be wrong with WordPress.org\n\nand also\n\nInstallation failed: Download failed. cURL error 28: Resolving timed out after 10005 milliseconds\n\nI eventually sorted by adding the following as a php file in mu-plugins:\nadd_action( 'http_api_curl', function( $curl_handle ) { curl_setopt( $curl_handle, CURLOPT_IPRESOLVE, CURL_IPRESOLVE_V4 );});\n\nand also when using curl directly in php by using the following option in the options array:\ncurl_setopt_array($curl, array(CURLOPT_IPRESOLVE => CURL_IPRESOLVE_V4));\n\nThe OS is IBM i (OS400/i5OS) v7.2 running on Power 6 and the php version is 8.1.10. Interestingly IPV6 is not active on the box.\n", "\nMy case on MacOS was simple: I closed the iTerm window I was using and opened a new one.\nIt seems likely that this is an issue with CURL cacheing DNS responses given that I was messing around with my DNS when I ran into the same error as the OP.\n", "\nIn my case, the problem was in the Static Route Table. Must be removed if a static route was previously added\n", "\nThe below solution was worked for me.\ncurl -vk -u username:password/apikey -X GET 'https://repo_path/file_path/file_name' > file_name \n\n", "\nRuby has a great XML/HTML parser available called Nokogiri.\nYou can do something like this:\nruby -r nokogiri -e 'Nokogiri::HTML($<.read).at(\"table\").search(\"tr\").\neach{ |tr|\n    cells = tr.search(\"th, td\")\n    puts cells.map{|cell| cell.text.strip }.join(\" \")\n}' file \n\nPrints:\nExaminer: Person\nQualification: Teacher\nNation: Any\n\n", "\nAssuming your HTML format will never change, as you stated, then using any POSIX awk:\n$ cat tst.sh\n#!/usr/bin/env bash\n\nawk '\n    { gsub(/^[[:space:]]+|[[:space:]]+$/,\"\") }\n    $0 == \"</td>\"                   { inTag=inVal=0 }\n    inTag { tag = $0 }\n    inVal { print tag, $0 }\n    $0 == \"<td>\"                    { inTag=1 }\n    $0 == \"<td class=\\\"marked\\\">\"   { inVal=1 }\n' \"${@:--}\"\n\n\n$ ./tst.sh file\nExaminer: Person\nQualification: Teacher\nNation: Any\n\nIf you REALLY want a blank line after each output line as shown in the expected output in your question then just change print tag, $0 to print tag, $0 ORS.\n", "\n$ awk '!/^$|</{i++; printf \"%s %s\", $1, (i%2==0 ? \"\\n\": \"\")}' file\nExaminer: Person \nQualification: Teacher\nNation: Any\n\n", "\nThis might work for you (xidel version 0.9.8, GNU paste and sed):\nxidel file -se '//td' | paste -d' ' - -\n\nor to put all on one line separated by #:\nxidel file -se '//td' | sed 'N;s/\\n//' | paste -sd#\n\n\nThe above solutions can also be replicated entirely with xidel (thanks to Reino) as:\nxidel file -se '//tr/normalize-space()'\n\nand:\nxidel file -se 'replace(join(//tr/normalize-space(),\"#\"),\" \",\"\")'\n\n", "\nYou can try using the graph API to upload files to SharePoint Online.\nPUT /sites/{site-id}/drive/items/{parent-id}:/{filename}:/content\nContent-Type: text/plain\n\nThe contents of the file goes here.\n\n"], "rejected": ["\nThis is with very high likelyhood the website blocking you from outside brazil.\nIf this isnt fixable any other way you can click a cheap VPN like https://mullvad.net/en and install it on the server. I would go with their wireguard option. Make sure to not set the default route via the VPN or your server might become unaccessible. Here is an example config:\n[Interface]\n# you need this\nPrivateKey = secret-private-key-here\n# and this - you can remove the ipv6 address or leave it in, doesnt rly matter if you only use it to access one server\nAddress = your-private-internal-vpn-ipv4-here,your-private-internal-ipv6-here\n# REMOVE THIS!!\n#DNS = 100.61.0.24\n# REMOVE THIS TOO (if its in your config)\n#PostUp = iptables -I OUTPUT ! -o %i -m mark ! --mark $(wg show %i fwmark) -m addrtype ! --dst-type LOCAL -j REJECT && ip6tables -I OUTPUT ! -o %i -m mark ! --mark $(wg show %i fwmark) -m addrtype ! --dst-type LOCAL -j REJECT\n#PreDown = iptables -D OUTPUT ! -o %i -m mark ! --mark $(wg show %i fwmark) -m addrtype ! --dst-type LOCAL -j REJECT && ip6tables -D OUTPUT ! -o %i -m mark ! --mark $(wg show %i fwmark) -m addrtype ! --dst-type LOCAL -j REJECT\n\n[Peer]\n# You need this\nPublicKey = mullvad-wireguard-public-key-here\n# CHANGE THIS\nAllowedIPs = 0.0.0.0/0,::0/0\n# This would set your default route (route to 0.0.0.0/0) to the wireguard server. You don't want to use it by default, only for specific hosts:\n# Here you only define the IP you want to access. For stackoverflow.com:\n# user@host:~$ host -t A stackoverflow.com\n# stackoverflow.com has address 172.64.155.249\n# stackoverflow.com has address 104.18.32.7\n# you would write:\nAllowedIPs = 172.64.155.249/32,104.18.32.7/32\n\nInstalling that:\nsudo apt install wireguard-tools\nsudo editor /etc/wireguard/mullvad.conf\n\nThen to test if it works:\nsudo apt install tmux\ntmux\n# then inside the tmux\nsudo systemctl start [email\u00a0protected]; sleep 10; sudo systemctl stop [email\u00a0protected]\n\nIf you dont loose the connection to the server you're all set. If you do it will be back after 10 seconds. If it goes offline, paste your VPN config here (but redact private information!).\nYou can then enable the wireguard service to start on (re)boot:\nsudo systemctl enable [email\u00a0protected]\n\nNow your server will go over the mullvad VPN if it is accessing the IP you defined.\n", "\nchange your DNS to 0.0.0.0 and push!\n", "\nchange your DNS to 0.0.0.0 and push!\n", "\nchange your DNS to 0.0.0.0 and push!\n", "\nchange your DNS to 0.0.0.0 and push!\n", "\nchange your DNS to 0.0.0.0 and push!\n", "\nchange your DNS to 0.0.0.0 and push!\n", "\nSplit the command into words like the shell would.\nrest_api_address = ...\ncommmand = [\"curl\",\n            \"--insecure\", \"POST\",\n            \"--form\", \"file1=@path_to_file\",\n            \"--form\", \"file2=@path_to_file2\",\n            \"--form\", \"config={...}\",\n            rest_api_address]\n\np = Popen(command, ...)\n\nThe single quotes were for the benefit of the shell; they are not necessary when bypassing the shell as we do here.\n", "\nFirst of all this is a anti-pattern. Containers are meant to be stateless and not change after they are deployed.\nThe reason why you can't run apt-get is because you are running your container with an unprivileged user as you can tell by the \"$\" sign in your command prompt. Also sudo is not installed and thus not usable.\nIf you really want to have curl in your container you have a couple of options:\n\nExtend your docker image, and install curl at build time rather than at run time\nRun your container as root and install curl from an interactive session as you tried to do (discouraged).\n\nExample of the first approach, the one I suggest you to use, involves a Dockerfile like the following:\nFROM the-image-name-you-are-currently-using\n\nRUN apt-get update; apt-get install -y curl\n\nYou then need to build this new image with (from the same directory where your Dockerfile is):\ndocker build -t your-new-image-name:version .\n\nAfter you pushed the image to a registry with docker push you can update your Pod to use your-new-image-name:version as image.\n", "\nErrm... Shouldn't you have either a docker ENTRYPOINT or docker CMD instruction somewhere in your docker file? How did it decide /docker-entrypoint.sh was your entrypoint, and where do you copy that file into the container?\nIn any case, for the exec() system call to be able to execute a shell script it needs (a) to have the x bit set. i.e. chmod +x docker-entrypoint.sh. (b) it needs to have #!/bin/bash (or whatever shell) at the beginning. That error would indicate that it probably doesn't.\n", "\nUse both -k and -s results in wall of text output. You need to suppress stdout as:\n    curl -sk <url>  1>/dev/null\n", "\ntry\n--upload-file \"Subject: The files you requested\\n $PROCESS_LOG\"\n", "\ntry\n--upload-file \"Subject: The files you requested\\n $PROCESS_LOG\"\n", "\nContent in .sh file\n      output=$(curl -s -v https://<websiteURL>/Login --stderr -)\n      echo \"My output----------------------------------------------------\"\n      echo $output\n\n", "\nContent in .sh file\n      output=$(curl -s -v https://<websiteURL>/Login --stderr -)\n      echo \"My output----------------------------------------------------\"\n      echo $output\n\n", "\nContent in .sh file\n      output=$(curl -s -v https://<websiteURL>/Login --stderr -)\n      echo \"My output----------------------------------------------------\"\n      echo $output\n\n", "\nContent in .sh file\n      output=$(curl -s -v https://<websiteURL>/Login --stderr -)\n      echo \"My output----------------------------------------------------\"\n      echo $output\n\n", "\nCould be a firewall issue.\nTry:\nufw allow out 53\nreboot\n\n", "\nCould be a firewall issue.\nTry:\nufw allow out 53\nreboot\n\n", "\nCould be a firewall issue.\nTry:\nufw allow out 53\nreboot\n\n", "\nCould be a firewall issue.\nTry:\nufw allow out 53\nreboot\n\n", "\nCould be a firewall issue.\nTry:\nufw allow out 53\nreboot\n\n", "\nCould be a firewall issue.\nTry:\nufw allow out 53\nreboot\n\n", "\nCould be a firewall issue.\nTry:\nufw allow out 53\nreboot\n\n", "\nCould be a firewall issue.\nTry:\nufw allow out 53\nreboot\n\n", "\nCould be a firewall issue.\nTry:\nufw allow out 53\nreboot\n\n", "\nI have a repository called maven-local, and uploaded an ear file called test.ear under the path com/test/jfrog.\nWe can use the below curl command directly to download the file:\ncurl -u \"user:password\" -X GET https://myartifactory.jfrog.io/artifactory/maven-local/com/test/jfrog/test-test.ear -H 'Content-Type:application/json' -o test.ear\n\n", "\nYou can use xmllint in HTML mode and an XPath expression to extract the contents of the table cells, and then massage it into the desired format:\n$\u00a0xmllint --html --xpath '//div[@class=\"container\"]/table/tr/td/text()' input.html | perl -0777 -pe 's/:\\s+/: /g; s/^\\s+//mg'\nExaminer: Person\nQualification: Teacher\nNation: Any\n\n", "\nYou can use xmllint in HTML mode and an XPath expression to extract the contents of the table cells, and then massage it into the desired format:\n$\u00a0xmllint --html --xpath '//div[@class=\"container\"]/table/tr/td/text()' input.html | perl -0777 -pe 's/:\\s+/: /g; s/^\\s+//mg'\nExaminer: Person\nQualification: Teacher\nNation: Any\n\n", "\nYou can use xmllint in HTML mode and an XPath expression to extract the contents of the table cells, and then massage it into the desired format:\n$\u00a0xmllint --html --xpath '//div[@class=\"container\"]/table/tr/td/text()' input.html | perl -0777 -pe 's/:\\s+/: /g; s/^\\s+//mg'\nExaminer: Person\nQualification: Teacher\nNation: Any\n\n", "\nYou can use xmllint in HTML mode and an XPath expression to extract the contents of the table cells, and then massage it into the desired format:\n$\u00a0xmllint --html --xpath '//div[@class=\"container\"]/table/tr/td/text()' input.html | perl -0777 -pe 's/:\\s+/: /g; s/^\\s+//mg'\nExaminer: Person\nQualification: Teacher\nNation: Any\n\n", "\nI found out I was using the CURL command wrong, I needed to use the -F option to specify I was using an actual file on the machine.\nOnce I included the -F option, it worked\ncurl -F \"[email\u00a0protected]\" \"https://tenant.sharepoint.com/teams/testSite/_api/web/GetFolderByServerRelativeUrl('%20Shared%20Documents')/Files/add(url='a.txt',overwrite=true)\" -H \"Authorization: Bearer $(cat token.txt)\" -H \"accept: application/json\"\n\n"]}