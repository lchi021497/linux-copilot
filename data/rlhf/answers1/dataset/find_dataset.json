{"prompt": ["The path structure of the files on my server is similar to that shown below,/home/sun/sdir1/mp4/file.mp4\n/home/sun/collection/sdir2/mp4/file.mp4I would like to move the files of \"mp4\"  into one level up(into sdir1 and sdir2 respectively)So the output should be,/home/sun/sdir1/file.mp4\n/home/sun/collection/sdir2/file.mp4\nI have no idea to do this, so not tried yet anything...\n", "The path structure of the files on my server is similar to that shown below,/home/sun/sdir1/mp4/file.mp4\n/home/sun/collection/sdir2/mp4/file.mp4I would like to move the files of \"mp4\"  into one level up(into sdir1 and sdir2 respectively)So the output should be,/home/sun/sdir1/file.mp4\n/home/sun/collection/sdir2/file.mp4\nI have no idea to do this, so not tried yet anything...\n", "The path structure of the files on my server is similar to that shown below,/home/sun/sdir1/mp4/file.mp4\n/home/sun/collection/sdir2/mp4/file.mp4I would like to move the files of \"mp4\"  into one level up(into sdir1 and sdir2 respectively)So the output should be,/home/sun/sdir1/file.mp4\n/home/sun/collection/sdir2/file.mp4\nI have no idea to do this, so not tried yet anything...\n", "I have the following directory tree:Inside the \"all\" folder there are a lot of subfolder, let's call one of them \"mainfolder\".What I want to do is:\nto delete all files in the mainfolder which are older than 2 minutes other than mainfolder/.ssh folder (and what is inside) and the .sync file\nI have the following find command:find all/* -mindepth 1 ! \\( -name \".sync\" -o -type d,f -path all'/*/.ssh' -o -type d,f -path all'/*/.ssh/*' \\) -mmin +2 -delete >/dev/null\nIt works so far, but the mainfolder/test/.ssh folder and the included files (file5 and .file6) won't be deleted:How can I solve this?", "I have the following directory tree:Inside the \"all\" folder there are a lot of subfolder, let's call one of them \"mainfolder\".What I want to do is:\nto delete all files in the mainfolder which are older than 2 minutes other than mainfolder/.ssh folder (and what is inside) and the .sync file\nI have the following find command:find all/* -mindepth 1 ! \\( -name \".sync\" -o -type d,f -path all'/*/.ssh' -o -type d,f -path all'/*/.ssh/*' \\) -mmin +2 -delete >/dev/null\nIt works so far, but the mainfolder/test/.ssh folder and the included files (file5 and .file6) won't be deleted:How can I solve this?", "I have the following directory tree:Inside the \"all\" folder there are a lot of subfolder, let's call one of them \"mainfolder\".What I want to do is:\nto delete all files in the mainfolder which are older than 2 minutes other than mainfolder/.ssh folder (and what is inside) and the .sync file\nI have the following find command:find all/* -mindepth 1 ! \\( -name \".sync\" -o -type d,f -path all'/*/.ssh' -o -type d,f -path all'/*/.ssh/*' \\) -mmin +2 -delete >/dev/null\nIt works so far, but the mainfolder/test/.ssh folder and the included files (file5 and .file6) won't be deleted:How can I solve this?", "I need a bash command that searches the directory \"rawdata\" for all subdirectories with names starting with \"AB\", searches all these for the subdirectory \"demo\" and within all \"demo\" directories all subdirectories with a name consisting of just numbers. From all these I need the name of the file that has \".txt\" as an extension. The command always has to look just one depth and not search deeper... I tried to write all the found filenames in \"test.txt\" but my code didn't work right.My approach:find rawdata/AB* -type d -name 'demo' -exec find {} -mindepth 1 -maxdepth 1 -type d -regex '.*/[0-9]+' -exec find {} -mindepth 1 -maxdepth 1 -type f -name \"*.txt\" {} \\; | awk -F/ '{print $NF}' > test.txt\nI got error messages like this:\u2018rawdata/AB.../q.../A.../demultiplexed\u2019: No such file or directory\nwhich for me is a proof that it does not first search for demo, because it took the subdirectory q... Further on it didn't take a folder with a number as name!A correct path should look like this: \u2018rawdata/AB.../demo/123/hereAndJustInThisLevelHereIsTheSearchedFile.txt\u2019\nSo on every first directory level there must be the order \"rawdata\", on the second level it should just check the directories whose names start with \"AB\", in the third level there is just one \"demo\" and it should check just this and in the fourth level it must check just all directories that have a number as folder name!I already tried some other similar code versions but none of them gave me the right result.", "I need a bash command that searches the directory \"rawdata\" for all subdirectories with names starting with \"AB\", searches all these for the subdirectory \"demo\" and within all \"demo\" directories all subdirectories with a name consisting of just numbers. From all these I need the name of the file that has \".txt\" as an extension. The command always has to look just one depth and not search deeper... I tried to write all the found filenames in \"test.txt\" but my code didn't work right.My approach:find rawdata/AB* -type d -name 'demo' -exec find {} -mindepth 1 -maxdepth 1 -type d -regex '.*/[0-9]+' -exec find {} -mindepth 1 -maxdepth 1 -type f -name \"*.txt\" {} \\; | awk -F/ '{print $NF}' > test.txt\nI got error messages like this:\u2018rawdata/AB.../q.../A.../demultiplexed\u2019: No such file or directory\nwhich for me is a proof that it does not first search for demo, because it took the subdirectory q... Further on it didn't take a folder with a number as name!A correct path should look like this: \u2018rawdata/AB.../demo/123/hereAndJustInThisLevelHereIsTheSearchedFile.txt\u2019\nSo on every first directory level there must be the order \"rawdata\", on the second level it should just check the directories whose names start with \"AB\", in the third level there is just one \"demo\" and it should check just this and in the fourth level it must check just all directories that have a number as folder name!I already tried some other similar code versions but none of them gave me the right result.", "So I have this command line that works.find . -type f |xargs ls -lS |head -20\nThe thing is I only want the output to be the file size and the name. I tried:find . -type f -printf '%s %p\\n' |xargs ls -lS |head -20\nbut this gives me a bunch of 'cannot access [inode], no such file or directory' errors. My goal is to print the biggest 20 files in the directory, not using ls.", "So I have this command line that works.find . -type f |xargs ls -lS |head -20\nThe thing is I only want the output to be the file size and the name. I tried:find . -type f -printf '%s %p\\n' |xargs ls -lS |head -20\nbut this gives me a bunch of 'cannot access [inode], no such file or directory' errors. My goal is to print the biggest 20 files in the directory, not using ls.", "So I have this command line that works.find . -type f |xargs ls -lS |head -20\nThe thing is I only want the output to be the file size and the name. I tried:find . -type f -printf '%s %p\\n' |xargs ls -lS |head -20\nbut this gives me a bunch of 'cannot access [inode], no such file or directory' errors. My goal is to print the biggest 20 files in the directory, not using ls.", "So I have this command line that works.find . -type f |xargs ls -lS |head -20\nThe thing is I only want the output to be the file size and the name. I tried:find . -type f -printf '%s %p\\n' |xargs ls -lS |head -20\nbut this gives me a bunch of 'cannot access [inode], no such file or directory' errors. My goal is to print the biggest 20 files in the directory, not using ls.", "I would like to find out which of my files in a directory are dos text files (as opposed to unix text files). Specifically, these are files that, when opened in Vim, the bottom bar will say something like \"filename.php\" [dos] [noeol]I've tried find . -name \"*.php\" | xargs grep ^M -l, but I don't get reliable results. In particular, it doesn't detect certain dos files that don't have ^M characters in them.Is there a better alternative?", "I would like to find out which of my files in a directory are dos text files (as opposed to unix text files). Specifically, these are files that, when opened in Vim, the bottom bar will say something like \"filename.php\" [dos] [noeol]I've tried find . -name \"*.php\" | xargs grep ^M -l, but I don't get reliable results. In particular, it doesn't detect certain dos files that don't have ^M characters in them.Is there a better alternative?", "I would like to find out which of my files in a directory are dos text files (as opposed to unix text files). Specifically, these are files that, when opened in Vim, the bottom bar will say something like \"filename.php\" [dos] [noeol]I've tried find . -name \"*.php\" | xargs grep ^M -l, but I don't get reliable results. In particular, it doesn't detect certain dos files that don't have ^M characters in them.Is there a better alternative?", "I would like to find out which of my files in a directory are dos text files (as opposed to unix text files). Specifically, these are files that, when opened in Vim, the bottom bar will say something like \"filename.php\" [dos] [noeol]I've tried find . -name \"*.php\" | xargs grep ^M -l, but I don't get reliable results. In particular, it doesn't detect certain dos files that don't have ^M characters in them.Is there a better alternative?", "I would like to find out which of my files in a directory are dos text files (as opposed to unix text files). Specifically, these are files that, when opened in Vim, the bottom bar will say something like \"filename.php\" [dos] [noeol]I've tried find . -name \"*.php\" | xargs grep ^M -l, but I don't get reliable results. In particular, it doesn't detect certain dos files that don't have ^M characters in them.Is there a better alternative?", "I would like to find out which of my files in a directory are dos text files (as opposed to unix text files). Specifically, these are files that, when opened in Vim, the bottom bar will say something like \"filename.php\" [dos] [noeol]I've tried find . -name \"*.php\" | xargs grep ^M -l, but I don't get reliable results. In particular, it doesn't detect certain dos files that don't have ^M characters in them.Is there a better alternative?", "I would like to find out which of my files in a directory are dos text files (as opposed to unix text files). Specifically, these are files that, when opened in Vim, the bottom bar will say something like \"filename.php\" [dos] [noeol]I've tried find . -name \"*.php\" | xargs grep ^M -l, but I don't get reliable results. In particular, it doesn't detect certain dos files that don't have ^M characters in them.Is there a better alternative?", "I needed to find all the files that contained a specific string pattern. The first solution that comes to mind is using find piped with xargs grep:find . -iname '*.py' | xargs grep -e 'YOUR_PATTERN'\nBut if I need to find patterns that spans on more than one line, I'm stuck because vanilla grep can't find multiline patterns.", "I needed to find all the files that contained a specific string pattern. The first solution that comes to mind is using find piped with xargs grep:find . -iname '*.py' | xargs grep -e 'YOUR_PATTERN'\nBut if I need to find patterns that spans on more than one line, I'm stuck because vanilla grep can't find multiline patterns.", "I needed to find all the files that contained a specific string pattern. The first solution that comes to mind is using find piped with xargs grep:find . -iname '*.py' | xargs grep -e 'YOUR_PATTERN'\nBut if I need to find patterns that spans on more than one line, I'm stuck because vanilla grep can't find multiline patterns.", "I needed to find all the files that contained a specific string pattern. The first solution that comes to mind is using find piped with xargs grep:find . -iname '*.py' | xargs grep -e 'YOUR_PATTERN'\nBut if I need to find patterns that spans on more than one line, I'm stuck because vanilla grep can't find multiline patterns.", "I needed to find all the files that contained a specific string pattern. The first solution that comes to mind is using find piped with xargs grep:find . -iname '*.py' | xargs grep -e 'YOUR_PATTERN'\nBut if I need to find patterns that spans on more than one line, I'm stuck because vanilla grep can't find multiline patterns.", "I needed to find all the files that contained a specific string pattern. The first solution that comes to mind is using find piped with xargs grep:find . -iname '*.py' | xargs grep -e 'YOUR_PATTERN'\nBut if I need to find patterns that spans on more than one line, I'm stuck because vanilla grep can't find multiline patterns.", "I needed to find all the files that contained a specific string pattern. The first solution that comes to mind is using find piped with xargs grep:find . -iname '*.py' | xargs grep -e 'YOUR_PATTERN'\nBut if I need to find patterns that spans on more than one line, I'm stuck because vanilla grep can't find multiline patterns.", "I needed to find all the files that contained a specific string pattern. The first solution that comes to mind is using find piped with xargs grep:find . -iname '*.py' | xargs grep -e 'YOUR_PATTERN'\nBut if I need to find patterns that spans on more than one line, I'm stuck because vanilla grep can't find multiline patterns.", "I needed to find all the files that contained a specific string pattern. The first solution that comes to mind is using find piped with xargs grep:find . -iname '*.py' | xargs grep -e 'YOUR_PATTERN'\nBut if I need to find patterns that spans on more than one line, I'm stuck because vanilla grep can't find multiline patterns.", "I needed to find all the files that contained a specific string pattern. The first solution that comes to mind is using find piped with xargs grep:find . -iname '*.py' | xargs grep -e 'YOUR_PATTERN'\nBut if I need to find patterns that spans on more than one line, I'm stuck because vanilla grep can't find multiline patterns.", "I needed to find all the files that contained a specific string pattern. The first solution that comes to mind is using find piped with xargs grep:find . -iname '*.py' | xargs grep -e 'YOUR_PATTERN'\nBut if I need to find patterns that spans on more than one line, I'm stuck because vanilla grep can't find multiline patterns.", "I needed to find all the files that contained a specific string pattern. The first solution that comes to mind is using find piped with xargs grep:find . -iname '*.py' | xargs grep -e 'YOUR_PATTERN'\nBut if I need to find patterns that spans on more than one line, I'm stuck because vanilla grep can't find multiline patterns.", "I am new to linux. I have a directory in linux with approx 250,000 files\nI need to find count of number of files matching a pattern.I tried using following command :ls -1 20061101-20131101_kh5x7tte9n_2010_* | wc -l\nI got the following error message:-bash: /bin/ls: Argument list too long\n0\nPlease help. Thanks in advance", "I am new to linux. I have a directory in linux with approx 250,000 files\nI need to find count of number of files matching a pattern.I tried using following command :ls -1 20061101-20131101_kh5x7tte9n_2010_* | wc -l\nI got the following error message:-bash: /bin/ls: Argument list too long\n0\nPlease help. Thanks in advance", "I am new to linux. I have a directory in linux with approx 250,000 files\nI need to find count of number of files matching a pattern.I tried using following command :ls -1 20061101-20131101_kh5x7tte9n_2010_* | wc -l\nI got the following error message:-bash: /bin/ls: Argument list too long\n0\nPlease help. Thanks in advance", "I am new to linux. I have a directory in linux with approx 250,000 files\nI need to find count of number of files matching a pattern.I tried using following command :ls -1 20061101-20131101_kh5x7tte9n_2010_* | wc -l\nI got the following error message:-bash: /bin/ls: Argument list too long\n0\nPlease help. Thanks in advance", "I am new to linux. I have a directory in linux with approx 250,000 files\nI need to find count of number of files matching a pattern.I tried using following command :ls -1 20061101-20131101_kh5x7tte9n_2010_* | wc -l\nI got the following error message:-bash: /bin/ls: Argument list too long\n0\nPlease help. Thanks in advance", "I am new to linux. I have a directory in linux with approx 250,000 files\nI need to find count of number of files matching a pattern.I tried using following command :ls -1 20061101-20131101_kh5x7tte9n_2010_* | wc -l\nI got the following error message:-bash: /bin/ls: Argument list too long\n0\nPlease help. Thanks in advance", "I am new to linux. I have a directory in linux with approx 250,000 files\nI need to find count of number of files matching a pattern.I tried using following command :ls -1 20061101-20131101_kh5x7tte9n_2010_* | wc -l\nI got the following error message:-bash: /bin/ls: Argument list too long\n0\nPlease help. Thanks in advance", "I am tracking some big files with git annex. I usually do:find . -type f -size +10M | xargs -r git annex add\nThe problem is that find encounters the big files in the .git directory:find . -type f -size +10M\nOutput:./.git/annex/objects/47/fx/SHA256E-s1208418304--5bca6a4c23b7c92976076e1a2490e81a6181301c86d2c2737840bb5b50a285d1.vmdk/SHA256E-s1208418304--5bca6a4c23b7c92976076e1a2490e81a6181301c86d2c2737840bb5b50a285d1.vmdk\n./.git/annex/objects/ZZ/Q5/SHA256E-s3262054400--63bc227c3247ed9dfcb41d5ed20b887cf0ba2ef207dfae0ba95160efcbc89581.vmdk/SHA256E-s3262054400--63bc227c3247ed9dfcb41d5ed20b887cf0ba2ef207dfae0ba95160efcbc89581.vmdk\n./.git/annex/objects/zj/mK/SHA256E-s6072303616--efdb32d49d31557a84f66fdb9871e24b63aa97b19956f050e2516cf392cd2467.vdi/SHA256E-s6072303616--efdb32d49d31557a84f66fdb9871e24b63aa97b19956f050e2516cf392cd2467.vdi\nAnd git annex tries to readd them.How can I tell 'find' to ignore (prune) the files in the .git directory, while still filtering for big files (+10M)? I am unable to construct the right command.", "Why does the following does not copy the files to the destination folder?# find /home/shantanu/processed/ -name '*2011*.xml' -exec cp /home/shantanu/tosend {} \\;\n\ncp: omitting directory `/home/shantanu/tosend'\ncp: omitting directory `/home/shantanu/tosend'\ncp: omitting directory `/home/shantanu/tosend'\n", "Why does the following does not copy the files to the destination folder?# find /home/shantanu/processed/ -name '*2011*.xml' -exec cp /home/shantanu/tosend {} \\;\n\ncp: omitting directory `/home/shantanu/tosend'\ncp: omitting directory `/home/shantanu/tosend'\ncp: omitting directory `/home/shantanu/tosend'\n", "Why does the following does not copy the files to the destination folder?# find /home/shantanu/processed/ -name '*2011*.xml' -exec cp /home/shantanu/tosend {} \\;\n\ncp: omitting directory `/home/shantanu/tosend'\ncp: omitting directory `/home/shantanu/tosend'\ncp: omitting directory `/home/shantanu/tosend'\n", "Why does the following does not copy the files to the destination folder?# find /home/shantanu/processed/ -name '*2011*.xml' -exec cp /home/shantanu/tosend {} \\;\n\ncp: omitting directory `/home/shantanu/tosend'\ncp: omitting directory `/home/shantanu/tosend'\ncp: omitting directory `/home/shantanu/tosend'\n"], "chosen": ["\nThere are different ways to solve your problem\n\nIf you just want to move those specific files, run these commands:\ncd /home/sun/\nmv sdir1/mp4/file.mp4 sdir1/\nmv sdir2/mp4/file.mp4 sdir2/\n\nIf you want to move all mp4 files on those directories (sdir1 and sdir2), run these commands:\ncd /home/sun/\nmv sdir1/mp4/*.mp4 sdir1/\nmv sdir2/mp4/*.mp4 sdir2/\n\n\nEdit:\n\nMake a script that iterates all the directories:\n\nCreate a script and name it and edit it with your favorite editor (nano, vim, gedit, ...):\ngedit folderIterator.sh\n\nThe script file content is:\n#/bin/bash\n\n# Go to the desired directory\ncd /home/sun/\n\n# Do an action over all the subdirectories in the folder\nfor dir in /home/sun/*/\ndo\n    dir=${dir%*/}\n    mv \"$dir\"/mp4/*.mp4 \"$dir\"/\n\n    # If you want to remove the subdirectory after moving the files, uncomment the following line\n    # rm -rf \"$dir\"\ndone\n\nSave the file and give it execute permissions:\nchmod +x folderIterator.sh\n\nAnd execute it:\n./folderIterator.sh\n\n", "\nYou can do this:\n# move all .mp4 files from sdir1/mp4 to sdir1 directory\nuser@host:~/home/sun$ mv sdir1/mp4/*.mp4 sdir/\n\n# move all .mp4 files from collection/sdir2/mp4 to collection/sdir2 directory\nuser@host:~/home/sun$ mv collection/sdir2/mp4/*.mp4 collection/sdir2/\n\n# move only 1 file\nuser@host:~/home/sun$ mv sdir1/mp4/file.mp4 sdir/\nuser@host:~/home/sun$ mv collection/sdir2/mp4/file.mp4 collection/sdir2/\n\n", "\nI suggest you use find and something like\ncd /home/sun/sdir1/mp4/\nfind . -name \"*\" -exec mv {} /home/sun/sdir1/ \\;\ncd /home/sun/collection/sdir2/mp4/\nfind . -name \"*\" -exec mv {} /home/sun/collection/sdir2/ \\;\n\nAlternatively, you could use tar and something like\ncd /home/sun/sdir1/mp4/\ntar cfp - * | (cd ../ ; tar xvvf -)\n# Make sure everything looks good\nrm -rf mp4\ncd /home/sun/collection/sdir2/mp4/\ntar cfp - * | (cd ../ ; tar xvvf -)\n# Make sure everything looks good\nrm -rf mp4\n\n", "\nOne possible way to do what you want is to use Bash pathname expansion (aka globbing) to exclude files and directories and find to process the unexcluded paths.  Try this Shellcheck-clean Bash code:\n#! /bin/bash -p\n\nshopt -s dotglob extglob nullglob\n\nfind all/*/!(.sync|.ssh) -type f -mmin +2 -print\n\n\nshopt -s ... enables some Bash settings that are required by the code:\n\ndotglob enables globs to match files and directories that begin with ..  find processes such files by default.\nextglob enables \"extended globbing\" (including patterns like !(.sync|.ssh)).  See the extglob section in glob - Greg's Wiki.\nnullglob makes globs expand to nothing when nothing matches (otherwise they expand to the glob pattern itself, which is almost never useful in programs).\n\n\nAdd -delete to the find options if you are happy that it will delete only the files that you want deleted.\n\n", "\nAs-is I get:\nfind: cannot delete \u2018all/mainfolder/test\u2019: Directory not empty\n\nReplacing -delete with -exec rm -fr {} + works, though when test is >2m it's removed, regardless of age of files under it.\n-prune doesn't work with -delete, so doesn't help by itself. Note that as jhnc mentioned, slashes do not delimit the glob in -path 'all/*/.ssh', so the * matches all/mainfolder/test/.ssh as well - that's probably your issue. This might not be a one-liner; consider a script.\nExpanding a bit on jhnc's regex-based idea, I'd recommend doing it in a couple of passes.\nStarting with your example file structure -\n$: find all\nall/\nall/mainfolder/\nall/mainfolder/.file2\nall/mainfolder/.ssh/\nall/mainfolder/.ssh/authorized_keys\nall/mainfolder/.ssh/id_rsa\nall/mainfolder/.ssh/id_rsa.pub\nall/mainfolder/.sync\nall/mainfolder/file1\nall/mainfolder/test/\nall/mainfolder/test/.file4\nall/mainfolder/test/.ssh/\nall/mainfolder/test/.ssh/.file6\nall/mainfolder/test/.ssh/file5\nall/mainfolder/test/file3\n\nI substituted in an -exec rm {} + for the -delete, which allows us to use -prune to skip files and directories. Borrowing jhnc's -regex prevents -path from ignoring slash delimiters, so it avoids an arbitrary depth issue.\nI set -type f on this pass so that directories older than 2m won't be deleted even if files in them don't match, which would eliminate files it shouldn't. That also saves us from having to use a -recursive option to rm for some added safety (for the same reason). For this example we didn't need the -mindepth so I removed it.\n$: find all -mmin +2 -type f -regextype awk \\( -regex 'all/[^/]+/\\.(ssh.*|sync)' -prune -o -exec rm {} + \\)\n\n$: find all\nall\nall/mainfolder\nall/mainfolder/.ssh\nall/mainfolder/.ssh/authorized_keys\nall/mainfolder/.ssh/id_rsa\nall/mainfolder/.ssh/id_rsa.pub\nall/mainfolder/.sync\nall/mainfolder/test\nall/mainfolder/test/.ssh\n\nThis still leaves some empty directories, so to clean those up in a quick second pass:\n$: find all -empty -type d -delete\n\n$: find all\nall\nall/mainfolder\nall/mainfolder/.ssh\nall/mainfolder/.ssh/authorized_keys\nall/mainfolder/.ssh/id_rsa\nall/mainfolder/.ssh/id_rsa.pub\nall/mainfolder/.sync\n\nI think that leaves the result you wanted.\nPlease backup and/or test before running it locally.\nI recommend using echo and \\; instead of + for testing, as you can see the files better;\n$: find all -mmin +2 -type f \\( -regextype awk -regex 'all/[^/]+/\\.(ssh.*|sync)' -prune -o -exec echo rm {} \\; \\)\nrm all/mainfolder/.file2\nrm all/mainfolder/file1\nrm all/mainfolder/test/.file4\nrm all/mainfolder/test/.ssh/.file6\nrm all/mainfolder/test/.ssh/file5\nrm all/mainfolder/test/file3\n\nThe + is a lot more efficient for a live run, so if the actual filesystem is bigger it's probably worth switching it back.\n$: find all -mmin +2 -type f \\( -regextype awk -regex 'all/[^/]+/\\.(ssh.*|sync)' -prune -o -exec echo rm {} + \\)\nrm all/mainfolder/.file2 all/mainfolder/file1 all/mainfolder/test/.file4 all/mainfolder/test/.ssh/.file6 all/mainfolder/test/.ssh/file5 all/mainfolder/test/file3\n\nGood luck.\n", "\nPer your specification:\n\nkeep ./all/mainfolder/.ssh and its content\nkeep ./all/mainfolder/.sync\ndelete other files (not directories) that are older than 2 minutes\n\nYou can try:\nfind ./all/mainfolder -type f ! -path './all/mainfolder/.ssh/*' \\\n  ! -path ./all/mainfolder/.sync -mmin +2 -delete\n\nOr, if your find is GNU find:\nfind ./all/mainfolder -type f ! -regex '\\./all/mainfolder/\\.\\(ssh/.*\\|sync\\)' \\\n  -mmin +2 -delete\n\nIf you want to delete files and directories:\nfind ./all/mainfolder -mindepth 1 ! -path ./all/mainfolder/.ssh \\\n  ! -path './all/mainfolder/.ssh/*' ! -path ./all/mainfolder/.sync -mmin +2 \\\n  -print0 | xargs -0 rm -rf\n\nOr, if your find is GNU find:\nfind ./all/mainfolder ! -regex '\\./all/mainfolder\\(/\\.\\(ssh\\(/.*\\)?\\|sync\\)\\)?' \\\n  -mmin +2 -print0 | xargs -0 rm -rf\n\n", "\n\nI need a bash command that searches into folder \"rawdata\"\n\nfind 'rawdata' -maxdepth 1\n\n\nall subfolders names starting with \"AB\",\n\nfind 'rawdata' -maxdepth 1 -type d -name 'AB*'\n\n\nsearches in all this orders the\nsubfolder \"demo\"\n\nwhile IFS= read -r dir1; do\n    find \"$dir1\" -maxdepth 1 -type d -name 'demo'\ndone < <(find 'rawdata' -type d -name 'AB*')\n\n\nand in the \"demo\" folder all subfolders with a name\nconsisting of just numbers.\n\nwhile IFS= read -r dir1; do\n    while IFS= read -r dir2; do\n        find \"$dir2\" -maxdepth 1 -type d -regex '.*/[0-9]+$'\n    done < <(find \"$dir1\" -maxdepth 1 -type d -name 'demo')\ndone < <(find 'rawdata' -maxdepth 1 -type d -name 'AB*')\n\n\nFrom all this folders that are named with\na number I need the name of the file that hat \".txt\" as ending.\n\nwhile IFS= read -r dir1; do\n    while IFS= read -r dir2; do\n        while IFS= read -r dir3; do\n            find \"$dir3\" -maxdepth 1 -type f -name '*.txt'\n        done < <(find \"$dir2\" -maxdepth 1 -type d -regex '.*/[0-9]*$')\n    done < <(find \"$dir1\" -maxdepth 1 -type d -name 'demo')\ndone < <(find 'rawdata' -maxdepth 1 -type d -name 'AB*')\n\nAlternatively you could just do:\nshopt -s extglob\nprintf '%s\\n' rawdata/AB*/demo/+([0-9])/*.txt\n\nSince printf is a builtin that won't fail if there's a large number of files like other tools would if the combination of the number of files and length of their names exceeded ARG_MAX.\nFor example, given this directory structure:\n$ mkdir -p rawdata/ABx/demo/17/\n$ mkdir -p rawdata/ABy/demo/235\n$ > rawdata/ABx/demo/17/foo.txt\n$ > rawdata/ABx/demo/17/bar.txt\n$ > rawdata/ABy/demo/235/whatever.txt\n\nto get the full paths to the files:\n$ while IFS= read -r dir1; do\n    while IFS= read -r dir2; do\n        while IFS= read -r dir3; do\n            find \"$dir3\" -maxdepth 1 -type f -name '*.txt'\n        done < <(find \"$dir2\" -maxdepth 1 -type d -regex '.*/[0-9]*$')\n    done < <(find \"$dir1\" -maxdepth 1 -type d -name 'demo')\ndone < <(find 'rawdata' -maxdepth 1 -type d -name 'AB*')\nrawdata/ABx/demo/17/bar.txt\nrawdata/ABx/demo/17/foo.txt\nrawdata/ABy/demo/235/whatever.txt\n\n$ shopt -s extglob\n$ printf '%s\\n' rawdata/AB*/demo/+([0-9])/*.txt\nrawdata/ABx/demo/17/bar.txt\nrawdata/ABx/demo/17/foo.txt\nrawdata/ABy/demo/235/whatever.txt\n\nor to just get the names of the files:\n$ while IFS= read -r dir1; do\n    while IFS= read -r dir2; do\n        while IFS= read -r dir3; do\n            find \"$dir3\" -maxdepth 1 -type f -name '*.txt' -printf '%P\\n'\n        done < <(find \"$dir2\" -maxdepth 1 -type d -regex '.*/[0-9]*$')\n    done < <(find \"$dir1\" -maxdepth 1 -type d -name 'demo')\ndone < <(find 'rawdata' -maxdepth 1 -type d -name 'AB*')\nbar.txt\nfoo.txt\nwhatever.txt\n\n$ shopt -s extglob\n$ printf '%s\\n' rawdata/AB*/demo/+([0-9])/*.txt | sed 's:.*/::'\nbar.txt\nfoo.txt\nwhatever.txt\n\nThe above assumes that none of your file or directory names contain newlines.\n", "\nI still think that this simple find should do the trick.\nfind -regex './rawdata/AB.*/demo/[0-9]+/.*\\.txt'|awk -F/ '{print $NF}' > test.txt\n\n", "\nAn answer without ls involved:\nfind . -type f -printf '%k %p\\n' |sort -n |tail -n 20\n\nThis gives each file, listed with the size (in kB), a space, then the file name, sorted numerically, and then you get the last 20 items (the 20 largest).\nYour problem was in piping to ls.\nIf you've got a really big directory structure, sort will fall over. If you already know the ballpark size and that most files are much smaller, you can tell find to rule out smaller sizes with an additional option, e.g. find . -type f -size +2M -printf \u2026 which prunes out anything under 2MiB. Otherwise, you'd have to use some custom code that stores only the largest 20 items.\n", "\nUse following commmand to get size of the fiule in linux. \ndu -h <<FileName>>\n\nOr\ndu -h <<FilePath>>\n\n", "\nIn the question, you state:\n\nMy goal is to print the biggest 20 files in the directory, not using ls.\n\nThis implies that an acceptable solution should not use ls.\nAnother issue is the use of xargs.  A construction like find . -type f | xargs ls will not work with subdirectory or file names containing white space, since it will split the string from find before giving it to ls.  You can protect the string or work around this using null terminated strings, such as find . -type f -print0 | xargs -0 ls.  In general, there are security considerations for using xargs.  Rather than verifying if your xargs construction is safe, it's easier to avoid using it altogether (especially if you don't need it).\nTry printing the 20 biggest files without ls and without xargs:\n    find . -type f -printf '%s %p\\n' | sort -rn | head -20\n\n", "\nfind . -type f |xargs ls -lS |head -20 | awk '{print $9, $5}'\nSince the output of ls is columnar, just print the proper columns and you're done.\n", "\nNot sure what you mean exactly by \"not reliable\" but you may want to try:\nfind . -name '*.php' -print0 | xargs -0 grep -l '^M$'\n\nThis uses the more atrocious-filenames-with-spaces-in-them-friendly options and only finds carriage returns immediately before the end of line.\nKeep in mind that the ^M is a single CTRLM character, not two characters.\nAnd also that it'll list files where even one line is in DOS mode, which is probably what you want anyway since those would have been UNIX files mangled by a non-UNIX editor.\n\nBased on your update that vim is reporting your files as DOS format:\nIf vim is reporting it as DOS format, then every line ends with CRLF. That's the way vim works. If even one line doesn't have CR, then it's considered UNIX format and the ^M characters are visible in the buffer. If it's all DOS format, the ^M characters are not displayed:\n\nVim will look for both dos and unix line endings, but Vim has a built-in preference for the unix format.\n\n  - If all lines in the file end with CRLF, the dos file format will be applied, meaning that each CRLF is removed when reading the lines into a buffer, and the buffer 'ff' option will be dos.\n  - If one or more lines end with LF only, the unix file format will be applied, meaning that each LF is removed (but each CR will be present in the buffer, and will display as ^M), and the buffer 'ff' option will be unix. \n\nIf you really want to know what's in the file, don't rely on a too-smart tool like vim :-)\nUse:\nod -xcb input_file_name | less\n\nand check the line endings yourself.\n", "\nHow about:\nfind . -name \"*.php\" | xargs file | grep \"CRLF\"\n\nI don't think it is reliable to try and use ^M to try and find the files.\n", "\ni had good luck with\nfind . -name \"*.php\" -exec grep -Pl \"\\r\" {} \\;\n\n", "\nThis is much like your original solution; therefore, it's possibly more easy for you to remember:\nfind . -name \"*.php\" | xargs grep \"\\r\" -l\n\nThought process:\nIn VIM, to remove the ^M you type:\n %s:/^M//g\n\nWhere ^ is your Ctrl key and M is the ENTER key.  But I could never remember the keys to type to print that sequence, so I've always removed them using:\n %s:/\\r//g\n\nSo my deduction is that the \\r and ^M are equivalent, with the former being easier to remember to type.\n", "\nIf your dos2unix command has the -i option, you can use that feature to find files in a directory that have DOS line breaks.\n$ man dos2unix\n.\n.\n.\n     -i[FLAGS], --info[=FLAGS] FILE ...\n           Display file information. No conversion is done.\n\n    The following information is printed, in this order:\n    number of DOS line breaks,\n    number of Unix line breaks,\n    number of Mac line breaks,\n    byte order mark,\n    text or binary, file name.\n.\n.\n.\nOptionally extra flags can be set to change the (-i) output.\n.\n.\n.\n           c   Print only the files that would be converted.\n\nThe following one-liner script reads:\n\nfind all files in this directory tree,\nrun dos2unix on all files to determine the files to be changed,\nrun dos2unix on files to be changed\n\n$ find . -type f | xargs -d '\\n' dos2unix -ic | xargs -d '\\n' dos2unix\n", "\nI've been using cat -e to see what line endings files have.\nUsing ^M as a single CTRLM character didn't really work out for me (it works as if I just press return, without actually inserting the non-printable ^M line ending \u2014\u00a0tested with echo 'CTRLM' | cat -e), so what I ended up doing will probably seem too much, but it did the job nevertheless:\ngrep '$' *.php | cat -e | grep '\\^M\\$' | sed 's/:.*//' | uniq\n\n, where\n\nthe first grep just prepends filenames to each line of each file (can be replaced with awk '{print FILENAME, $0}', but grep worked faster on my set of files);\ncat -e explicitly prints non-printable line endings;\nthe second grep finds lines ending with ^M$, and ^M are two characters;\nthe sed part keeps only the file names (can be replaced with cut -d ':' -f 1);\nuniq just keeps each file name once.\n\n", "\nGNU find\nfind . -type f -iname \"*.php\"  -exec file \"{}\" + | grep CRLF\n\nI don't know what you want to do after you find those DOS php files, but if you want to convert them to unix format, then \nfind . -type f -iname \"*.php\"  -exec dos2unix \"{}\" +;\n\nwill suffice. There's no need to specifically check whether they are DOS files or not.\n", "\nHere is the example using GNU grep:\ngrep -Pzo '_name.*\\n.*_description'\n\n\n-z/--null-data Treat the input as a set of lines, each terminated by a zero byte (the ASCII NUL character) instead of a newline.\n\nWhich has the effect of treating the whole file as one large line.\nSee -z description on grep's manual and also common question no 14 on grep's manual usage page\n", "\nWhy don't you go for awk:\nawk '/Start pattern/,/End pattern/' filename\n\n", "\nSo I discovered pcregrep which stands for Perl Compatible Regular Expressions GREP.\n\nthe -M option makes it possible to search for patterns that span line boundaries.\n\nFor example, you need to find files where the '_name' variable is followed on the next line by the '_description' variable:\nfind . -iname '*.py' | xargs pcregrep -M '_name.*\\n.*_description'\n\nTip: you need to include the line break character in your pattern. Depending on your platform, it could be '\\n', \\r', '\\r\\n', ...\n", "\ngrep -P also uses libpcre, but is much more widely installed. To find a complete title section of an html document, even if it spans multiple lines, you can use this:\ngrep -P '(?s)<title>.*</title>' example.html\n\nSince the PCRE project implements to the perl standard, use the perl documentation for reference:\n\nhttp://perldoc.perl.org/perlre.html#Modifiers\nhttp://perldoc.perl.org/perlre.html#Extended-Patterns\n\n", "\nHere is a more useful example:\npcregrep -Mi \"<title>(.*\\n){0,5}</title>\" afile.html\n\nIt searches the title tag in a html file even if it spans up to 5 lines.\nHere is an example of unlimited lines:\npcregrep -Mi \"(?s)<title>.*</title>\" example.html \n\n", "\nWith silver searcher:\nag 'abc.*(\\n|.)*efg'\n\nSpeed optimizations of silver searcher could possibly shine here.\n", "\nThis answer might be useful:\nRegex (grep) for multi-line search needed\nTo find recursively you can use flags -R (recursive) and --include (GLOB pattern). See:\nUse grep --exclude/--include syntax to not grep through certain files\n", "\n@Marcin:\nawk example non-greedy:\nawk '{if ($0 ~ /Start pattern/) {triggered=1;}if (triggered) {print; if ($0 ~ /End pattern/) { exit;}}}' filename\n\n", "\nYou can use the grep alternative sift here (disclaimer: I am the author).\nIt support multiline matching and limiting the search to specific file types out of the box:\nsift -m --files '*.py' 'YOUR_PATTERN'\n\n(search all *.py files for the specified multiline regex pattern)\nIt is available for all major operating systems. Take a look at the samples page to see how it can be used to  to extract multiline values from an XML file.\n", "\nperl -ne 'print if (/begin pattern/../end pattern/)' filename\n\n", "\nUsing ex/vi editor and globstar option (syntax similar to awk and sed):\nex +\"/string1/,/string3/p\" -R -scq! file.txt\n\nwhere aaa is your starting point, and bbb is your ending text.\nTo search recursively, try:\nex +\"/aaa/,/bbb/p\" -scq! **/*.py\n\nNote: To enable ** syntax, run shopt -s globstar (Bash 4 or zsh).\n", "\nI believe the following should work and has the advantage of only using extended regular expressions without the need to install an extra tool like pcregrep if you don\u2019t have it yet or don\u2019t have the -P option to grep available (eg. macOS):\negrep -irzo \u201c.*aaa(.*\\s.*){1,}.*bbb.*\" path_to_filenames\nCaveat emptor: this does some slight disadvantages:\n\nit will find the largest selection of lines from the first aaa to the last bbb in each file, unless...\nthere are several repetitions of the aaa [stuff] bbb pattern in each file.\n\n", "\nyou got \"argument too long\" because shell expands your pattern to the list of files. \ntry:\nfind  -maxdepth 1 -name '20061101-20131101_kh5x7tte9n_2010_*' |wc -l\n\nplease pay attention - pattern is enclosed in quotes to prevent shell expansion\n", "\nIt might be better to use find for this:\nfind . -name \"pattern_*\" -printf '.' | wc -m\n\nIn your specific case:\nfind . -maxdepth 1 -name \"20061101-20131101_kh5x7tte9n_2010_*\" -printf '.' | wc -m\n\nfind will return a list of files matching the criteria. -maxdepth 1 will make the search to be done just in the path, no subdirectories (thanks Petesh!). -printf '.' will print a dot for every match, so that names with new lines won't make wc -m break.\nThen wc -m will indicate the number of characters which will match the number of files.\n\nPerformance comparation of two possible options:\nLet's create 10 000 files with this pattern:\n$ for i in {1..10000}; do touch 20061101-20131101_kh5x7tte9n_201_$i; done\n\nAnd then compare the time it takes to get the result with ls -1 ... or find ...:\n$ time find . -maxdepth 1 -name \"20061101-20131101_kh5x7tte9n_201_*\" | wc -m\n10000\n\nreal    0m0.034s\nuser    0m0.017s\nsys     0m0.021s\n\n$ time ls -1 | grep 20061101-20131101_kh5x7tte9n_201 | wc -m\n10000\n\nreal    0m0.254s\nuser    0m0.245s\nsys     0m0.020s\n\nfind is x5 times faster! But if we use ls -1f (thanks Petesh again!), then ls is even faster than find:\n$ time ls -1f | grep 20061101-20131101_kh5x7tte9n_201 | wc -m\n10000\n\nreal    0m0.023s\nuser    0m0.020s\nsys     0m0.012s\n\n", "\nJust do:\nfind . -name \"pattern_*\" |wc -l\n\n", "\nThe MacOS / OS X command line solution\nIf you are attempting to do this in the command line on a Mac you will soon find out that find does not support the -printf option.\nTo accomplish the same result as the solution proposed by fedorqui-supports-monica try this:\nfind . -name \"pattern_*\" -exec stat -f \".\" {} \\; | wc -l\n\nThis will find all files matching the pattern you entered, print a . for each of them in a newline, then finally count the number of lines and output that number.\n\nTo limit your search depth to the current directory, add -maxdepth 1 to the command like so:\nfind . -maxdepth 1 -name \"196288.*\" -exec stat -f \".\" {} \\; | wc -l\n\n", "\nTry this:\nls -1 | grep 20061101-20131101_kh5x7tte9n_2010_ | wc -l\n\n", "\nYou should generally avoid ls in scripts and in fact, performing the calculation in a shell function will avoid the \"argument list too long\" error because there is no exec boundary and so the ARGV_MAX limit doesn't come into play.\nnumber_of_files () {\n    if [ -e \"$1\" ]; then\n        echo \"$#\"\n    else\n        echo 0\n    fi\n}\n\nThe conditional guards against the glob not being expanded at all (which is the default out of the box; in Bash, you can shopt -s nullglob to make wildcards which don't match any files get expanded into the empty string).\nTry it:\nnumber_of_files 20061101-20131101_kh5x7tte9n_2010_*\n\n", "\nFirst of all it is better not to use ls according to this article !!!\nand this problem can be solved in many ways. I will list some of the most elegant ones that come to my mind.\ncount=$(printf '%s\\n' *pattern* | wc -l) \n#or\ncount=$(shopt -s nullglob; files=(*pattern*); echo ${#files[@]})\n#or\ncount=$(file *pattern* | wc -l)\n#or\ncount=$(stat -c \"%n\" *pattern* | wc -l)\n#or\ncount=$(du -a *pattern* | wc -l)\n#or\ncount=$(echo *pattern* | wc -w)\n\nbut last one gives the wrong number when the file names contain whitespace.\n", "\nfind . -type f -size +10M -not -path \"./.git/*\" should do the trick\n", "\ni faced an issue something like this...\nActually, in two ways you can process find command output in copy command\n\nIf find command's output doesn't contain any space i.e if file name doesn't contain space in it then you can use below mentioned command:\nSyntax: find <Path> <Conditions> | xargs cp -t <copy file path>\nExample: find -mtime -1 -type f | xargs cp -t inner/\nBut most of the time our production data files might contain space in it. So most of time below mentioned command is safer:\nSyntax: find <path> <condition> -exec cp '{}' <copy path> \\;\nExample find -mtime -1 -type f -exec cp '{}' inner/ \\;\n\nIn the second example, last part i.e semi-colon is also considered as part of find command, that should be escaped before press the enter button. Otherwise you will get an error something like this\nfind: missing argument to `-exec'\n\nIn your case, copy command syntax is wrong in order to copy find file into /home/shantanu/tosend.  The following command will work:\nfind /home/shantanu/processed/ -name '*2011*.xml' -exec cp  {} /home/shantanu/tosend \\;\n\n", "\nIf your intent is to copy the found files into /home/shantanu/tosend, you have the order of the arguments to cp reversed:\nfind /home/shantanu/processed/ -name '*2011*.xml' -exec cp \"{}\" /home/shantanu/tosend  \\;\n\nPlease note: the find command uses {} as placeholder for the matched file.\n", "\nYou need to use cp -t /home/shantanu/tosend in order to tell it that the argument is the target directory and not a source. You can then change it to -exec ... + in order to get cp to copy as many files as possible at once.\n", "\nThe reason for that error is that you are trying to copy a folder which requires -r option also to cp\nThanks\n"], "rejected": ["\nThe command to move a file (or directory) up one level is:\nmv /home/sun/sdir1/mp4/file.mp4 ..\n\nWildcards can be used to select more files & directories, you can also provide more than one directory at a time.\nmv /home/sun/sdir1/mp4/*.mp4 /home/sun/collection/sdir2/mp4/*.mp4 ..\n\n", "\nThe command to move a file (or directory) up one level is:\nmv /home/sun/sdir1/mp4/file.mp4 ..\n\nWildcards can be used to select more files & directories, you can also provide more than one directory at a time.\nmv /home/sun/sdir1/mp4/*.mp4 /home/sun/collection/sdir2/mp4/*.mp4 ..\n\n", "\nThe command to move a file (or directory) up one level is:\nmv /home/sun/sdir1/mp4/file.mp4 ..\n\nWildcards can be used to select more files & directories, you can also provide more than one directory at a time.\nmv /home/sun/sdir1/mp4/*.mp4 /home/sun/collection/sdir2/mp4/*.mp4 ..\n\n", "\n* does not treat / specially.\nOne possibility is to double each test:\nfind all \\\n    -mindepth 2 \\\n    \\( \\\n        -path 'all/*/.ssh' ! -path 'all/*/*/.ssh' -prune \\\n        -o \\\n        -path 'all/*/.sync' ! -path 'all/*/*/.sync' -prune \\\n        -o \\\n        ...\n    \\)\n\nIf you are using GNU grep, it may have -regex:\nfind all \\\n    -mindepth 2 \\\n    \\( \\\n        -regextype awk \\\n        -regex 'all/[^/]+/\\.(ssh|sync)' -prune \\\n        -o \\\n        ...\n    \\)\n\n", "\n* does not treat / specially.\nOne possibility is to double each test:\nfind all \\\n    -mindepth 2 \\\n    \\( \\\n        -path 'all/*/.ssh' ! -path 'all/*/*/.ssh' -prune \\\n        -o \\\n        -path 'all/*/.sync' ! -path 'all/*/*/.sync' -prune \\\n        -o \\\n        ...\n    \\)\n\nIf you are using GNU grep, it may have -regex:\nfind all \\\n    -mindepth 2 \\\n    \\( \\\n        -regextype awk \\\n        -regex 'all/[^/]+/\\.(ssh|sync)' -prune \\\n        -o \\\n        ...\n    \\)\n\n", "\n* does not treat / specially.\nOne possibility is to double each test:\nfind all \\\n    -mindepth 2 \\\n    \\( \\\n        -path 'all/*/.ssh' ! -path 'all/*/*/.ssh' -prune \\\n        -o \\\n        -path 'all/*/.sync' ! -path 'all/*/*/.sync' -prune \\\n        -o \\\n        ...\n    \\)\n\nIf you are using GNU grep, it may have -regex:\nfind all \\\n    -mindepth 2 \\\n    \\( \\\n        -regextype awk \\\n        -regex 'all/[^/]+/\\.(ssh|sync)' -prune \\\n        -o \\\n        ...\n    \\)\n\n", "\nThis Shellcheck-clean code demonstrates a possible way to do what you want with pure POSIX shell:\n#! /bin/sh -\n\nfor txtfile in rawdata/AB*/demo/*/*.txt; do\n    case $txtfile in\n        rawdata/AB*/demo/*[!0-9]*/*.txt) : ;;\n        *) [ -f \"$txtfile\" ] && printf '%s\\n' \"${txtfile##*/}\" ;;\n    esac\ndone\n\n\nSee the Pattern Matching Notation section of the POSIX Shell Command Language document for an explanation of the rawdata/AB*/demo/*/*.txt and rawdata/AB*/demo/*[!0-9]*/*.txt patterns.\nrawdata/AB*/demo/*[!0-9]*/*.txt) : ;; causes files in level 3 subdirectories that contain non-numeric characters to be skipped.\nSee the Parameter Expansion section of the POSIX Shell Command Language document for an explanation of ${txtfile##*/}.\nThis code works with Bash, but if it will always be run with Bash then it would be better (shorter, clearer) to use the extglob feature to match numeric directory names.\n\n", "\nThis Shellcheck-clean code demonstrates a possible way to do what you want with pure POSIX shell:\n#! /bin/sh -\n\nfor txtfile in rawdata/AB*/demo/*/*.txt; do\n    case $txtfile in\n        rawdata/AB*/demo/*[!0-9]*/*.txt) : ;;\n        *) [ -f \"$txtfile\" ] && printf '%s\\n' \"${txtfile##*/}\" ;;\n    esac\ndone\n\n\nSee the Pattern Matching Notation section of the POSIX Shell Command Language document for an explanation of the rawdata/AB*/demo/*/*.txt and rawdata/AB*/demo/*[!0-9]*/*.txt patterns.\nrawdata/AB*/demo/*[!0-9]*/*.txt) : ;; causes files in level 3 subdirectories that contain non-numeric characters to be skipped.\nSee the Parameter Expansion section of the POSIX Shell Command Language document for an explanation of ${txtfile##*/}.\nThis code works with Bash, but if it will always be run with Bash then it would be better (shorter, clearer) to use the extglob feature to match numeric directory names.\n\n", "\nxargs takes each line of output from the previous command and basically slaps at the end of its arguments, so your find is printing something like\n123 ./somefile.txt \n\nwhich xargs turns into\nls -lS 123 ./somefile.txt\n\nunless you actually have a file named 123 in that directory, you get your \"cannot access\" error:\nmarc@panic:~$ touch foo\nmarc@panic:~$ ls -lS file_that_does_not_exist foo\nls: cannot access file_that_does_not_exist: No such file or directory\n-rw-rw-r-- 1 marc marc 0 Feb  3 14:26 foo\n\n", "\nxargs takes each line of output from the previous command and basically slaps at the end of its arguments, so your find is printing something like\n123 ./somefile.txt \n\nwhich xargs turns into\nls -lS 123 ./somefile.txt\n\nunless you actually have a file named 123 in that directory, you get your \"cannot access\" error:\nmarc@panic:~$ touch foo\nmarc@panic:~$ ls -lS file_that_does_not_exist foo\nls: cannot access file_that_does_not_exist: No such file or directory\n-rw-rw-r-- 1 marc marc 0 Feb  3 14:26 foo\n\n", "\nxargs takes each line of output from the previous command and basically slaps at the end of its arguments, so your find is printing something like\n123 ./somefile.txt \n\nwhich xargs turns into\nls -lS 123 ./somefile.txt\n\nunless you actually have a file named 123 in that directory, you get your \"cannot access\" error:\nmarc@panic:~$ touch foo\nmarc@panic:~$ ls -lS file_that_does_not_exist foo\nls: cannot access file_that_does_not_exist: No such file or directory\n-rw-rw-r-- 1 marc marc 0 Feb  3 14:26 foo\n\n", "\nxargs takes each line of output from the previous command and basically slaps at the end of its arguments, so your find is printing something like\n123 ./somefile.txt \n\nwhich xargs turns into\nls -lS 123 ./somefile.txt\n\nunless you actually have a file named 123 in that directory, you get your \"cannot access\" error:\nmarc@panic:~$ touch foo\nmarc@panic:~$ ls -lS file_that_does_not_exist foo\nls: cannot access file_that_does_not_exist: No such file or directory\n-rw-rw-r-- 1 marc marc 0 Feb  3 14:26 foo\n\n", "\nIf you prefer vim to tell you which files are in this format you can use the following script:\n\"use this script to check which files are in dos format according to vim\n\"use: in the folder that you want to check\n\"create a file, say res.txt\n\"> vim -u NONE --noplugins res.txt\n\"> in vim: source this_script.vim\n\npython << EOF\nimport os\nimport vim\n\ncur_buf =  vim.current.buffer\n\nIGNORE_START = ''.split()\nIGNORE_END = '.pyc .swp .png ~'.split()\n\nIGNORE_DIRS = '.hg .git dd_ .bzr'.split()\n\nfor dirpath, dirnames, fnames in os.walk(os.curdir):\n  for dirn in dirnames:\n    for diri in IGNORE_DIRS:\n      if dirn.endswith(diri):\n        dirnames.remove(dirn)\n        break\n  for fname in fnames:\n    skip = False\n    for fstart in IGNORE_START:\n      if fname.startswith(fstart):\n        skip = True\n    for fend in IGNORE_END:\n      if fname.endswith(fend):\n        skip = True\n    if skip is True:\n      continue\n    fname = os.path.join(dirpath, fname)\n    vim.command('view {}'.format(fname))\n    curr_ff = vim.eval('&ff')\n    if vim.current.buffer != cur_buf:\n      vim.command('bw!')\n    if curr_ff == 'dos':\n      cur_buf.append('{} {}'.format(curr_ff, fname))\nEOF\n\nyour vim needs to be compiled with python (python is used to loop over the files in the folder, there is probably an easier way of doing this, but I don't really know it....\n", "\nIf you prefer vim to tell you which files are in this format you can use the following script:\n\"use this script to check which files are in dos format according to vim\n\"use: in the folder that you want to check\n\"create a file, say res.txt\n\"> vim -u NONE --noplugins res.txt\n\"> in vim: source this_script.vim\n\npython << EOF\nimport os\nimport vim\n\ncur_buf =  vim.current.buffer\n\nIGNORE_START = ''.split()\nIGNORE_END = '.pyc .swp .png ~'.split()\n\nIGNORE_DIRS = '.hg .git dd_ .bzr'.split()\n\nfor dirpath, dirnames, fnames in os.walk(os.curdir):\n  for dirn in dirnames:\n    for diri in IGNORE_DIRS:\n      if dirn.endswith(diri):\n        dirnames.remove(dirn)\n        break\n  for fname in fnames:\n    skip = False\n    for fstart in IGNORE_START:\n      if fname.startswith(fstart):\n        skip = True\n    for fend in IGNORE_END:\n      if fname.endswith(fend):\n        skip = True\n    if skip is True:\n      continue\n    fname = os.path.join(dirpath, fname)\n    vim.command('view {}'.format(fname))\n    curr_ff = vim.eval('&ff')\n    if vim.current.buffer != cur_buf:\n      vim.command('bw!')\n    if curr_ff == 'dos':\n      cur_buf.append('{} {}'.format(curr_ff, fname))\nEOF\n\nyour vim needs to be compiled with python (python is used to loop over the files in the folder, there is probably an easier way of doing this, but I don't really know it....\n", "\nIf you prefer vim to tell you which files are in this format you can use the following script:\n\"use this script to check which files are in dos format according to vim\n\"use: in the folder that you want to check\n\"create a file, say res.txt\n\"> vim -u NONE --noplugins res.txt\n\"> in vim: source this_script.vim\n\npython << EOF\nimport os\nimport vim\n\ncur_buf =  vim.current.buffer\n\nIGNORE_START = ''.split()\nIGNORE_END = '.pyc .swp .png ~'.split()\n\nIGNORE_DIRS = '.hg .git dd_ .bzr'.split()\n\nfor dirpath, dirnames, fnames in os.walk(os.curdir):\n  for dirn in dirnames:\n    for diri in IGNORE_DIRS:\n      if dirn.endswith(diri):\n        dirnames.remove(dirn)\n        break\n  for fname in fnames:\n    skip = False\n    for fstart in IGNORE_START:\n      if fname.startswith(fstart):\n        skip = True\n    for fend in IGNORE_END:\n      if fname.endswith(fend):\n        skip = True\n    if skip is True:\n      continue\n    fname = os.path.join(dirpath, fname)\n    vim.command('view {}'.format(fname))\n    curr_ff = vim.eval('&ff')\n    if vim.current.buffer != cur_buf:\n      vim.command('bw!')\n    if curr_ff == 'dos':\n      cur_buf.append('{} {}'.format(curr_ff, fname))\nEOF\n\nyour vim needs to be compiled with python (python is used to loop over the files in the folder, there is probably an easier way of doing this, but I don't really know it....\n", "\nIf you prefer vim to tell you which files are in this format you can use the following script:\n\"use this script to check which files are in dos format according to vim\n\"use: in the folder that you want to check\n\"create a file, say res.txt\n\"> vim -u NONE --noplugins res.txt\n\"> in vim: source this_script.vim\n\npython << EOF\nimport os\nimport vim\n\ncur_buf =  vim.current.buffer\n\nIGNORE_START = ''.split()\nIGNORE_END = '.pyc .swp .png ~'.split()\n\nIGNORE_DIRS = '.hg .git dd_ .bzr'.split()\n\nfor dirpath, dirnames, fnames in os.walk(os.curdir):\n  for dirn in dirnames:\n    for diri in IGNORE_DIRS:\n      if dirn.endswith(diri):\n        dirnames.remove(dirn)\n        break\n  for fname in fnames:\n    skip = False\n    for fstart in IGNORE_START:\n      if fname.startswith(fstart):\n        skip = True\n    for fend in IGNORE_END:\n      if fname.endswith(fend):\n        skip = True\n    if skip is True:\n      continue\n    fname = os.path.join(dirpath, fname)\n    vim.command('view {}'.format(fname))\n    curr_ff = vim.eval('&ff')\n    if vim.current.buffer != cur_buf:\n      vim.command('bw!')\n    if curr_ff == 'dos':\n      cur_buf.append('{} {}'.format(curr_ff, fname))\nEOF\n\nyour vim needs to be compiled with python (python is used to loop over the files in the folder, there is probably an easier way of doing this, but I don't really know it....\n", "\nIf you prefer vim to tell you which files are in this format you can use the following script:\n\"use this script to check which files are in dos format according to vim\n\"use: in the folder that you want to check\n\"create a file, say res.txt\n\"> vim -u NONE --noplugins res.txt\n\"> in vim: source this_script.vim\n\npython << EOF\nimport os\nimport vim\n\ncur_buf =  vim.current.buffer\n\nIGNORE_START = ''.split()\nIGNORE_END = '.pyc .swp .png ~'.split()\n\nIGNORE_DIRS = '.hg .git dd_ .bzr'.split()\n\nfor dirpath, dirnames, fnames in os.walk(os.curdir):\n  for dirn in dirnames:\n    for diri in IGNORE_DIRS:\n      if dirn.endswith(diri):\n        dirnames.remove(dirn)\n        break\n  for fname in fnames:\n    skip = False\n    for fstart in IGNORE_START:\n      if fname.startswith(fstart):\n        skip = True\n    for fend in IGNORE_END:\n      if fname.endswith(fend):\n        skip = True\n    if skip is True:\n      continue\n    fname = os.path.join(dirpath, fname)\n    vim.command('view {}'.format(fname))\n    curr_ff = vim.eval('&ff')\n    if vim.current.buffer != cur_buf:\n      vim.command('bw!')\n    if curr_ff == 'dos':\n      cur_buf.append('{} {}'.format(curr_ff, fname))\nEOF\n\nyour vim needs to be compiled with python (python is used to loop over the files in the folder, there is probably an easier way of doing this, but I don't really know it....\n", "\nIf you prefer vim to tell you which files are in this format you can use the following script:\n\"use this script to check which files are in dos format according to vim\n\"use: in the folder that you want to check\n\"create a file, say res.txt\n\"> vim -u NONE --noplugins res.txt\n\"> in vim: source this_script.vim\n\npython << EOF\nimport os\nimport vim\n\ncur_buf =  vim.current.buffer\n\nIGNORE_START = ''.split()\nIGNORE_END = '.pyc .swp .png ~'.split()\n\nIGNORE_DIRS = '.hg .git dd_ .bzr'.split()\n\nfor dirpath, dirnames, fnames in os.walk(os.curdir):\n  for dirn in dirnames:\n    for diri in IGNORE_DIRS:\n      if dirn.endswith(diri):\n        dirnames.remove(dirn)\n        break\n  for fname in fnames:\n    skip = False\n    for fstart in IGNORE_START:\n      if fname.startswith(fstart):\n        skip = True\n    for fend in IGNORE_END:\n      if fname.endswith(fend):\n        skip = True\n    if skip is True:\n      continue\n    fname = os.path.join(dirpath, fname)\n    vim.command('view {}'.format(fname))\n    curr_ff = vim.eval('&ff')\n    if vim.current.buffer != cur_buf:\n      vim.command('bw!')\n    if curr_ff == 'dos':\n      cur_buf.append('{} {}'.format(curr_ff, fname))\nEOF\n\nyour vim needs to be compiled with python (python is used to loop over the files in the folder, there is probably an easier way of doing this, but I don't really know it....\n", "\nIf you prefer vim to tell you which files are in this format you can use the following script:\n\"use this script to check which files are in dos format according to vim\n\"use: in the folder that you want to check\n\"create a file, say res.txt\n\"> vim -u NONE --noplugins res.txt\n\"> in vim: source this_script.vim\n\npython << EOF\nimport os\nimport vim\n\ncur_buf =  vim.current.buffer\n\nIGNORE_START = ''.split()\nIGNORE_END = '.pyc .swp .png ~'.split()\n\nIGNORE_DIRS = '.hg .git dd_ .bzr'.split()\n\nfor dirpath, dirnames, fnames in os.walk(os.curdir):\n  for dirn in dirnames:\n    for diri in IGNORE_DIRS:\n      if dirn.endswith(diri):\n        dirnames.remove(dirn)\n        break\n  for fname in fnames:\n    skip = False\n    for fstart in IGNORE_START:\n      if fname.startswith(fstart):\n        skip = True\n    for fend in IGNORE_END:\n      if fname.endswith(fend):\n        skip = True\n    if skip is True:\n      continue\n    fname = os.path.join(dirpath, fname)\n    vim.command('view {}'.format(fname))\n    curr_ff = vim.eval('&ff')\n    if vim.current.buffer != cur_buf:\n      vim.command('bw!')\n    if curr_ff == 'dos':\n      cur_buf.append('{} {}'.format(curr_ff, fname))\nEOF\n\nyour vim needs to be compiled with python (python is used to loop over the files in the folder, there is probably an easier way of doing this, but I don't really know it....\n", "\nAs Amit's answer earlier, you can use awk to search for multiple lines. In case you need to print the line number, use the following:\nawk '/Start pattern/,/End pattern/ {print NR \":\" $0}' filename\n\n", "\nAs Amit's answer earlier, you can use awk to search for multiple lines. In case you need to print the line number, use the following:\nawk '/Start pattern/,/End pattern/ {print NR \":\" $0}' filename\n\n", "\nAs Amit's answer earlier, you can use awk to search for multiple lines. In case you need to print the line number, use the following:\nawk '/Start pattern/,/End pattern/ {print NR \":\" $0}' filename\n\n", "\nAs Amit's answer earlier, you can use awk to search for multiple lines. In case you need to print the line number, use the following:\nawk '/Start pattern/,/End pattern/ {print NR \":\" $0}' filename\n\n", "\nAs Amit's answer earlier, you can use awk to search for multiple lines. In case you need to print the line number, use the following:\nawk '/Start pattern/,/End pattern/ {print NR \":\" $0}' filename\n\n", "\nAs Amit's answer earlier, you can use awk to search for multiple lines. In case you need to print the line number, use the following:\nawk '/Start pattern/,/End pattern/ {print NR \":\" $0}' filename\n\n", "\nAs Amit's answer earlier, you can use awk to search for multiple lines. In case you need to print the line number, use the following:\nawk '/Start pattern/,/End pattern/ {print NR \":\" $0}' filename\n\n", "\nAs Amit's answer earlier, you can use awk to search for multiple lines. In case you need to print the line number, use the following:\nawk '/Start pattern/,/End pattern/ {print NR \":\" $0}' filename\n\n", "\nAs Amit's answer earlier, you can use awk to search for multiple lines. In case you need to print the line number, use the following:\nawk '/Start pattern/,/End pattern/ {print NR \":\" $0}' filename\n\n", "\nAs Amit's answer earlier, you can use awk to search for multiple lines. In case you need to print the line number, use the following:\nawk '/Start pattern/,/End pattern/ {print NR \":\" $0}' filename\n\n", "\nAs Amit's answer earlier, you can use awk to search for multiple lines. In case you need to print the line number, use the following:\nawk '/Start pattern/,/End pattern/ {print NR \":\" $0}' filename\n\n", "\nAs Amit's answer earlier, you can use awk to search for multiple lines. In case you need to print the line number, use the following:\nawk '/Start pattern/,/End pattern/ {print NR \":\" $0}' filename\n\n", "\nls -1 | grep '20061101-20131101_kh5x7tte9n_2010_*' | wc -l\n\nPrevious answer did not included quotes around search criteria neither * wildcard.\n", "\nls -1 | grep '20061101-20131101_kh5x7tte9n_2010_*' | wc -l\n\nPrevious answer did not included quotes around search criteria neither * wildcard.\n", "\nls -1 | grep '20061101-20131101_kh5x7tte9n_2010_*' | wc -l\n\nPrevious answer did not included quotes around search criteria neither * wildcard.\n", "\nls -1 | grep '20061101-20131101_kh5x7tte9n_2010_*' | wc -l\n\nPrevious answer did not included quotes around search criteria neither * wildcard.\n", "\nls -1 | grep '20061101-20131101_kh5x7tte9n_2010_*' | wc -l\n\nPrevious answer did not included quotes around search criteria neither * wildcard.\n", "\nls -1 | grep '20061101-20131101_kh5x7tte9n_2010_*' | wc -l\n\nPrevious answer did not included quotes around search criteria neither * wildcard.\n", "\nls -1 | grep '20061101-20131101_kh5x7tte9n_2010_*' | wc -l\n\nPrevious answer did not included quotes around search criteria neither * wildcard.\n", "\nRemove .git/ from the descent candidate list.\nfind . -name .git -type d -prune -o -type f -size +10M -print0 | xargs -0 ...\n\n", "\nfor i in $(ls); do cp -r \"$i\" \"$i\"_dev; done;\n\n", "\nfor i in $(ls); do cp -r \"$i\" \"$i\"_dev; done;\n\n", "\nfor i in $(ls); do cp -r \"$i\" \"$i\"_dev; done;\n\n", "\nfor i in $(ls); do cp -r \"$i\" \"$i\"_dev; done;\n\n"]}