{"prompt": ["Due to the Internet connect is poor on customer side, I copied the tar file of my Yocto Project to customer.However, customer met an issue while untar the Yocto Project and run the bitbake command to build project on their PC.Customer got the following build code error: s32v@s32v-vm:~/s32v_15.0/yocto_auto_linux_bsp15.0/build_s32v234evb_release$ bitbake fsl-image-s32v2xx\nERROR:  OE-core's config sanity checker detected a potential misconfiguration.\n  Either fix the cause of this error or at your own risk disable the checker (see sanity.conf).\n  Following is the list of potential problems / advisories:\n\n  Error, TMPDIR has changed location. You need to either move it back to /media/2T_HDD_for_SDK/Amingo/S32V/yocto_auto_linux_bsp15.0/build_s32v234evb_release/tmp or rebuild\n\nSummary: There was 1 ERROR message shown, returning a non-zero exit code.\nI edited /build_s32v234evb_release/tmp/saved_tmpdir file to re-position the tmp directory, this error has pass.However, I got another error while building Kernel, it seems the directory parameter is still wrong... (There is no error while building U-Boot only.)s32v@s32v-vm:~/s32v_15.0/yocto_auto_linux_bsp15.0/build_s32v234evb_release$ bitbake fsl-image-s32v2xx\nLoading cache: 100% |########################################################################################################################################################################| ETA:  00:00:00\nLoaded 2462 entries from dependency cache.\nNOTE: Resolving any missing task queue dependencies\n\nBuild Configuration:\nBB_VERSION        = \"1.26.0\"\nBUILD_SYS         = \"x86_64-linux\"\nNATIVELSBSTRING   = \"Ubuntu-14.04\"\nTARGET_SYS        = \"aarch64-fsl-linux\"\nMACHINE           = \"s32v234evb\"\nDISTRO            = \"fsl-networking\"\nDISTRO_VERSION    = \"1.8\"\nTUNE_FEATURES     = \"aarch64\"\nTARGET_FPU        = \"\"\nmeta              \nmeta-yocto        \nmeta-yocto-bsp    = \"(nobranch):03b0fbcf6b3b5cd16ae16738fbaabd1c6bf98536\"\nmeta-fsl-arm      = \"(nobranch):c9f259a4bf8472dfa3ff75f1c3fcbe5e0ded7aaf\"\nmeta-fsl-networking = \"(nobranch):b8ff02a8d508464a16c84e1d13c155f45aa98cbe\"\nmeta-fsl-toolchain = \"(nobranch):0a235c4bcd4057608ee60b8c898eec9509632b95\"\nmeta-virtualization = \"(nobranch):0277cbcb47db4239d0a4aa3b37c5c6a705070951\"\nmeta-fsl-s32v     = \"<unknown>:<unknown>\"\nmeta-oe           \nmeta-networking   \nmeta-python       \nmeta-webserver    \nmeta-filesystems  = \"(nobranch):c841231b9f327d2d06d19d2ba1324dd86b83617c\"\nmeta-linaro       \nmeta-aarch64      \nmeta-linaro-toolchain = \"(nobranch):5075a82bd510d19617803fb16da2375605225cbb\"\n\nNOTE: Preparing RunQueue\nWARNING: /home/s32v/s32v_15.0/yocto_auto_linux_bsp15.0/meta-fsl-s32v/recipes-kernel/linux/linux-s32v2xx_4.1.26.bb.do_compile is tainted from a forced run\nWARNING: /home/s32v/s32v_15.0/yocto_auto_linux_bsp15.0/meta-fsl-s32v/recipes-bsp/u-boot/u-boot-s32v2xx_2016.01.bb.do_compile is tainted from a forced run\nWARNING: /home/s32v/s32v_15.0/yocto_auto_linux_bsp15.0/meta-fsl-s32v/recipes-bsp/u-boot/u-boot-s32v2xx_2016.01.bb.do_deploy is tainted from a forced run\nNOTE: Executing SetScene Tasks\nNOTE: Executing RunQueue Tasks\nERROR: Function failed: do_compile (log file is located at /home/s32v/s32v_15.0/yocto_auto_linux_bsp15.0/build_s32v234evb_release/tmp/work/s32v234evb-fsl-linux/linux-s32v2xx/4.1.26-r0/temp/log.do_compile.17853)\nERROR: Logfile of failure stored in: /home/s32v/s32v_15.0/yocto_auto_linux_bsp15.0/build_s32v234evb_release/tmp/work/s32v234evb-fsl-linux/linux-s32v2xx/4.1.26-r0/temp/log.do_compile.17853\nLog data follows:\n| DEBUG: Executing shell function do_compile\n| NOTE: make -j 4 Image CC=aarch64-fsl-linux-gcc    --sysroot=/home/s32v/s32v_15.0/yocto_auto_linux_bsp15.0/build_s32v234evb_release/tmp/sysroots/s32v234evb LD=aarch64-fsl-linux-ld.bfd    --sysroot=/home/s32v/s32v_15.0/yocto_auto_linux_bsp15.0/build_s32v234evb_release/tmp/sysroots/s32v234evb\n| make: *** /media/2T_HDD_for_SDK/Amingo/S32V/yocto_auto_linux_bsp15.0/build_s32v234evb_release/tmp/work-shared/s32v234evb/kernel-source: No such file or directory.  Stop.\n| make: *** [__sub-make] Error 2\n| ERROR: oe_runmake failed\n| WARNING: exit code 1 from a shell command.\n| ERROR: Function failed: do_compile (log file is located at /home/s32v/s32v_15.0/yocto_auto_linux_bsp15.0/build_s32v234evb_release/tmp/work/s32v234evb-fsl-linux/linux-s32v2xx/4.1.26-r0/temp/log.do_compile.17853)\nERROR: Task 76 (/home/s32v/s32v_15.0/yocto_auto_linux_bsp15.0/meta-fsl-s32v/recipes-kernel/linux/linux-s32v2xx_4.1.26.bb, do_compile) failed with exit code '1'\nERROR: Function failed: do_compile (log file is located at /home/s32v/s32v_15.0/yocto_auto_linux_bsp15.0/build_s32v234evb_release/tmp/work/x86_64-linux/qemu-native/2.2.0-r1/temp/log.do_compile.17854)\nERROR: Logfile of failure stored in: /home/s32v/s32v_15.0/yocto_auto_linux_bsp15.0/build_s32v234evb_release/tmp/work/x86_64-linux/qemu-native/2.2.0-r1/temp/log.do_compile.17854\nLog data follows:\n| DEBUG: Executing shell function do_compile\n| NOTE: make -j 4\n|   LINK  tests/qemu-iotests/socket_scm_helper\n|   GEN   qemu-doc.html\n|   GEN   qemu.1\n|   CC    qga/commands.o\n| cc1: warning: /media/2T_HDD_for_SDK/Amingo/S32V/yocto_auto_linux_bsp15.0/build_s32v234evb_release/tmp/sysroots/x86_64-linux/usr/include/pixman-1: No such file or directory [enabled by default]\n| cc1: warning: /media/2T_HDD_for_SDK/Amingo/S32V/yocto_auto_linux_bsp15.0/build_s32v234evb_release/tmp/sysroots/x86_64-linux/usr/include/glib-2.0: No such file or directory [enabled by default]\n| cc1: warning: /media/2T_HDD_for_SDK/Amingo/S32V/yocto_auto_linux_bsp15.0/build_s32v234evb_release/tmp/sysroots/x86_64-linux/usr/lib/glib-2.0/include: No such file or directory [enabled by default]\n| /home/s32v/s32v_15.0/yocto_auto_linux_bsp15.0/build_s32v234evb_release/tmp/work/x86_64-linux/qemu-native/2.2.0-r1/qemu-2.2.0/qga/commands.c:13:18: fatal error: glib.h: No such file or directory\n|  #include <glib.h>\n|                   ^\n| compilation terminated.\n| make: *** [qga/commands.o] Error 1\n| make: *** Waiting for unfinished jobs....\n| ERROR: oe_runmake failed\n| WARNING: exit code 1 from a shell command.\n| ERROR: Function failed: do_compile (log file is located at /home/s32v/s32v_15.0/yocto_auto_linux_bsp15.0/build_s32v234evb_release/tmp/work/x86_64-linux/qemu-native/2.2.0-r1/temp/log.do_compile.17854)\nERROR: Task 2849 (virtual:native:/home/s32v/s32v_15.0/yocto_auto_linux_bsp15.0/poky/meta/recipes-devtools/qemu/qemu_2.2.0.bb, do_compile) failed with exit code '1'\nNOTE: Tasks Summary: Attempted 1504 tasks of which 1502 didn't need to be rerun and 2 failed.\nWaiting for 0 running tasks to finish:\n\nSummary: 2 tasks failed:\n  /home/s32v/s32v_15.0/yocto_auto_linux_bsp15.0/meta-fsl-s32v/recipes-kernel/linux/linux-s32v2xx_4.1.26.bb, do_compile\n  virtual:native:/home/s32v/s32v_15.0/yocto_auto_linux_bsp15.0/poky/meta/recipes-devtools/qemu/qemu_2.2.0.bb, do_compile\nSummary: There were 3 WARNING messages shown.\nSummary: There were 2 ERROR messages shown, returning a non-zero exit code.\nMy question is:\nIs it possible to copy the Yocot Project to another PC by tar file?\nWhat configuration / initial files I need to edit except saved_tmpdir file?\nWhich file does Yocto Project define the \"kernel-source\" directory?\nBest Regards,\nWayne Kuo", "Due to the Internet connect is poor on customer side, I copied the tar file of my Yocto Project to customer.However, customer met an issue while untar the Yocto Project and run the bitbake command to build project on their PC.Customer got the following build code error: s32v@s32v-vm:~/s32v_15.0/yocto_auto_linux_bsp15.0/build_s32v234evb_release$ bitbake fsl-image-s32v2xx\nERROR:  OE-core's config sanity checker detected a potential misconfiguration.\n  Either fix the cause of this error or at your own risk disable the checker (see sanity.conf).\n  Following is the list of potential problems / advisories:\n\n  Error, TMPDIR has changed location. You need to either move it back to /media/2T_HDD_for_SDK/Amingo/S32V/yocto_auto_linux_bsp15.0/build_s32v234evb_release/tmp or rebuild\n\nSummary: There was 1 ERROR message shown, returning a non-zero exit code.\nI edited /build_s32v234evb_release/tmp/saved_tmpdir file to re-position the tmp directory, this error has pass.However, I got another error while building Kernel, it seems the directory parameter is still wrong... (There is no error while building U-Boot only.)s32v@s32v-vm:~/s32v_15.0/yocto_auto_linux_bsp15.0/build_s32v234evb_release$ bitbake fsl-image-s32v2xx\nLoading cache: 100% |########################################################################################################################################################################| ETA:  00:00:00\nLoaded 2462 entries from dependency cache.\nNOTE: Resolving any missing task queue dependencies\n\nBuild Configuration:\nBB_VERSION        = \"1.26.0\"\nBUILD_SYS         = \"x86_64-linux\"\nNATIVELSBSTRING   = \"Ubuntu-14.04\"\nTARGET_SYS        = \"aarch64-fsl-linux\"\nMACHINE           = \"s32v234evb\"\nDISTRO            = \"fsl-networking\"\nDISTRO_VERSION    = \"1.8\"\nTUNE_FEATURES     = \"aarch64\"\nTARGET_FPU        = \"\"\nmeta              \nmeta-yocto        \nmeta-yocto-bsp    = \"(nobranch):03b0fbcf6b3b5cd16ae16738fbaabd1c6bf98536\"\nmeta-fsl-arm      = \"(nobranch):c9f259a4bf8472dfa3ff75f1c3fcbe5e0ded7aaf\"\nmeta-fsl-networking = \"(nobranch):b8ff02a8d508464a16c84e1d13c155f45aa98cbe\"\nmeta-fsl-toolchain = \"(nobranch):0a235c4bcd4057608ee60b8c898eec9509632b95\"\nmeta-virtualization = \"(nobranch):0277cbcb47db4239d0a4aa3b37c5c6a705070951\"\nmeta-fsl-s32v     = \"<unknown>:<unknown>\"\nmeta-oe           \nmeta-networking   \nmeta-python       \nmeta-webserver    \nmeta-filesystems  = \"(nobranch):c841231b9f327d2d06d19d2ba1324dd86b83617c\"\nmeta-linaro       \nmeta-aarch64      \nmeta-linaro-toolchain = \"(nobranch):5075a82bd510d19617803fb16da2375605225cbb\"\n\nNOTE: Preparing RunQueue\nWARNING: /home/s32v/s32v_15.0/yocto_auto_linux_bsp15.0/meta-fsl-s32v/recipes-kernel/linux/linux-s32v2xx_4.1.26.bb.do_compile is tainted from a forced run\nWARNING: /home/s32v/s32v_15.0/yocto_auto_linux_bsp15.0/meta-fsl-s32v/recipes-bsp/u-boot/u-boot-s32v2xx_2016.01.bb.do_compile is tainted from a forced run\nWARNING: /home/s32v/s32v_15.0/yocto_auto_linux_bsp15.0/meta-fsl-s32v/recipes-bsp/u-boot/u-boot-s32v2xx_2016.01.bb.do_deploy is tainted from a forced run\nNOTE: Executing SetScene Tasks\nNOTE: Executing RunQueue Tasks\nERROR: Function failed: do_compile (log file is located at /home/s32v/s32v_15.0/yocto_auto_linux_bsp15.0/build_s32v234evb_release/tmp/work/s32v234evb-fsl-linux/linux-s32v2xx/4.1.26-r0/temp/log.do_compile.17853)\nERROR: Logfile of failure stored in: /home/s32v/s32v_15.0/yocto_auto_linux_bsp15.0/build_s32v234evb_release/tmp/work/s32v234evb-fsl-linux/linux-s32v2xx/4.1.26-r0/temp/log.do_compile.17853\nLog data follows:\n| DEBUG: Executing shell function do_compile\n| NOTE: make -j 4 Image CC=aarch64-fsl-linux-gcc    --sysroot=/home/s32v/s32v_15.0/yocto_auto_linux_bsp15.0/build_s32v234evb_release/tmp/sysroots/s32v234evb LD=aarch64-fsl-linux-ld.bfd    --sysroot=/home/s32v/s32v_15.0/yocto_auto_linux_bsp15.0/build_s32v234evb_release/tmp/sysroots/s32v234evb\n| make: *** /media/2T_HDD_for_SDK/Amingo/S32V/yocto_auto_linux_bsp15.0/build_s32v234evb_release/tmp/work-shared/s32v234evb/kernel-source: No such file or directory.  Stop.\n| make: *** [__sub-make] Error 2\n| ERROR: oe_runmake failed\n| WARNING: exit code 1 from a shell command.\n| ERROR: Function failed: do_compile (log file is located at /home/s32v/s32v_15.0/yocto_auto_linux_bsp15.0/build_s32v234evb_release/tmp/work/s32v234evb-fsl-linux/linux-s32v2xx/4.1.26-r0/temp/log.do_compile.17853)\nERROR: Task 76 (/home/s32v/s32v_15.0/yocto_auto_linux_bsp15.0/meta-fsl-s32v/recipes-kernel/linux/linux-s32v2xx_4.1.26.bb, do_compile) failed with exit code '1'\nERROR: Function failed: do_compile (log file is located at /home/s32v/s32v_15.0/yocto_auto_linux_bsp15.0/build_s32v234evb_release/tmp/work/x86_64-linux/qemu-native/2.2.0-r1/temp/log.do_compile.17854)\nERROR: Logfile of failure stored in: /home/s32v/s32v_15.0/yocto_auto_linux_bsp15.0/build_s32v234evb_release/tmp/work/x86_64-linux/qemu-native/2.2.0-r1/temp/log.do_compile.17854\nLog data follows:\n| DEBUG: Executing shell function do_compile\n| NOTE: make -j 4\n|   LINK  tests/qemu-iotests/socket_scm_helper\n|   GEN   qemu-doc.html\n|   GEN   qemu.1\n|   CC    qga/commands.o\n| cc1: warning: /media/2T_HDD_for_SDK/Amingo/S32V/yocto_auto_linux_bsp15.0/build_s32v234evb_release/tmp/sysroots/x86_64-linux/usr/include/pixman-1: No such file or directory [enabled by default]\n| cc1: warning: /media/2T_HDD_for_SDK/Amingo/S32V/yocto_auto_linux_bsp15.0/build_s32v234evb_release/tmp/sysroots/x86_64-linux/usr/include/glib-2.0: No such file or directory [enabled by default]\n| cc1: warning: /media/2T_HDD_for_SDK/Amingo/S32V/yocto_auto_linux_bsp15.0/build_s32v234evb_release/tmp/sysroots/x86_64-linux/usr/lib/glib-2.0/include: No such file or directory [enabled by default]\n| /home/s32v/s32v_15.0/yocto_auto_linux_bsp15.0/build_s32v234evb_release/tmp/work/x86_64-linux/qemu-native/2.2.0-r1/qemu-2.2.0/qga/commands.c:13:18: fatal error: glib.h: No such file or directory\n|  #include <glib.h>\n|                   ^\n| compilation terminated.\n| make: *** [qga/commands.o] Error 1\n| make: *** Waiting for unfinished jobs....\n| ERROR: oe_runmake failed\n| WARNING: exit code 1 from a shell command.\n| ERROR: Function failed: do_compile (log file is located at /home/s32v/s32v_15.0/yocto_auto_linux_bsp15.0/build_s32v234evb_release/tmp/work/x86_64-linux/qemu-native/2.2.0-r1/temp/log.do_compile.17854)\nERROR: Task 2849 (virtual:native:/home/s32v/s32v_15.0/yocto_auto_linux_bsp15.0/poky/meta/recipes-devtools/qemu/qemu_2.2.0.bb, do_compile) failed with exit code '1'\nNOTE: Tasks Summary: Attempted 1504 tasks of which 1502 didn't need to be rerun and 2 failed.\nWaiting for 0 running tasks to finish:\n\nSummary: 2 tasks failed:\n  /home/s32v/s32v_15.0/yocto_auto_linux_bsp15.0/meta-fsl-s32v/recipes-kernel/linux/linux-s32v2xx_4.1.26.bb, do_compile\n  virtual:native:/home/s32v/s32v_15.0/yocto_auto_linux_bsp15.0/poky/meta/recipes-devtools/qemu/qemu_2.2.0.bb, do_compile\nSummary: There were 3 WARNING messages shown.\nSummary: There were 2 ERROR messages shown, returning a non-zero exit code.\nMy question is:\nIs it possible to copy the Yocot Project to another PC by tar file?\nWhat configuration / initial files I need to edit except saved_tmpdir file?\nWhich file does Yocto Project define the \"kernel-source\" directory?\nBest Regards,\nWayne Kuo", "Due to the Internet connect is poor on customer side, I copied the tar file of my Yocto Project to customer.However, customer met an issue while untar the Yocto Project and run the bitbake command to build project on their PC.Customer got the following build code error: s32v@s32v-vm:~/s32v_15.0/yocto_auto_linux_bsp15.0/build_s32v234evb_release$ bitbake fsl-image-s32v2xx\nERROR:  OE-core's config sanity checker detected a potential misconfiguration.\n  Either fix the cause of this error or at your own risk disable the checker (see sanity.conf).\n  Following is the list of potential problems / advisories:\n\n  Error, TMPDIR has changed location. You need to either move it back to /media/2T_HDD_for_SDK/Amingo/S32V/yocto_auto_linux_bsp15.0/build_s32v234evb_release/tmp or rebuild\n\nSummary: There was 1 ERROR message shown, returning a non-zero exit code.\nI edited /build_s32v234evb_release/tmp/saved_tmpdir file to re-position the tmp directory, this error has pass.However, I got another error while building Kernel, it seems the directory parameter is still wrong... (There is no error while building U-Boot only.)s32v@s32v-vm:~/s32v_15.0/yocto_auto_linux_bsp15.0/build_s32v234evb_release$ bitbake fsl-image-s32v2xx\nLoading cache: 100% |########################################################################################################################################################################| ETA:  00:00:00\nLoaded 2462 entries from dependency cache.\nNOTE: Resolving any missing task queue dependencies\n\nBuild Configuration:\nBB_VERSION        = \"1.26.0\"\nBUILD_SYS         = \"x86_64-linux\"\nNATIVELSBSTRING   = \"Ubuntu-14.04\"\nTARGET_SYS        = \"aarch64-fsl-linux\"\nMACHINE           = \"s32v234evb\"\nDISTRO            = \"fsl-networking\"\nDISTRO_VERSION    = \"1.8\"\nTUNE_FEATURES     = \"aarch64\"\nTARGET_FPU        = \"\"\nmeta              \nmeta-yocto        \nmeta-yocto-bsp    = \"(nobranch):03b0fbcf6b3b5cd16ae16738fbaabd1c6bf98536\"\nmeta-fsl-arm      = \"(nobranch):c9f259a4bf8472dfa3ff75f1c3fcbe5e0ded7aaf\"\nmeta-fsl-networking = \"(nobranch):b8ff02a8d508464a16c84e1d13c155f45aa98cbe\"\nmeta-fsl-toolchain = \"(nobranch):0a235c4bcd4057608ee60b8c898eec9509632b95\"\nmeta-virtualization = \"(nobranch):0277cbcb47db4239d0a4aa3b37c5c6a705070951\"\nmeta-fsl-s32v     = \"<unknown>:<unknown>\"\nmeta-oe           \nmeta-networking   \nmeta-python       \nmeta-webserver    \nmeta-filesystems  = \"(nobranch):c841231b9f327d2d06d19d2ba1324dd86b83617c\"\nmeta-linaro       \nmeta-aarch64      \nmeta-linaro-toolchain = \"(nobranch):5075a82bd510d19617803fb16da2375605225cbb\"\n\nNOTE: Preparing RunQueue\nWARNING: /home/s32v/s32v_15.0/yocto_auto_linux_bsp15.0/meta-fsl-s32v/recipes-kernel/linux/linux-s32v2xx_4.1.26.bb.do_compile is tainted from a forced run\nWARNING: /home/s32v/s32v_15.0/yocto_auto_linux_bsp15.0/meta-fsl-s32v/recipes-bsp/u-boot/u-boot-s32v2xx_2016.01.bb.do_compile is tainted from a forced run\nWARNING: /home/s32v/s32v_15.0/yocto_auto_linux_bsp15.0/meta-fsl-s32v/recipes-bsp/u-boot/u-boot-s32v2xx_2016.01.bb.do_deploy is tainted from a forced run\nNOTE: Executing SetScene Tasks\nNOTE: Executing RunQueue Tasks\nERROR: Function failed: do_compile (log file is located at /home/s32v/s32v_15.0/yocto_auto_linux_bsp15.0/build_s32v234evb_release/tmp/work/s32v234evb-fsl-linux/linux-s32v2xx/4.1.26-r0/temp/log.do_compile.17853)\nERROR: Logfile of failure stored in: /home/s32v/s32v_15.0/yocto_auto_linux_bsp15.0/build_s32v234evb_release/tmp/work/s32v234evb-fsl-linux/linux-s32v2xx/4.1.26-r0/temp/log.do_compile.17853\nLog data follows:\n| DEBUG: Executing shell function do_compile\n| NOTE: make -j 4 Image CC=aarch64-fsl-linux-gcc    --sysroot=/home/s32v/s32v_15.0/yocto_auto_linux_bsp15.0/build_s32v234evb_release/tmp/sysroots/s32v234evb LD=aarch64-fsl-linux-ld.bfd    --sysroot=/home/s32v/s32v_15.0/yocto_auto_linux_bsp15.0/build_s32v234evb_release/tmp/sysroots/s32v234evb\n| make: *** /media/2T_HDD_for_SDK/Amingo/S32V/yocto_auto_linux_bsp15.0/build_s32v234evb_release/tmp/work-shared/s32v234evb/kernel-source: No such file or directory.  Stop.\n| make: *** [__sub-make] Error 2\n| ERROR: oe_runmake failed\n| WARNING: exit code 1 from a shell command.\n| ERROR: Function failed: do_compile (log file is located at /home/s32v/s32v_15.0/yocto_auto_linux_bsp15.0/build_s32v234evb_release/tmp/work/s32v234evb-fsl-linux/linux-s32v2xx/4.1.26-r0/temp/log.do_compile.17853)\nERROR: Task 76 (/home/s32v/s32v_15.0/yocto_auto_linux_bsp15.0/meta-fsl-s32v/recipes-kernel/linux/linux-s32v2xx_4.1.26.bb, do_compile) failed with exit code '1'\nERROR: Function failed: do_compile (log file is located at /home/s32v/s32v_15.0/yocto_auto_linux_bsp15.0/build_s32v234evb_release/tmp/work/x86_64-linux/qemu-native/2.2.0-r1/temp/log.do_compile.17854)\nERROR: Logfile of failure stored in: /home/s32v/s32v_15.0/yocto_auto_linux_bsp15.0/build_s32v234evb_release/tmp/work/x86_64-linux/qemu-native/2.2.0-r1/temp/log.do_compile.17854\nLog data follows:\n| DEBUG: Executing shell function do_compile\n| NOTE: make -j 4\n|   LINK  tests/qemu-iotests/socket_scm_helper\n|   GEN   qemu-doc.html\n|   GEN   qemu.1\n|   CC    qga/commands.o\n| cc1: warning: /media/2T_HDD_for_SDK/Amingo/S32V/yocto_auto_linux_bsp15.0/build_s32v234evb_release/tmp/sysroots/x86_64-linux/usr/include/pixman-1: No such file or directory [enabled by default]\n| cc1: warning: /media/2T_HDD_for_SDK/Amingo/S32V/yocto_auto_linux_bsp15.0/build_s32v234evb_release/tmp/sysroots/x86_64-linux/usr/include/glib-2.0: No such file or directory [enabled by default]\n| cc1: warning: /media/2T_HDD_for_SDK/Amingo/S32V/yocto_auto_linux_bsp15.0/build_s32v234evb_release/tmp/sysroots/x86_64-linux/usr/lib/glib-2.0/include: No such file or directory [enabled by default]\n| /home/s32v/s32v_15.0/yocto_auto_linux_bsp15.0/build_s32v234evb_release/tmp/work/x86_64-linux/qemu-native/2.2.0-r1/qemu-2.2.0/qga/commands.c:13:18: fatal error: glib.h: No such file or directory\n|  #include <glib.h>\n|                   ^\n| compilation terminated.\n| make: *** [qga/commands.o] Error 1\n| make: *** Waiting for unfinished jobs....\n| ERROR: oe_runmake failed\n| WARNING: exit code 1 from a shell command.\n| ERROR: Function failed: do_compile (log file is located at /home/s32v/s32v_15.0/yocto_auto_linux_bsp15.0/build_s32v234evb_release/tmp/work/x86_64-linux/qemu-native/2.2.0-r1/temp/log.do_compile.17854)\nERROR: Task 2849 (virtual:native:/home/s32v/s32v_15.0/yocto_auto_linux_bsp15.0/poky/meta/recipes-devtools/qemu/qemu_2.2.0.bb, do_compile) failed with exit code '1'\nNOTE: Tasks Summary: Attempted 1504 tasks of which 1502 didn't need to be rerun and 2 failed.\nWaiting for 0 running tasks to finish:\n\nSummary: 2 tasks failed:\n  /home/s32v/s32v_15.0/yocto_auto_linux_bsp15.0/meta-fsl-s32v/recipes-kernel/linux/linux-s32v2xx_4.1.26.bb, do_compile\n  virtual:native:/home/s32v/s32v_15.0/yocto_auto_linux_bsp15.0/poky/meta/recipes-devtools/qemu/qemu_2.2.0.bb, do_compile\nSummary: There were 3 WARNING messages shown.\nSummary: There were 2 ERROR messages shown, returning a non-zero exit code.\nMy question is:\nIs it possible to copy the Yocot Project to another PC by tar file?\nWhat configuration / initial files I need to edit except saved_tmpdir file?\nWhich file does Yocto Project define the \"kernel-source\" directory?\nBest Regards,\nWayne Kuo", "I have a tar file called test.tgz , inside it are the following files:tool.foo\natest.you\nbtest.you\nctest.you\nt.you\nI want to rename the files inside test.tgz to be: 0.foo\n0.you\n1.you\n2.you\n3.you\nWithout the use of extracting the files and repacking them. How could I accomplish this?", "I have a tar file called test.tgz , inside it are the following files:tool.foo\natest.you\nbtest.you\nctest.you\nt.you\nI want to rename the files inside test.tgz to be: 0.foo\n0.you\n1.you\n2.you\n3.you\nWithout the use of extracting the files and repacking them. How could I accomplish this?", "I'm trying to download a dataset from here for my machine learning project\nthe data file appears to be tar but not extracting properly.tar -xvf SNAKE_ALL.tar\ntar: This does not look like a tar archive\ntar: Exiting with failure status due to previous errors\ntriedgzip -dc SNAKE_ALL.tar | tar -xf -\ngzip: SNAKE_ALL.tar: not in gzip format\ntar: This does not look like a tar archive\ntar: Exiting with failure status due to previous errors\nandfile SNAKE_ALL.tar\nSNAKE_ALL.tar: HTML document, ASCII text\nlink to data:https://data.mendeley.com/datasets/v88xfw5wyx/1", "I'm trying to download a dataset from here for my machine learning project\nthe data file appears to be tar but not extracting properly.tar -xvf SNAKE_ALL.tar\ntar: This does not look like a tar archive\ntar: Exiting with failure status due to previous errors\ntriedgzip -dc SNAKE_ALL.tar | tar -xf -\ngzip: SNAKE_ALL.tar: not in gzip format\ntar: This does not look like a tar archive\ntar: Exiting with failure status due to previous errors\nandfile SNAKE_ALL.tar\nSNAKE_ALL.tar: HTML document, ASCII text\nlink to data:https://data.mendeley.com/datasets/v88xfw5wyx/1", "Is there a simple shell command/script that supports excluding certain files/folders from being archived?I have a directory that need to be archived with a sub directory that has a number of very large files I do not need to backup.Not quite solutions:The tar --exclude=PATTERN command matches the given pattern and excludes those files, but I need specific files & folders to be ignored (full file path), otherwise valid files might be excluded.I could also use the find command to create a list of files and exclude the ones I don't want to archive and pass the list to tar, but that only works with for a small amount of files. I have tens of thousands.I'm beginning to think the only solution is to create a file with a list of files/folders to be excluded, then use rsync with --exclude-from=file to copy all the files to a tmp directory, and then use tar to archive that directory.Can anybody think of a better/more efficient solution?EDIT: Charles Ma's solution works well. The big gotcha is that the --exclude='./folder' MUST be at the beginning of the tar command. Full command (cd first, so backup is relative to that directory):cd /folder_to_backup\ntar --exclude='./folder' --exclude='./upload/folder2' -zcvf /backup/filename.tgz .\n", "Is there a simple shell command/script that supports excluding certain files/folders from being archived?I have a directory that need to be archived with a sub directory that has a number of very large files I do not need to backup.Not quite solutions:The tar --exclude=PATTERN command matches the given pattern and excludes those files, but I need specific files & folders to be ignored (full file path), otherwise valid files might be excluded.I could also use the find command to create a list of files and exclude the ones I don't want to archive and pass the list to tar, but that only works with for a small amount of files. I have tens of thousands.I'm beginning to think the only solution is to create a file with a list of files/folders to be excluded, then use rsync with --exclude-from=file to copy all the files to a tmp directory, and then use tar to archive that directory.Can anybody think of a better/more efficient solution?EDIT: Charles Ma's solution works well. The big gotcha is that the --exclude='./folder' MUST be at the beginning of the tar command. Full command (cd first, so backup is relative to that directory):cd /folder_to_backup\ntar --exclude='./folder' --exclude='./upload/folder2' -zcvf /backup/filename.tgz .\n", "Is there a simple shell command/script that supports excluding certain files/folders from being archived?I have a directory that need to be archived with a sub directory that has a number of very large files I do not need to backup.Not quite solutions:The tar --exclude=PATTERN command matches the given pattern and excludes those files, but I need specific files & folders to be ignored (full file path), otherwise valid files might be excluded.I could also use the find command to create a list of files and exclude the ones I don't want to archive and pass the list to tar, but that only works with for a small amount of files. I have tens of thousands.I'm beginning to think the only solution is to create a file with a list of files/folders to be excluded, then use rsync with --exclude-from=file to copy all the files to a tmp directory, and then use tar to archive that directory.Can anybody think of a better/more efficient solution?EDIT: Charles Ma's solution works well. The big gotcha is that the --exclude='./folder' MUST be at the beginning of the tar command. Full command (cd first, so backup is relative to that directory):cd /folder_to_backup\ntar --exclude='./folder' --exclude='./upload/folder2' -zcvf /backup/filename.tgz .\n", "Is there a simple shell command/script that supports excluding certain files/folders from being archived?I have a directory that need to be archived with a sub directory that has a number of very large files I do not need to backup.Not quite solutions:The tar --exclude=PATTERN command matches the given pattern and excludes those files, but I need specific files & folders to be ignored (full file path), otherwise valid files might be excluded.I could also use the find command to create a list of files and exclude the ones I don't want to archive and pass the list to tar, but that only works with for a small amount of files. I have tens of thousands.I'm beginning to think the only solution is to create a file with a list of files/folders to be excluded, then use rsync with --exclude-from=file to copy all the files to a tmp directory, and then use tar to archive that directory.Can anybody think of a better/more efficient solution?EDIT: Charles Ma's solution works well. The big gotcha is that the --exclude='./folder' MUST be at the beginning of the tar command. Full command (cd first, so backup is relative to that directory):cd /folder_to_backup\ntar --exclude='./folder' --exclude='./upload/folder2' -zcvf /backup/filename.tgz .\n", "Is there a simple shell command/script that supports excluding certain files/folders from being archived?I have a directory that need to be archived with a sub directory that has a number of very large files I do not need to backup.Not quite solutions:The tar --exclude=PATTERN command matches the given pattern and excludes those files, but I need specific files & folders to be ignored (full file path), otherwise valid files might be excluded.I could also use the find command to create a list of files and exclude the ones I don't want to archive and pass the list to tar, but that only works with for a small amount of files. I have tens of thousands.I'm beginning to think the only solution is to create a file with a list of files/folders to be excluded, then use rsync with --exclude-from=file to copy all the files to a tmp directory, and then use tar to archive that directory.Can anybody think of a better/more efficient solution?EDIT: Charles Ma's solution works well. The big gotcha is that the --exclude='./folder' MUST be at the beginning of the tar command. Full command (cd first, so backup is relative to that directory):cd /folder_to_backup\ntar --exclude='./folder' --exclude='./upload/folder2' -zcvf /backup/filename.tgz .\n", "Is there a simple shell command/script that supports excluding certain files/folders from being archived?I have a directory that need to be archived with a sub directory that has a number of very large files I do not need to backup.Not quite solutions:The tar --exclude=PATTERN command matches the given pattern and excludes those files, but I need specific files & folders to be ignored (full file path), otherwise valid files might be excluded.I could also use the find command to create a list of files and exclude the ones I don't want to archive and pass the list to tar, but that only works with for a small amount of files. I have tens of thousands.I'm beginning to think the only solution is to create a file with a list of files/folders to be excluded, then use rsync with --exclude-from=file to copy all the files to a tmp directory, and then use tar to archive that directory.Can anybody think of a better/more efficient solution?EDIT: Charles Ma's solution works well. The big gotcha is that the --exclude='./folder' MUST be at the beginning of the tar command. Full command (cd first, so backup is relative to that directory):cd /folder_to_backup\ntar --exclude='./folder' --exclude='./upload/folder2' -zcvf /backup/filename.tgz .\n", "Is there a simple shell command/script that supports excluding certain files/folders from being archived?I have a directory that need to be archived with a sub directory that has a number of very large files I do not need to backup.Not quite solutions:The tar --exclude=PATTERN command matches the given pattern and excludes those files, but I need specific files & folders to be ignored (full file path), otherwise valid files might be excluded.I could also use the find command to create a list of files and exclude the ones I don't want to archive and pass the list to tar, but that only works with for a small amount of files. I have tens of thousands.I'm beginning to think the only solution is to create a file with a list of files/folders to be excluded, then use rsync with --exclude-from=file to copy all the files to a tmp directory, and then use tar to archive that directory.Can anybody think of a better/more efficient solution?EDIT: Charles Ma's solution works well. The big gotcha is that the --exclude='./folder' MUST be at the beginning of the tar command. Full command (cd first, so backup is relative to that directory):cd /folder_to_backup\ntar --exclude='./folder' --exclude='./upload/folder2' -zcvf /backup/filename.tgz .\n", "Is there a simple shell command/script that supports excluding certain files/folders from being archived?I have a directory that need to be archived with a sub directory that has a number of very large files I do not need to backup.Not quite solutions:The tar --exclude=PATTERN command matches the given pattern and excludes those files, but I need specific files & folders to be ignored (full file path), otherwise valid files might be excluded.I could also use the find command to create a list of files and exclude the ones I don't want to archive and pass the list to tar, but that only works with for a small amount of files. I have tens of thousands.I'm beginning to think the only solution is to create a file with a list of files/folders to be excluded, then use rsync with --exclude-from=file to copy all the files to a tmp directory, and then use tar to archive that directory.Can anybody think of a better/more efficient solution?EDIT: Charles Ma's solution works well. The big gotcha is that the --exclude='./folder' MUST be at the beginning of the tar command. Full command (cd first, so backup is relative to that directory):cd /folder_to_backup\ntar --exclude='./folder' --exclude='./upload/folder2' -zcvf /backup/filename.tgz .\n", "Is there a simple shell command/script that supports excluding certain files/folders from being archived?I have a directory that need to be archived with a sub directory that has a number of very large files I do not need to backup.Not quite solutions:The tar --exclude=PATTERN command matches the given pattern and excludes those files, but I need specific files & folders to be ignored (full file path), otherwise valid files might be excluded.I could also use the find command to create a list of files and exclude the ones I don't want to archive and pass the list to tar, but that only works with for a small amount of files. I have tens of thousands.I'm beginning to think the only solution is to create a file with a list of files/folders to be excluded, then use rsync with --exclude-from=file to copy all the files to a tmp directory, and then use tar to archive that directory.Can anybody think of a better/more efficient solution?EDIT: Charles Ma's solution works well. The big gotcha is that the --exclude='./folder' MUST be at the beginning of the tar command. Full command (cd first, so backup is relative to that directory):cd /folder_to_backup\ntar --exclude='./folder' --exclude='./upload/folder2' -zcvf /backup/filename.tgz .\n", "Is there a simple shell command/script that supports excluding certain files/folders from being archived?I have a directory that need to be archived with a sub directory that has a number of very large files I do not need to backup.Not quite solutions:The tar --exclude=PATTERN command matches the given pattern and excludes those files, but I need specific files & folders to be ignored (full file path), otherwise valid files might be excluded.I could also use the find command to create a list of files and exclude the ones I don't want to archive and pass the list to tar, but that only works with for a small amount of files. I have tens of thousands.I'm beginning to think the only solution is to create a file with a list of files/folders to be excluded, then use rsync with --exclude-from=file to copy all the files to a tmp directory, and then use tar to archive that directory.Can anybody think of a better/more efficient solution?EDIT: Charles Ma's solution works well. The big gotcha is that the --exclude='./folder' MUST be at the beginning of the tar command. Full command (cd first, so backup is relative to that directory):cd /folder_to_backup\ntar --exclude='./folder' --exclude='./upload/folder2' -zcvf /backup/filename.tgz .\n", "Is there a simple shell command/script that supports excluding certain files/folders from being archived?I have a directory that need to be archived with a sub directory that has a number of very large files I do not need to backup.Not quite solutions:The tar --exclude=PATTERN command matches the given pattern and excludes those files, but I need specific files & folders to be ignored (full file path), otherwise valid files might be excluded.I could also use the find command to create a list of files and exclude the ones I don't want to archive and pass the list to tar, but that only works with for a small amount of files. I have tens of thousands.I'm beginning to think the only solution is to create a file with a list of files/folders to be excluded, then use rsync with --exclude-from=file to copy all the files to a tmp directory, and then use tar to archive that directory.Can anybody think of a better/more efficient solution?EDIT: Charles Ma's solution works well. The big gotcha is that the --exclude='./folder' MUST be at the beginning of the tar command. Full command (cd first, so backup is relative to that directory):cd /folder_to_backup\ntar --exclude='./folder' --exclude='./upload/folder2' -zcvf /backup/filename.tgz .\n", "Is there a simple shell command/script that supports excluding certain files/folders from being archived?I have a directory that need to be archived with a sub directory that has a number of very large files I do not need to backup.Not quite solutions:The tar --exclude=PATTERN command matches the given pattern and excludes those files, but I need specific files & folders to be ignored (full file path), otherwise valid files might be excluded.I could also use the find command to create a list of files and exclude the ones I don't want to archive and pass the list to tar, but that only works with for a small amount of files. I have tens of thousands.I'm beginning to think the only solution is to create a file with a list of files/folders to be excluded, then use rsync with --exclude-from=file to copy all the files to a tmp directory, and then use tar to archive that directory.Can anybody think of a better/more efficient solution?EDIT: Charles Ma's solution works well. The big gotcha is that the --exclude='./folder' MUST be at the beginning of the tar command. Full command (cd first, so backup is relative to that directory):cd /folder_to_backup\ntar --exclude='./folder' --exclude='./upload/folder2' -zcvf /backup/filename.tgz .\n", "Is there a simple shell command/script that supports excluding certain files/folders from being archived?I have a directory that need to be archived with a sub directory that has a number of very large files I do not need to backup.Not quite solutions:The tar --exclude=PATTERN command matches the given pattern and excludes those files, but I need specific files & folders to be ignored (full file path), otherwise valid files might be excluded.I could also use the find command to create a list of files and exclude the ones I don't want to archive and pass the list to tar, but that only works with for a small amount of files. I have tens of thousands.I'm beginning to think the only solution is to create a file with a list of files/folders to be excluded, then use rsync with --exclude-from=file to copy all the files to a tmp directory, and then use tar to archive that directory.Can anybody think of a better/more efficient solution?EDIT: Charles Ma's solution works well. The big gotcha is that the --exclude='./folder' MUST be at the beginning of the tar command. Full command (cd first, so backup is relative to that directory):cd /folder_to_backup\ntar --exclude='./folder' --exclude='./upload/folder2' -zcvf /backup/filename.tgz .\n", "Is there a simple shell command/script that supports excluding certain files/folders from being archived?I have a directory that need to be archived with a sub directory that has a number of very large files I do not need to backup.Not quite solutions:The tar --exclude=PATTERN command matches the given pattern and excludes those files, but I need specific files & folders to be ignored (full file path), otherwise valid files might be excluded.I could also use the find command to create a list of files and exclude the ones I don't want to archive and pass the list to tar, but that only works with for a small amount of files. I have tens of thousands.I'm beginning to think the only solution is to create a file with a list of files/folders to be excluded, then use rsync with --exclude-from=file to copy all the files to a tmp directory, and then use tar to archive that directory.Can anybody think of a better/more efficient solution?EDIT: Charles Ma's solution works well. The big gotcha is that the --exclude='./folder' MUST be at the beginning of the tar command. Full command (cd first, so backup is relative to that directory):cd /folder_to_backup\ntar --exclude='./folder' --exclude='./upload/folder2' -zcvf /backup/filename.tgz .\n", "Is there a simple shell command/script that supports excluding certain files/folders from being archived?I have a directory that need to be archived with a sub directory that has a number of very large files I do not need to backup.Not quite solutions:The tar --exclude=PATTERN command matches the given pattern and excludes those files, but I need specific files & folders to be ignored (full file path), otherwise valid files might be excluded.I could also use the find command to create a list of files and exclude the ones I don't want to archive and pass the list to tar, but that only works with for a small amount of files. I have tens of thousands.I'm beginning to think the only solution is to create a file with a list of files/folders to be excluded, then use rsync with --exclude-from=file to copy all the files to a tmp directory, and then use tar to archive that directory.Can anybody think of a better/more efficient solution?EDIT: Charles Ma's solution works well. The big gotcha is that the --exclude='./folder' MUST be at the beginning of the tar command. Full command (cd first, so backup is relative to that directory):cd /folder_to_backup\ntar --exclude='./folder' --exclude='./upload/folder2' -zcvf /backup/filename.tgz .\n", "Is there a simple shell command/script that supports excluding certain files/folders from being archived?I have a directory that need to be archived with a sub directory that has a number of very large files I do not need to backup.Not quite solutions:The tar --exclude=PATTERN command matches the given pattern and excludes those files, but I need specific files & folders to be ignored (full file path), otherwise valid files might be excluded.I could also use the find command to create a list of files and exclude the ones I don't want to archive and pass the list to tar, but that only works with for a small amount of files. I have tens of thousands.I'm beginning to think the only solution is to create a file with a list of files/folders to be excluded, then use rsync with --exclude-from=file to copy all the files to a tmp directory, and then use tar to archive that directory.Can anybody think of a better/more efficient solution?EDIT: Charles Ma's solution works well. The big gotcha is that the --exclude='./folder' MUST be at the beginning of the tar command. Full command (cd first, so backup is relative to that directory):cd /folder_to_backup\ntar --exclude='./folder' --exclude='./upload/folder2' -zcvf /backup/filename.tgz .\n", "Is there a simple shell command/script that supports excluding certain files/folders from being archived?I have a directory that need to be archived with a sub directory that has a number of very large files I do not need to backup.Not quite solutions:The tar --exclude=PATTERN command matches the given pattern and excludes those files, but I need specific files & folders to be ignored (full file path), otherwise valid files might be excluded.I could also use the find command to create a list of files and exclude the ones I don't want to archive and pass the list to tar, but that only works with for a small amount of files. I have tens of thousands.I'm beginning to think the only solution is to create a file with a list of files/folders to be excluded, then use rsync with --exclude-from=file to copy all the files to a tmp directory, and then use tar to archive that directory.Can anybody think of a better/more efficient solution?EDIT: Charles Ma's solution works well. The big gotcha is that the --exclude='./folder' MUST be at the beginning of the tar command. Full command (cd first, so backup is relative to that directory):cd /folder_to_backup\ntar --exclude='./folder' --exclude='./upload/folder2' -zcvf /backup/filename.tgz .\n", "Is there a simple shell command/script that supports excluding certain files/folders from being archived?I have a directory that need to be archived with a sub directory that has a number of very large files I do not need to backup.Not quite solutions:The tar --exclude=PATTERN command matches the given pattern and excludes those files, but I need specific files & folders to be ignored (full file path), otherwise valid files might be excluded.I could also use the find command to create a list of files and exclude the ones I don't want to archive and pass the list to tar, but that only works with for a small amount of files. I have tens of thousands.I'm beginning to think the only solution is to create a file with a list of files/folders to be excluded, then use rsync with --exclude-from=file to copy all the files to a tmp directory, and then use tar to archive that directory.Can anybody think of a better/more efficient solution?EDIT: Charles Ma's solution works well. The big gotcha is that the --exclude='./folder' MUST be at the beginning of the tar command. Full command (cd first, so backup is relative to that directory):cd /folder_to_backup\ntar --exclude='./folder' --exclude='./upload/folder2' -zcvf /backup/filename.tgz .\n", "Is there a simple shell command/script that supports excluding certain files/folders from being archived?I have a directory that need to be archived with a sub directory that has a number of very large files I do not need to backup.Not quite solutions:The tar --exclude=PATTERN command matches the given pattern and excludes those files, but I need specific files & folders to be ignored (full file path), otherwise valid files might be excluded.I could also use the find command to create a list of files and exclude the ones I don't want to archive and pass the list to tar, but that only works with for a small amount of files. I have tens of thousands.I'm beginning to think the only solution is to create a file with a list of files/folders to be excluded, then use rsync with --exclude-from=file to copy all the files to a tmp directory, and then use tar to archive that directory.Can anybody think of a better/more efficient solution?EDIT: Charles Ma's solution works well. The big gotcha is that the --exclude='./folder' MUST be at the beginning of the tar command. Full command (cd first, so backup is relative to that directory):cd /folder_to_backup\ntar --exclude='./folder' --exclude='./upload/folder2' -zcvf /backup/filename.tgz .\n", "Is there a simple shell command/script that supports excluding certain files/folders from being archived?I have a directory that need to be archived with a sub directory that has a number of very large files I do not need to backup.Not quite solutions:The tar --exclude=PATTERN command matches the given pattern and excludes those files, but I need specific files & folders to be ignored (full file path), otherwise valid files might be excluded.I could also use the find command to create a list of files and exclude the ones I don't want to archive and pass the list to tar, but that only works with for a small amount of files. I have tens of thousands.I'm beginning to think the only solution is to create a file with a list of files/folders to be excluded, then use rsync with --exclude-from=file to copy all the files to a tmp directory, and then use tar to archive that directory.Can anybody think of a better/more efficient solution?EDIT: Charles Ma's solution works well. The big gotcha is that the --exclude='./folder' MUST be at the beginning of the tar command. Full command (cd first, so backup is relative to that directory):cd /folder_to_backup\ntar --exclude='./folder' --exclude='./upload/folder2' -zcvf /backup/filename.tgz .\n", "Is there a simple shell command/script that supports excluding certain files/folders from being archived?I have a directory that need to be archived with a sub directory that has a number of very large files I do not need to backup.Not quite solutions:The tar --exclude=PATTERN command matches the given pattern and excludes those files, but I need specific files & folders to be ignored (full file path), otherwise valid files might be excluded.I could also use the find command to create a list of files and exclude the ones I don't want to archive and pass the list to tar, but that only works with for a small amount of files. I have tens of thousands.I'm beginning to think the only solution is to create a file with a list of files/folders to be excluded, then use rsync with --exclude-from=file to copy all the files to a tmp directory, and then use tar to archive that directory.Can anybody think of a better/more efficient solution?EDIT: Charles Ma's solution works well. The big gotcha is that the --exclude='./folder' MUST be at the beginning of the tar command. Full command (cd first, so backup is relative to that directory):cd /folder_to_backup\ntar --exclude='./folder' --exclude='./upload/folder2' -zcvf /backup/filename.tgz .\n", "Is there a simple shell command/script that supports excluding certain files/folders from being archived?I have a directory that need to be archived with a sub directory that has a number of very large files I do not need to backup.Not quite solutions:The tar --exclude=PATTERN command matches the given pattern and excludes those files, but I need specific files & folders to be ignored (full file path), otherwise valid files might be excluded.I could also use the find command to create a list of files and exclude the ones I don't want to archive and pass the list to tar, but that only works with for a small amount of files. I have tens of thousands.I'm beginning to think the only solution is to create a file with a list of files/folders to be excluded, then use rsync with --exclude-from=file to copy all the files to a tmp directory, and then use tar to archive that directory.Can anybody think of a better/more efficient solution?EDIT: Charles Ma's solution works well. The big gotcha is that the --exclude='./folder' MUST be at the beginning of the tar command. Full command (cd first, so backup is relative to that directory):cd /folder_to_backup\ntar --exclude='./folder' --exclude='./upload/folder2' -zcvf /backup/filename.tgz .\n", "Is there a simple shell command/script that supports excluding certain files/folders from being archived?I have a directory that need to be archived with a sub directory that has a number of very large files I do not need to backup.Not quite solutions:The tar --exclude=PATTERN command matches the given pattern and excludes those files, but I need specific files & folders to be ignored (full file path), otherwise valid files might be excluded.I could also use the find command to create a list of files and exclude the ones I don't want to archive and pass the list to tar, but that only works with for a small amount of files. I have tens of thousands.I'm beginning to think the only solution is to create a file with a list of files/folders to be excluded, then use rsync with --exclude-from=file to copy all the files to a tmp directory, and then use tar to archive that directory.Can anybody think of a better/more efficient solution?EDIT: Charles Ma's solution works well. The big gotcha is that the --exclude='./folder' MUST be at the beginning of the tar command. Full command (cd first, so backup is relative to that directory):cd /folder_to_backup\ntar --exclude='./folder' --exclude='./upload/folder2' -zcvf /backup/filename.tgz .\n", "Is there a simple shell command/script that supports excluding certain files/folders from being archived?I have a directory that need to be archived with a sub directory that has a number of very large files I do not need to backup.Not quite solutions:The tar --exclude=PATTERN command matches the given pattern and excludes those files, but I need specific files & folders to be ignored (full file path), otherwise valid files might be excluded.I could also use the find command to create a list of files and exclude the ones I don't want to archive and pass the list to tar, but that only works with for a small amount of files. I have tens of thousands.I'm beginning to think the only solution is to create a file with a list of files/folders to be excluded, then use rsync with --exclude-from=file to copy all the files to a tmp directory, and then use tar to archive that directory.Can anybody think of a better/more efficient solution?EDIT: Charles Ma's solution works well. The big gotcha is that the --exclude='./folder' MUST be at the beginning of the tar command. Full command (cd first, so backup is relative to that directory):cd /folder_to_backup\ntar --exclude='./folder' --exclude='./upload/folder2' -zcvf /backup/filename.tgz .\n", "Is there a simple shell command/script that supports excluding certain files/folders from being archived?I have a directory that need to be archived with a sub directory that has a number of very large files I do not need to backup.Not quite solutions:The tar --exclude=PATTERN command matches the given pattern and excludes those files, but I need specific files & folders to be ignored (full file path), otherwise valid files might be excluded.I could also use the find command to create a list of files and exclude the ones I don't want to archive and pass the list to tar, but that only works with for a small amount of files. I have tens of thousands.I'm beginning to think the only solution is to create a file with a list of files/folders to be excluded, then use rsync with --exclude-from=file to copy all the files to a tmp directory, and then use tar to archive that directory.Can anybody think of a better/more efficient solution?EDIT: Charles Ma's solution works well. The big gotcha is that the --exclude='./folder' MUST be at the beginning of the tar command. Full command (cd first, so backup is relative to that directory):cd /folder_to_backup\ntar --exclude='./folder' --exclude='./upload/folder2' -zcvf /backup/filename.tgz .\n", "Is there a simple shell command/script that supports excluding certain files/folders from being archived?I have a directory that need to be archived with a sub directory that has a number of very large files I do not need to backup.Not quite solutions:The tar --exclude=PATTERN command matches the given pattern and excludes those files, but I need specific files & folders to be ignored (full file path), otherwise valid files might be excluded.I could also use the find command to create a list of files and exclude the ones I don't want to archive and pass the list to tar, but that only works with for a small amount of files. I have tens of thousands.I'm beginning to think the only solution is to create a file with a list of files/folders to be excluded, then use rsync with --exclude-from=file to copy all the files to a tmp directory, and then use tar to archive that directory.Can anybody think of a better/more efficient solution?EDIT: Charles Ma's solution works well. The big gotcha is that the --exclude='./folder' MUST be at the beginning of the tar command. Full command (cd first, so backup is relative to that directory):cd /folder_to_backup\ntar --exclude='./folder' --exclude='./upload/folder2' -zcvf /backup/filename.tgz .\n", "Is there a simple shell command/script that supports excluding certain files/folders from being archived?I have a directory that need to be archived with a sub directory that has a number of very large files I do not need to backup.Not quite solutions:The tar --exclude=PATTERN command matches the given pattern and excludes those files, but I need specific files & folders to be ignored (full file path), otherwise valid files might be excluded.I could also use the find command to create a list of files and exclude the ones I don't want to archive and pass the list to tar, but that only works with for a small amount of files. I have tens of thousands.I'm beginning to think the only solution is to create a file with a list of files/folders to be excluded, then use rsync with --exclude-from=file to copy all the files to a tmp directory, and then use tar to archive that directory.Can anybody think of a better/more efficient solution?EDIT: Charles Ma's solution works well. The big gotcha is that the --exclude='./folder' MUST be at the beginning of the tar command. Full command (cd first, so backup is relative to that directory):cd /folder_to_backup\ntar --exclude='./folder' --exclude='./upload/folder2' -zcvf /backup/filename.tgz .\n", "Is there a simple shell command/script that supports excluding certain files/folders from being archived?I have a directory that need to be archived with a sub directory that has a number of very large files I do not need to backup.Not quite solutions:The tar --exclude=PATTERN command matches the given pattern and excludes those files, but I need specific files & folders to be ignored (full file path), otherwise valid files might be excluded.I could also use the find command to create a list of files and exclude the ones I don't want to archive and pass the list to tar, but that only works with for a small amount of files. I have tens of thousands.I'm beginning to think the only solution is to create a file with a list of files/folders to be excluded, then use rsync with --exclude-from=file to copy all the files to a tmp directory, and then use tar to archive that directory.Can anybody think of a better/more efficient solution?EDIT: Charles Ma's solution works well. The big gotcha is that the --exclude='./folder' MUST be at the beginning of the tar command. Full command (cd first, so backup is relative to that directory):cd /folder_to_backup\ntar --exclude='./folder' --exclude='./upload/folder2' -zcvf /backup/filename.tgz .\n", "Is there a simple shell command/script that supports excluding certain files/folders from being archived?I have a directory that need to be archived with a sub directory that has a number of very large files I do not need to backup.Not quite solutions:The tar --exclude=PATTERN command matches the given pattern and excludes those files, but I need specific files & folders to be ignored (full file path), otherwise valid files might be excluded.I could also use the find command to create a list of files and exclude the ones I don't want to archive and pass the list to tar, but that only works with for a small amount of files. I have tens of thousands.I'm beginning to think the only solution is to create a file with a list of files/folders to be excluded, then use rsync with --exclude-from=file to copy all the files to a tmp directory, and then use tar to archive that directory.Can anybody think of a better/more efficient solution?EDIT: Charles Ma's solution works well. The big gotcha is that the --exclude='./folder' MUST be at the beginning of the tar command. Full command (cd first, so backup is relative to that directory):cd /folder_to_backup\ntar --exclude='./folder' --exclude='./upload/folder2' -zcvf /backup/filename.tgz .\n", "Recently, i've been searching how to compress the git status modified files on command line linux. This git status before git add and git commit commands.$ git status\n.\n.\nmodified:   app/model/solicitud/Solicitud.js\nmodified:   app/view/basura/Grilla.js\nmodified:   app/view/excepcion/Grilla.js\nmodified:   app/view/modulo/Contenedor.js\nmodified:   app/view/modulo/Grilla.js\n.\n.\nSo, i came with this solutions, to .tar.gz and zip respectively:$ git status |grep -i \"modified:\" |cut -d':' -f2 |tee |tr -d \" \" | tar -T - -zcvf ~/myfolderdesttar/myfile.tar.gz\n$ git status |grep -i \"modified:\" |cut -d':' -f2 |tee |tr -d \" \" | zip ~/myfolderdestzip/myzipfile.zip -@\n\u00bfDo you have a shorter solution to this or a better way with git command?.\nThanks.", "I'm trying to back up a bunch of directories with tar and using find to get the files. I've seen this solution elsewhere in an old post but it duplicates every file and directory in the tarball; find itself doesn't duplicate anythingfind d1 d2 -print0 | tar -czvf backup.tar.gz --null -T -\nUsing Ubuntu 18.04 LTS, Gnu find 4.7.0 and Gnu tar 1.29I can just give the directories to tar, but curious why this behaviour is happening."], "chosen": ["\nIf it's only a matter of internet connection, I suggest you create a download folder mirror.\nOn your side, you add BB_GENERATE_MIRROR_TARBALLS and build.\nThen copy entire DL_DIR folder at customer side, and use BB_NO_NETWORK there. \nYou can look here and here for usage example.\nYou can then make a new build at customer side without internet connection. to speed up process, you can also copy your sstate-cache folder to customer side and add a sstate mirror with SSTATE_MIRRORS.\n\nNo, you will need a fresh build folder\nYou need to create a new Yocto environment at customer side\nIt's bitbake variable STAGING_KERNEL_DIR\n\n", "\nwhen you copy tar project to another PC, two files will be modified:\n\nbuild/conf/bblayers.conf\nbuild/tmp/saved_tmpdir\n\n", "\n\nError, TMPDIR has changed location. You need to either move it back to...\n\nI built all yocto stuff with the user jamie. Due to disk space running out, I copied the whole $HOME directory of jamie to another disk /dev/sdb1, which had a larger storage.\nWhen I tried to run bitbake command to make a test, I got the same error. Here is a simple solution which worked for me:\nmount  /dev/sdb1  /mnt/sdb1/\nmount  --bind  /mnt/sdb1/home_jamie/  /home/jamie/\n\nWhat I want was to restore the exact original filesystem layout which the bitbake commands were once run with.\nTo make the above changes permanent, write above mounting as entries of /etc/fstab.\n", "\nEven though you can't rename the files in the tar archive, you can rename them with a sed expression on the fly while they are being extracted. The option to tar is--transform [sed-expression]. \n", "\nYou do need to extract the files before you rename them. When files are in a tgz, they are protected from change.\n", "\nIt appears to be corrupted. Note that the file size is 0 bytes.\nfile screenshot\n", "\nYou have to use curl -JLO to download the file. With curl -O it just downloads an HTML file sometimes.\n", "\nYou can exclude directories with --exclude for tar.\nIf you want to archive everything except /usr you can use:\ntar -zcvf /all.tgz / --exclude=/usr\n\nIn your case perhaps something like\ntar -zcvf archive.tgz arc_dir --exclude=dir/ignore_this_dir\n\n", "\nYou can have multiple exclude options for tar so\n$ tar --exclude='./folder' --exclude='./upload/folder2' -zcvf /backup/filename.tgz .\n\netc will work. Make sure to put --exclude before the source and destination items. \n", "\nPossible options to exclude files/directories from backup using tar:\nExclude files using multiple patterns\ntar -czf backup.tar.gz --exclude=PATTERN1 --exclude=PATTERN2 ... /path/to/backup\n\nExclude files using an exclude file filled with a list of patterns\ntar -czf backup.tar.gz -X /path/to/exclude.txt /path/to/backup\n\nExclude files using tags by placing a tag file in any directory that should be skipped\ntar -czf backup.tar.gz --exclude-tag-all=exclude.tag /path/to/backup\n\n", "\nold question with many answers, but I found that none were quite clear enough for me, so I would like to add my try.\nif you have the following structure\n/home/ftp/mysite/\n\nwith following file/folders\n/home/ftp/mysite/file1\n/home/ftp/mysite/file2\n/home/ftp/mysite/file3\n/home/ftp/mysite/folder1\n/home/ftp/mysite/folder2\n/home/ftp/mysite/folder3\n\nso, you want to make a tar file that contain everyting inside /home/ftp/mysite (to move the site to a new server), but file3 is just junk, and everything in folder3 is also not needed, so we will skip those two.\nwe use the format\ntar -czvf <name of tar file> <what to tar> <any excludes>\n\nwhere the c = create, z = zip, and v = verbose (you can see the files as they are entered, usefull to make sure none of the files you exclude are being added). and f= file.\nso, my command would look like this\ncd /home/ftp/\ntar -czvf mysite.tar.gz mysite --exclude='file3' --exclude='folder3'\n\nnote the files/folders excluded are relatively to the root of your tar (I have tried full path here relative to / but I can not make that work). \nhope this will help someone (and me next time I google it)\n", "\nYou can use standard \"ant notation\" to exclude directories relative.\nThis works for me and excludes any .git or node_module directories:\ntar -cvf myFile.tar --exclude=**/.git/* --exclude=**/node_modules/*  -T /data/txt/myInputFile.txt 2> /data/txt/myTarLogFile.txt\n\nmyInputFile.txt contains:\n/dev2/java\n/dev2/javascript\n", "\nThis exclude pattern handles filename suffix like png or mp3 as well as directory names like .git and node_modules\ntar --exclude={*.png,*.mp3,*.wav,.git,node_modules} -Jcf ${target_tarball}  ${source_dirname}\n\n", "\nI've experienced that, at least with the Cygwin version of tar I'm using (\"CYGWIN_NT-5.1 1.7.17(0.262/5/3) 2012-10-19 14:39 i686 Cygwin\" on a Windows XP Home Edition SP3 machine), the order of options is important.\nWhile this construction worked for me:\ntar cfvz target.tgz --exclude='<dir1>' --exclude='<dir2>' target_dir\n\nthat one didn't work:\ntar cfvz --exclude='<dir1>' --exclude='<dir2>' target.tgz target_dir\n\nThis, while tar --help reveals the following:\ntar [OPTION...] [FILE]\n\nSo, the second command should also work, but apparently it doesn't seem to be the case...\nBest rgds,\n", "\nAfter reading all this good answers for different versions and having solved the problem for myself, I think there are very small details that are very important, and rare to GNU/Linux general use, that aren't stressed enough and deserves more than comments.\nSo I'm not going to try to answer the question for every case, but instead, try to register where to look when things doesn't work.\nIT IS VERY IMPORTANT TO NOTICE:\n\nTHE ORDER OF THE OPTIONS MATTER: it is not the same put the --exclude before than after the file option and directories to backup. This is unexpected at least to me, because in my experience, in GNU/Linux commands, usually the order of the options doesn't matter.\nDifferent tar versions expects this options in different order: for instance, @Andrew's answer indicates that in GNU tar v 1.26 and 1.28 the excludes comes last, whereas in my case, with GNU tar 1.29, it's the other way.\nTHE TRAILING SLASHES MATTER: at least in GNU tar 1.29, it shouldn't be any.\n\nIn my case, for GNU tar 1.29 on Debian stretch, the command that worked was\ntar --exclude=\"/home/user/.config/chromium\" --exclude=\"/home/user/.cache\" -cf file.tar  /dir1/ /home/ /dir3/\n\nThe quotes didn't matter, it worked with or without them.\nI hope this will be useful to someone.\n", "\nI'd like to show another option I used to get the same result as the answers before provide, I had a similar case where I wanted to backup android studio projects all together in a tar file to upload to media fire, using the du command to find the large files, I found that I didn't need some directories like:\nbuild, linux e .dart_tools\nUsing the first answer of Charles_ma I modified it a little bit to be able to run the command from the parent directory of the my Android directory.\ntar --exclude='*/build' --exclude='*/linux' --exclude='*/.dart_tool' -zcvf androidProjects.tar Android/\n\nIt worked like a charm.\nPs. Sorry if this kind of answer is not allowed, if this is the case I will remove.\n", "\nIf you are trying to exclude Version Control System (VCS) files, tar already supports two interesting options about it! :)\n\nOption : --exclude-vcs\n\nThis option excludes files and directories used by following version control systems: CVS, RCS, SCCS, SVN, Arch, Bazaar, Mercurial, and Darcs.\nAs of version 1.32, the following files are excluded:\n\nCVS/, and everything under it\nRCS/, and everything under it\nSCCS/, and everything under it\n.git/, and everything under it\n.gitignore\n.gitmodules\n.gitattributes\n.cvsignore\n.svn/, and everything under it\n.arch-ids/, and everything under it\n{arch}/, and everything under it\n=RELEASE-ID\n=meta-update\n=update\n.bzr\n.bzrignore\n.bzrtags\n.hg\n.hgignore\n.hgrags\n_darcs \n\nOption : --exclude-vcs-ignores\n\n\nWhen archiving directories that are under some version control system (VCS), it is often convenient to read exclusion patterns from this VCS' ignore files (e.g. .cvsignore, .gitignore, etc.) This option provide such possibility.\nBefore archiving a directory, see if it contains any of the following files: cvsignore, .gitignore, .bzrignore, or .hgignore. If so, read ignore patterns from these files.\nThe patterns are treated much as the corresponding VCS would treat them, i.e.:\n.cvsignore\nContains shell-style globbing patterns that apply only to the directory where this file resides. No comments are allowed in the file. Empty lines are ignored.\n.gitignore\nContains shell-style globbing patterns. Applies to the directory where .gitfile is located and all its subdirectories.\nAny line beginning with a # is a comment. Backslash escapes the comment character.\n.bzrignore\nContains shell globbing-patterns and regular expressions (if prefixed with RE:(16). Patterns affect the directory and all its subdirectories.\nAny line beginning with a # is a comment.\n.hgignore\nContains posix regular expressions(17). The line syntax: glob switches to shell globbing patterns. The line syntax: regexp switches back. Comments begin with a #. Patterns affect the directory and all its subdirectories. \n\nExample\n\ntar -czv --exclude-vcs --exclude-vcs-ignores -f path/to/my-tar-file.tar.gz path/to/my/project/\n", "\nI found this somewhere else so I won't take credit, but it worked better than any of the solutions above for my mac specific issues (even though this is closed):\ntar zc --exclude __MACOSX --exclude .DS_Store -f <archive> <source(s)>\n\n", "\nFor Mac OSX I had to do \ntar -zcv --exclude='folder' -f theOutputTarFile.tar folderToTar \nNote the -f after the --exclude=\n", "\nFor those who have issues with it, some versions of tar would only work properly without the './' in the exclude value.\nTar --version\n\n\ntar (GNU tar) 1.27.1\n\nCommand syntax that work:\ntar -czvf ../allfiles-butsome.tar.gz * --exclude=acme/foo\n\nThese will not work:\n$ tar -czvf ../allfiles-butsome.tar.gz * --exclude=./acme/foo\n$ tar -czvf ../allfiles-butsome.tar.gz * --exclude='./acme/foo'\n$ tar --exclude=./acme/foo -czvf ../allfiles-butsome.tar.gz *\n$ tar --exclude='./acme/foo' -czvf ../allfiles-butsome.tar.gz *\n$ tar -czvf ../allfiles-butsome.tar.gz * --exclude=/full/path/acme/foo\n$ tar -czvf ../allfiles-butsome.tar.gz * --exclude='/full/path/acme/foo'\n$ tar --exclude=/full/path/acme/foo -czvf ../allfiles-butsome.tar.gz *\n$ tar --exclude='/full/path/acme/foo' -czvf ../allfiles-butsome.tar.gz *\n\n", "\nI agree the --exclude flag is the right approach.\n$ tar --exclude='./folder_or_file' --exclude='file_pattern' --exclude='fileA'\n\nA word of warning for a side effect that I did not find immediately obvious:\nThe exclusion of 'fileA' in this example will search for 'fileA' RECURSIVELY!\nExample:A directory with a single subdirectory containing a file of the same name (data.txt)\ndata.txt\nconfig.txt\n--+dirA\n  |  data.txt\n  |  config.docx\n\n\nIf using --exclude='data.txt' the archive will not contain EITHER data.txt file. This can cause unexpected results if archiving third party libraries, such as a node_modules directory.\nTo avoid this issue make sure to give the entire path, like --exclude='./dirA/data.txt' \n\n", "\nAfter reading this thread, I did a little testing on RHEL 5 and here are my results for tarring up the abc directory:\nThis will exclude the directories error and logs and all files under the directories:\ntar cvpzf abc.tgz abc/ --exclude='abc/error' --exclude='abc/logs'\n\nAdding a wildcard after the excluded directory will exclude the files but preserve the directories:\ntar cvpzf abc.tgz abc/ --exclude='abc/error/*' --exclude='abc/logs/*'\n\n", "\nTo avoid possible 'xargs: Argument list too long' errors due to the use of find ... | xargs ... when processing tens of thousands of files, you can pipe the output of find directly to tar using find ... -print0 | tar --null ....\n# archive a given directory, but exclude various files & directories \n# specified by their full file paths\nfind \"$(pwd -P)\" -type d \\( -path '/path/to/dir1' -or -path '/path/to/dir2' \\) -prune \\\n   -or -not \\( -path '/path/to/file1' -or -path '/path/to/file2' \\) -print0 | \n   gnutar --null --no-recursion -czf archive.tar.gz --files-from -\n   #bsdtar --null -n -czf archive.tar.gz -T -\n\n", "\nYou can use cpio(1) to create tar files. cpio takes the files to archive on stdin, so if you've already figured out the find command you want to use to select the files the archive, pipe it into cpio to create the tar file:\nfind ... | cpio -o -H ustar | gzip -c > archive.tar.gz\n\n", "\nYou can also use one of the \"--exclude-tag\" options depending on your needs:\n\n--exclude-tag=FILE\n--exclude-tag-all=FILE\n--exclude-tag-under=FILE\n\nThe folder hosting the specified FILE will be excluded.\n", "\nUse the find command in conjunction with the tar append (-r) option.   This way you can add files to an existing tar in a single step, instead of a two pass solution (create list of files, create tar).\nfind /dir/dir -prune ... -o etc etc.... -exec tar rvf ~/tarfile.tar {} \\;\n\n", "\ngnu tar v 1.26 the --exclude needs to come after archive file and backup directory arguments, should have no leading or trailing slashes, and prefers no quotes (single or double).  So relative to the PARENT directory to be backed up, it's:\ntar cvfz /path_to/mytar.tgz ./dir_to_backup --exclude=some_path/to_exclude\n", "\ntar -cvzf destination_folder source_folder -X /home/folder/excludes.txt\n\n-X indicates a file which contains a list of filenames which must be excluded from the backup. For Instance, you can specify *~ in this file to not include any filenames ending with ~ in the backup.\n", "\nSuccess Case:\n1) if giving full path to take backup, in exclude also should be used full path.\ntar -zcvf /opt/ABC/BKP_27032020/backup_27032020.tar.gz --exclude='/opt/ABC/csv/' --exclude='/opt/ABC/log/' /opt/ABC\n2) if giving current path to take backup, in exclude also should be used current path only.\ntar -zcvf backup_27032020.tar.gz --exclude='ABC/csv/' --exclude='ABC/log/' ABC\nFailure Case:\n\nif giving currentpath directory to take backup and full path to ignore,then wont work\ntar -zcvf /opt/ABC/BKP_27032020/backup_27032020.tar.gz --exclude='/opt/ABC/csv/' --exclude='/opt/ABC/log/' ABC\n\nNote: mentioning exclude before/after backup directory is fine. \n", "\nIt seems to be impossible to exclude directories with absolute paths.\nAs soon as ANY of the paths are absolute (source or/and exclude) the exclude command will not work. That's my experience after trying all possible combinations.\n", "\nCheck it out\ntar cvpzf zip_folder.tgz . --exclude=./public --exclude=./tmp --exclude=./log --exclude=fileName\n\n", "\nI want to have fresh front-end version (angular folder) on localhost.\nAlso, git folder is huge in my case, and I want to exclude it.\nI need to download it from server, and unpack it in order to run application.\nCompress angular folder from /var/lib/tomcat7/webapps, move it to /tmp folder with name angular.23.12.19.tar.gz\nCommand : \ntar --exclude='.git' -zcvf /tmp/angular.23.12.19.tar.gz /var/lib/tomcat7/webapps/angular/\n\n", "\nYour best bet is to use find with tar, via xargs (to handle the large number of arguments).  For example:\nfind / -print0 | xargs -0 tar cjf tarfile.tar.bz2\n\n", "\nPossible redundant answer but since I found it useful, here it is:\nWhile a FreeBSD root (i.e. using csh) I wanted to copy my whole root filesystem to /mnt but without /usr and (obviously) /mnt. This is what worked (I am at /):\ntar --exclude ./usr --exclude ./mnt --create --file - . (cd /mnt && tar xvd -)\n\nMy whole point is that it was necessary (by putting the ./) to specify to tar that the excluded directories where part of the greater directory being copied.\nMy \u20ac0.02  \n", "\nI had no luck getting tar to exclude a 5 Gigabyte subdirectory a few levels deep. In the end, I just used the unix Zip command. It worked a lot easier for me.\nSo for this particular example from the original post\n(tar --exclude='./folder' --exclude='./upload/folder2' -zcvf /backup/filename.tgz .  )\nThe equivalent would be:\n\nzip -r /backup/filename.zip . -x upload/folder/**\\* upload/folder2/**\\*\n\n(NOTE: Here is the post I originally used that helped me https://superuser.com/questions/312301/unix-zip-directory-but-excluded-specific-subdirectories-and-everything-within-t) \n", "\nI've never made tar --exclude option work for me. In my case using rsync to copy folder tree to new location and then using standard tar worked.\nrsync -av --exclude='node_modules' --exclude='.git' folder_tree folder_tree_excluded\ntar -cvzf archive.tar.gz folder_tree_excluded\n\n", "\nto tar modified files:\ngit status | grep modified | awk '{print $3}' | xargs tar cvf modified.tar\n\nto tar new files:\ngit status | grep new | awk '{print $3}' | xargs tar cvf new.tar\n\n", "\nIs your find d1 d2 -print0 including the \".\" directory in its output from each d1 and d2, meaning it doubles the files? Try adding --no-recursion to the tar.\n"], "rejected": ["\nYou just need to edit the file ./build/tmp/saved_tmpdir so that it points to the new location\n", "\nYou just need to edit the file ./build/tmp/saved_tmpdir so that it points to the new location\n", "\nYou just need to edit the file ./build/tmp/saved_tmpdir so that it points to the new location\n", "\nYou can pipe your tar file through tools like tarcust or tardy to edit the names of their members. Those operate on raw tar data, so you'll need to pipe them through gunzip/gzip too. For example, something like:\n< original.tar.gz gunzip | tarcust OPTIONS GO HERE | gzip > new.tar.gz\n\n", "\nYou can pipe your tar file through tools like tarcust or tardy to edit the names of their members. Those operate on raw tar data, so you'll need to pipe them through gunzip/gzip too. For example, something like:\n< original.tar.gz gunzip | tarcust OPTIONS GO HERE | gzip > new.tar.gz\n\n", "\nIt's not a tar file. The download fails and the \".tar\" file you get is really a html fail saying:\n\"\n\n403 Forbidden\n\nForbidden\nYou don't have permission to access /public/snake_toxins/SNAKE_ALL.tar\non this server.\n\nApache/2.2.15 (Linux/SUSE) mod_ssl/2.2.15 OpenSSL/1.0.0 PHP/5.3.3 Server at www.cbs.dtu.dk Port 80\n\"\nNext time you get something like this run the commman:\nfile SNAKE_ALL.tar to see what kind of file it really is.\n", "\nIt's not a tar file. The download fails and the \".tar\" file you get is really a html fail saying:\n\"\n\n403 Forbidden\n\nForbidden\nYou don't have permission to access /public/snake_toxins/SNAKE_ALL.tar\non this server.\n\nApache/2.2.15 (Linux/SUSE) mod_ssl/2.2.15 OpenSSL/1.0.0 PHP/5.3.3 Server at www.cbs.dtu.dk Port 80\n\"\nNext time you get something like this run the commman:\nfile SNAKE_ALL.tar to see what kind of file it really is.\n", "\nPossibly also use cat/xargs/echo to emulate the --exclude-from=file option as rsync:\neval tar -cvzf tarball.tgz  $(cat exclude.lst | xargs -i echo -n \"--exclude='{}' \") *\n\neval and single quotes around {} are used for special names (containing spaces, for example).  If your folders do not have special chars in the name, you can skip the eval and the single quotes.\n", "\nPossibly also use cat/xargs/echo to emulate the --exclude-from=file option as rsync:\neval tar -cvzf tarball.tgz  $(cat exclude.lst | xargs -i echo -n \"--exclude='{}' \") *\n\neval and single quotes around {} are used for special names (containing spaces, for example).  If your folders do not have special chars in the name, you can skip the eval and the single quotes.\n", "\nPossibly also use cat/xargs/echo to emulate the --exclude-from=file option as rsync:\neval tar -cvzf tarball.tgz  $(cat exclude.lst | xargs -i echo -n \"--exclude='{}' \") *\n\neval and single quotes around {} are used for special names (containing spaces, for example).  If your folders do not have special chars in the name, you can skip the eval and the single quotes.\n", "\nPossibly also use cat/xargs/echo to emulate the --exclude-from=file option as rsync:\neval tar -cvzf tarball.tgz  $(cat exclude.lst | xargs -i echo -n \"--exclude='{}' \") *\n\neval and single quotes around {} are used for special names (containing spaces, for example).  If your folders do not have special chars in the name, you can skip the eval and the single quotes.\n", "\nPossibly also use cat/xargs/echo to emulate the --exclude-from=file option as rsync:\neval tar -cvzf tarball.tgz  $(cat exclude.lst | xargs -i echo -n \"--exclude='{}' \") *\n\neval and single quotes around {} are used for special names (containing spaces, for example).  If your folders do not have special chars in the name, you can skip the eval and the single quotes.\n", "\nPossibly also use cat/xargs/echo to emulate the --exclude-from=file option as rsync:\neval tar -cvzf tarball.tgz  $(cat exclude.lst | xargs -i echo -n \"--exclude='{}' \") *\n\neval and single quotes around {} are used for special names (containing spaces, for example).  If your folders do not have special chars in the name, you can skip the eval and the single quotes.\n", "\nPossibly also use cat/xargs/echo to emulate the --exclude-from=file option as rsync:\neval tar -cvzf tarball.tgz  $(cat exclude.lst | xargs -i echo -n \"--exclude='{}' \") *\n\neval and single quotes around {} are used for special names (containing spaces, for example).  If your folders do not have special chars in the name, you can skip the eval and the single quotes.\n", "\nPossibly also use cat/xargs/echo to emulate the --exclude-from=file option as rsync:\neval tar -cvzf tarball.tgz  $(cat exclude.lst | xargs -i echo -n \"--exclude='{}' \") *\n\neval and single quotes around {} are used for special names (containing spaces, for example).  If your folders do not have special chars in the name, you can skip the eval and the single quotes.\n", "\nPossibly also use cat/xargs/echo to emulate the --exclude-from=file option as rsync:\neval tar -cvzf tarball.tgz  $(cat exclude.lst | xargs -i echo -n \"--exclude='{}' \") *\n\neval and single quotes around {} are used for special names (containing spaces, for example).  If your folders do not have special chars in the name, you can skip the eval and the single quotes.\n", "\nPossibly also use cat/xargs/echo to emulate the --exclude-from=file option as rsync:\neval tar -cvzf tarball.tgz  $(cat exclude.lst | xargs -i echo -n \"--exclude='{}' \") *\n\neval and single quotes around {} are used for special names (containing spaces, for example).  If your folders do not have special chars in the name, you can skip the eval and the single quotes.\n", "\nPossibly also use cat/xargs/echo to emulate the --exclude-from=file option as rsync:\neval tar -cvzf tarball.tgz  $(cat exclude.lst | xargs -i echo -n \"--exclude='{}' \") *\n\neval and single quotes around {} are used for special names (containing spaces, for example).  If your folders do not have special chars in the name, you can skip the eval and the single quotes.\n", "\nPossibly also use cat/xargs/echo to emulate the --exclude-from=file option as rsync:\neval tar -cvzf tarball.tgz  $(cat exclude.lst | xargs -i echo -n \"--exclude='{}' \") *\n\neval and single quotes around {} are used for special names (containing spaces, for example).  If your folders do not have special chars in the name, you can skip the eval and the single quotes.\n", "\nPossibly also use cat/xargs/echo to emulate the --exclude-from=file option as rsync:\neval tar -cvzf tarball.tgz  $(cat exclude.lst | xargs -i echo -n \"--exclude='{}' \") *\n\neval and single quotes around {} are used for special names (containing spaces, for example).  If your folders do not have special chars in the name, you can skip the eval and the single quotes.\n", "\nPossibly also use cat/xargs/echo to emulate the --exclude-from=file option as rsync:\neval tar -cvzf tarball.tgz  $(cat exclude.lst | xargs -i echo -n \"--exclude='{}' \") *\n\neval and single quotes around {} are used for special names (containing spaces, for example).  If your folders do not have special chars in the name, you can skip the eval and the single quotes.\n", "\nPossibly also use cat/xargs/echo to emulate the --exclude-from=file option as rsync:\neval tar -cvzf tarball.tgz  $(cat exclude.lst | xargs -i echo -n \"--exclude='{}' \") *\n\neval and single quotes around {} are used for special names (containing spaces, for example).  If your folders do not have special chars in the name, you can skip the eval and the single quotes.\n", "\nPossibly also use cat/xargs/echo to emulate the --exclude-from=file option as rsync:\neval tar -cvzf tarball.tgz  $(cat exclude.lst | xargs -i echo -n \"--exclude='{}' \") *\n\neval and single quotes around {} are used for special names (containing spaces, for example).  If your folders do not have special chars in the name, you can skip the eval and the single quotes.\n", "\nPossibly also use cat/xargs/echo to emulate the --exclude-from=file option as rsync:\neval tar -cvzf tarball.tgz  $(cat exclude.lst | xargs -i echo -n \"--exclude='{}' \") *\n\neval and single quotes around {} are used for special names (containing spaces, for example).  If your folders do not have special chars in the name, you can skip the eval and the single quotes.\n", "\nPossibly also use cat/xargs/echo to emulate the --exclude-from=file option as rsync:\neval tar -cvzf tarball.tgz  $(cat exclude.lst | xargs -i echo -n \"--exclude='{}' \") *\n\neval and single quotes around {} are used for special names (containing spaces, for example).  If your folders do not have special chars in the name, you can skip the eval and the single quotes.\n", "\nPossibly also use cat/xargs/echo to emulate the --exclude-from=file option as rsync:\neval tar -cvzf tarball.tgz  $(cat exclude.lst | xargs -i echo -n \"--exclude='{}' \") *\n\neval and single quotes around {} are used for special names (containing spaces, for example).  If your folders do not have special chars in the name, you can skip the eval and the single quotes.\n", "\nPossibly also use cat/xargs/echo to emulate the --exclude-from=file option as rsync:\neval tar -cvzf tarball.tgz  $(cat exclude.lst | xargs -i echo -n \"--exclude='{}' \") *\n\neval and single quotes around {} are used for special names (containing spaces, for example).  If your folders do not have special chars in the name, you can skip the eval and the single quotes.\n", "\nPossibly also use cat/xargs/echo to emulate the --exclude-from=file option as rsync:\neval tar -cvzf tarball.tgz  $(cat exclude.lst | xargs -i echo -n \"--exclude='{}' \") *\n\neval and single quotes around {} are used for special names (containing spaces, for example).  If your folders do not have special chars in the name, you can skip the eval and the single quotes.\n", "\nPossibly also use cat/xargs/echo to emulate the --exclude-from=file option as rsync:\neval tar -cvzf tarball.tgz  $(cat exclude.lst | xargs -i echo -n \"--exclude='{}' \") *\n\neval and single quotes around {} are used for special names (containing spaces, for example).  If your folders do not have special chars in the name, you can skip the eval and the single quotes.\n", "\nPossibly also use cat/xargs/echo to emulate the --exclude-from=file option as rsync:\neval tar -cvzf tarball.tgz  $(cat exclude.lst | xargs -i echo -n \"--exclude='{}' \") *\n\neval and single quotes around {} are used for special names (containing spaces, for example).  If your folders do not have special chars in the name, you can skip the eval and the single quotes.\n", "\nPossibly also use cat/xargs/echo to emulate the --exclude-from=file option as rsync:\neval tar -cvzf tarball.tgz  $(cat exclude.lst | xargs -i echo -n \"--exclude='{}' \") *\n\neval and single quotes around {} are used for special names (containing spaces, for example).  If your folders do not have special chars in the name, you can skip the eval and the single quotes.\n", "\nPossibly also use cat/xargs/echo to emulate the --exclude-from=file option as rsync:\neval tar -cvzf tarball.tgz  $(cat exclude.lst | xargs -i echo -n \"--exclude='{}' \") *\n\neval and single quotes around {} are used for special names (containing spaces, for example).  If your folders do not have special chars in the name, you can skip the eval and the single quotes.\n", "\nPossibly also use cat/xargs/echo to emulate the --exclude-from=file option as rsync:\neval tar -cvzf tarball.tgz  $(cat exclude.lst | xargs -i echo -n \"--exclude='{}' \") *\n\neval and single quotes around {} are used for special names (containing spaces, for example).  If your folders do not have special chars in the name, you can skip the eval and the single quotes.\n", "\nPossibly also use cat/xargs/echo to emulate the --exclude-from=file option as rsync:\neval tar -cvzf tarball.tgz  $(cat exclude.lst | xargs -i echo -n \"--exclude='{}' \") *\n\neval and single quotes around {} are used for special names (containing spaces, for example).  If your folders do not have special chars in the name, you can skip the eval and the single quotes.\n", "\nPossibly also use cat/xargs/echo to emulate the --exclude-from=file option as rsync:\neval tar -cvzf tarball.tgz  $(cat exclude.lst | xargs -i echo -n \"--exclude='{}' \") *\n\neval and single quotes around {} are used for special names (containing spaces, for example).  If your folders do not have special chars in the name, you can skip the eval and the single quotes.\n", "\nPossibly also use cat/xargs/echo to emulate the --exclude-from=file option as rsync:\neval tar -cvzf tarball.tgz  $(cat exclude.lst | xargs -i echo -n \"--exclude='{}' \") *\n\neval and single quotes around {} are used for special names (containing spaces, for example).  If your folders do not have special chars in the name, you can skip the eval and the single quotes.\n", "\nTo create a tar of modified and newly added files:\nCommand 1\n(git diff --name-only --diff-filter=M && git ls-files --others --exclude-standard) | sort -u | xargs tar cvf modified.tar\ngit diff --name-only --diff-filter=M : Lists the modified files.\ngit ls-files --others --exclude-standard : Lists untracked files.\nsort -u : Sorts and removes duplicates.\nxargs tar cvf modified.tar : Creates the tarball.\nCommand 2\ngit status -s | awk '{print $2}' | xargs tar cvf modified.tar --exclude='node_modules'\n", "\nWhy use find? Just pass all directories to the tar command:\ntar -czf backup.tar.gz d1 d2\n\n"]}