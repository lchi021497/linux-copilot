{"prompt": ["I am now using the tail command as belowshow_log.sh:LOGFILE=`ls -1 -r ./myservice.log.????????.?????? | head -n 1`\ntail -v -f -s 1 -n  100 ${LOGFILE}\nto monitor the log file.The problem with it is that after each service restart, a new log file will be created, and the prior log file will be compressed. So the tail command stops working.I need to change the script so that to continue tailing with the new file", "I have tried the following, but the resulting file stays at size 0.tail -f /logs/localhost.log | gzip -c -9 -f > compressed.gz\nlocalhost.log is very active.Thank you.", "I have tried the following, but the resulting file stays at size 0.tail -f /logs/localhost.log | gzip -c -9 -f > compressed.gz\nlocalhost.log is very active.Thank you.", "this command is really very useful but where I can get the source code to see what is going on inside .thanks .", "this command is really very useful but where I can get the source code to see what is going on inside .thanks .", "this command is really very useful but where I can get the source code to see what is going on inside .thanks .", "I implemented below code but i want tailbuf[] should be in order. I want tailbuf[9] should be last line, tailbuf[8] second and so on. Please help me how i cant implement that in this code.#include<stdio.h>\n#include<stdlib.h>\nchar ** lastnumlines(FILE *fp, unsigned int num)   \n{\n  int count = num;\n  int n, i, iNo1 = 0, iNo2= 0,z = 0;\n  size_t MAXSIZE = 1024;\n  char **tailbuf=calloc(count, sizeof(char *));\n\n  for (i = 0; i < count; i++) \n  {\n    tailbuf[i] = calloc(MAXSIZE, sizeof(char));\n  }\n\n  while (getline(&tailbuf[iNo2], &MAXSIZE, fp) != EOF)\n  {\n     iNo2 = (iNo2 + 1) % count;\n     if (iNo2 == iNo1) \n     {\n        iNo1 = (iNo1 + 1) % count; \n     }\n  }\n\n i = iNo2;\n int k = 0;\n do{ \n     printf(\"%s\\n\",tailbuf[i]);\n     i = (i+1) % count;            \n   }while (i != iNo2);\n\n\n   free(tailbuf);    \n }\n\nint main()\n{\n  char *filename = \"demo1.txt\";\n  FILE *fp = fopen(filename,\"r\");\n\n  if(fp == NULL)\n  {\n     printf(\"Unable to open file!\\n\");\n     exit(1);\n  }\n\n  lastnumlines(fp,10);    \n  fclose(fp);   \n  return 0;\n}\nHow i can tailbuf in order?", "Say I have a directory with N log files inside:file1.log\nfile2.log\nfile3.log\n...\nfileN.log\nWhich linux command can I use to print the last n rows of each of those files above?I know how to print it for 1 file:less file1.log | tail -n 5\nBut I would like to do it simultaneously for all N files in the directory", "I work with some log system which creates a log file every hour, like follows:SoftwareLog.2010-08-01-08\nSoftwareLog.2010-08-01-09\nSoftwareLog.2010-08-01-10\nI'm trying to tail to follow the latest log file giving a pattern (e.g. SoftwareLog*) and I realize there's:tail -F (tail --follow=name --retry)\nbut that only follow one specific name - and these have different names by date and hour.  I tried something like:tail --follow=name --retry SoftwareLog*(.om[1])  \nbut the wildcard statement is resoved before it gets passed to tail and doesn't re-execute everytime tail retries.Any suggestions?", "I work with some log system which creates a log file every hour, like follows:SoftwareLog.2010-08-01-08\nSoftwareLog.2010-08-01-09\nSoftwareLog.2010-08-01-10\nI'm trying to tail to follow the latest log file giving a pattern (e.g. SoftwareLog*) and I realize there's:tail -F (tail --follow=name --retry)\nbut that only follow one specific name - and these have different names by date and hour.  I tried something like:tail --follow=name --retry SoftwareLog*(.om[1])  \nbut the wildcard statement is resoved before it gets passed to tail and doesn't re-execute everytime tail retries.Any suggestions?", "I work with some log system which creates a log file every hour, like follows:SoftwareLog.2010-08-01-08\nSoftwareLog.2010-08-01-09\nSoftwareLog.2010-08-01-10\nI'm trying to tail to follow the latest log file giving a pattern (e.g. SoftwareLog*) and I realize there's:tail -F (tail --follow=name --retry)\nbut that only follow one specific name - and these have different names by date and hour.  I tried something like:tail --follow=name --retry SoftwareLog*(.om[1])  \nbut the wildcard statement is resoved before it gets passed to tail and doesn't re-execute everytime tail retries.Any suggestions?", "I work with some log system which creates a log file every hour, like follows:SoftwareLog.2010-08-01-08\nSoftwareLog.2010-08-01-09\nSoftwareLog.2010-08-01-10\nI'm trying to tail to follow the latest log file giving a pattern (e.g. SoftwareLog*) and I realize there's:tail -F (tail --follow=name --retry)\nbut that only follow one specific name - and these have different names by date and hour.  I tried something like:tail --follow=name --retry SoftwareLog*(.om[1])  \nbut the wildcard statement is resoved before it gets passed to tail and doesn't re-execute everytime tail retries.Any suggestions?", "I work with some log system which creates a log file every hour, like follows:SoftwareLog.2010-08-01-08\nSoftwareLog.2010-08-01-09\nSoftwareLog.2010-08-01-10\nI'm trying to tail to follow the latest log file giving a pattern (e.g. SoftwareLog*) and I realize there's:tail -F (tail --follow=name --retry)\nbut that only follow one specific name - and these have different names by date and hour.  I tried something like:tail --follow=name --retry SoftwareLog*(.om[1])  \nbut the wildcard statement is resoved before it gets passed to tail and doesn't re-execute everytime tail retries.Any suggestions?", "Is that possible to use grep on a continuous stream?What I mean is sort of a tail -f <file> command, but with grep on the output in order to keep only the lines that interest me.I've tried tail -f <file> | grep pattern but it seems that grep can only be executed once tail finishes, that is to say never.", "Is that possible to use grep on a continuous stream?What I mean is sort of a tail -f <file> command, but with grep on the output in order to keep only the lines that interest me.I've tried tail -f <file> | grep pattern but it seems that grep can only be executed once tail finishes, that is to say never.", "Is that possible to use grep on a continuous stream?What I mean is sort of a tail -f <file> command, but with grep on the output in order to keep only the lines that interest me.I've tried tail -f <file> | grep pattern but it seems that grep can only be executed once tail finishes, that is to say never.", "Is that possible to use grep on a continuous stream?What I mean is sort of a tail -f <file> command, but with grep on the output in order to keep only the lines that interest me.I've tried tail -f <file> | grep pattern but it seems that grep can only be executed once tail finishes, that is to say never.", "Is that possible to use grep on a continuous stream?What I mean is sort of a tail -f <file> command, but with grep on the output in order to keep only the lines that interest me.I've tried tail -f <file> | grep pattern but it seems that grep can only be executed once tail finishes, that is to say never.", "Is that possible to use grep on a continuous stream?What I mean is sort of a tail -f <file> command, but with grep on the output in order to keep only the lines that interest me.I've tried tail -f <file> | grep pattern but it seems that grep can only be executed once tail finishes, that is to say never.", "Is that possible to use grep on a continuous stream?What I mean is sort of a tail -f <file> command, but with grep on the output in order to keep only the lines that interest me.I've tried tail -f <file> | grep pattern but it seems that grep can only be executed once tail finishes, that is to say never.", "Is that possible to use grep on a continuous stream?What I mean is sort of a tail -f <file> command, but with grep on the output in order to keep only the lines that interest me.I've tried tail -f <file> | grep pattern but it seems that grep can only be executed once tail finishes, that is to say never.", "Is that possible to use grep on a continuous stream?What I mean is sort of a tail -f <file> command, but with grep on the output in order to keep only the lines that interest me.I've tried tail -f <file> | grep pattern but it seems that grep can only be executed once tail finishes, that is to say never.", "Is that possible to use grep on a continuous stream?What I mean is sort of a tail -f <file> command, but with grep on the output in order to keep only the lines that interest me.I've tried tail -f <file> | grep pattern but it seems that grep can only be executed once tail finishes, that is to say never.", "Is that possible to use grep on a continuous stream?What I mean is sort of a tail -f <file> command, but with grep on the output in order to keep only the lines that interest me.I've tried tail -f <file> | grep pattern but it seems that grep can only be executed once tail finishes, that is to say never.", "Is that possible to use grep on a continuous stream?What I mean is sort of a tail -f <file> command, but with grep on the output in order to keep only the lines that interest me.I've tried tail -f <file> | grep pattern but it seems that grep can only be executed once tail finishes, that is to say never.", "I need to the following things to make sure my application server is \nTail a log file for a specific string\nRemain blocked until that string is printed\nHowever if the string is not printed for about 20 mins quit and throw and exception message like \"Server took more that 20 mins to be up\"\nIf string is printed in the log file quit the loop and proceed.\nIs there a way to include time outs in a while loop ? ", "I need to the following things to make sure my application server is \nTail a log file for a specific string\nRemain blocked until that string is printed\nHowever if the string is not printed for about 20 mins quit and throw and exception message like \"Server took more that 20 mins to be up\"\nIf string is printed in the log file quit the loop and proceed.\nIs there a way to include time outs in a while loop ? ", "I need to the following things to make sure my application server is \nTail a log file for a specific string\nRemain blocked until that string is printed\nHowever if the string is not printed for about 20 mins quit and throw and exception message like \"Server took more that 20 mins to be up\"\nIf string is printed in the log file quit the loop and proceed.\nIs there a way to include time outs in a while loop ? ", "I need to the following things to make sure my application server is \nTail a log file for a specific string\nRemain blocked until that string is printed\nHowever if the string is not printed for about 20 mins quit and throw and exception message like \"Server took more that 20 mins to be up\"\nIf string is printed in the log file quit the loop and proceed.\nIs there a way to include time outs in a while loop ? ", "I want to understand the following command in Linux:# tail -n+454 /path/to/a/file | head -n 6\nI expect that tail -n+454 /path/to/a/file prints the lines, starting at line 454 and the following 5 lines.The | sends that output tohead as an input. Then only the first 10 lines are taken.Finally, -n 6 defines that only the first 6 lines are printed to the screen.Did I translate the command correctly?Now I have the following problem: Let's assume I have a file and the following line in it:# Step #6: Configure output plugins\nI want to print the 5 lines immediately before that line (including that line).First I checked, what line number my line in question has:nl /path/to/a/file | grep output\nThe line number is 459.I want the 5 lines preceding line 459 as well as line 459 itself (that is, line 454 to 459).The command tail -n+454 /path/to/a/file | head -n 6 gives me the following output:...and this is line 380 to 384:I expected to get lines 454 to 459. What did I not understand? Is my command not correct?", "What have I tried so far...Command:find . -type f -ctime -3 | tail -n 5\nResult:./Mobilni Telefoni/01. Box Update/05. DC Unlocker Client/dc-unlocker_client-1.00.0857.exe\n./Mobilni Telefoni/01. Box Update/39. Z3X Box/01. Update/01. Samsung Box/SamsungTool_12.4.exe\n./Mobilni Telefoni/10. Nokia/1. SRPSKI  HRVATSKI  JEZICI/BB5/3xx_Series/Asha 300/06.97/rm781_06.97_ppm_d.rar\n./GPS Navigacije/01. Garmin/03. Garmin Other/garmin_kgen_15.exe\n./GPS Navigacije/01. Garmin/03. Garmin Other/test.txt\nThis output is OK, doesn't work good if I put wider time span. (notice I use -ctime and not -mtime because some uploaded files are modified few years ago)Problem is that files can be uploaded once a month, or once in a year, and I still need to get 10 latest files, regardless of time span.If it can't be done, does tail only limit output, or somehow just fetches number specified without huge performance impact on large number of files.By using command from one answer on SO, I was able to get the files but some files were missing...find . -type f -printf '%T@ %p\\n' | sort -n | tail -10 | cut -f2- -d\" \"\nResult:./Mobilni Telefoni/11. Samsung/1. FLASH FILES/1. SRPSKI HRVATSKI JEZICI/E/E2330/E2330_OXFKE2.rar\n./Mobilni Telefoni/11. Samsung/1. FLASH FILES/1. SRPSKI HRVATSKI JEZICI/E/E2330/FlashTool_E2_R6.zip\n./Mobilni Telefoni/11. Samsung/1. FLASH FILES/1. SRPSKI HRVATSKI JEZICI/E/E210/E210_XFGH2.rar\n./Mobilni Telefoni/05. iPhone/07. iFaith/iFaith-v1.4.1_windows-final.zip\n./Mobilni Telefoni/05. iPhone/09. iPhone Browser/SetupiPhoneBrowser.1.93.exe\n./Mobilni Telefoni/05. iPhone/10. iPhone_PC_Suite/iPhone_PC_Suite_Eng_v0.2.1.rar\n./Mobilni Telefoni/05. iPhone/10. iPhone_PC_Suite/iPhone_PC_Suite_Ok.rar\n./test\n./Mobilni Telefoni/11. Samsung/1. FLASH FILES/1. SRPSKI HRVATSKI JEZICI/E/E2152/E2152_XXJH4_OXFJI2.zip.filepart\n./GPS Navigacije/01. Garmin/03. Garmin Other/test.txt\nFile garmin_kgen_15.exe is missing because it was created in 2008, but it was uploaded in last 24 hours.", "What have I tried so far...Command:find . -type f -ctime -3 | tail -n 5\nResult:./Mobilni Telefoni/01. Box Update/05. DC Unlocker Client/dc-unlocker_client-1.00.0857.exe\n./Mobilni Telefoni/01. Box Update/39. Z3X Box/01. Update/01. Samsung Box/SamsungTool_12.4.exe\n./Mobilni Telefoni/10. Nokia/1. SRPSKI  HRVATSKI  JEZICI/BB5/3xx_Series/Asha 300/06.97/rm781_06.97_ppm_d.rar\n./GPS Navigacije/01. Garmin/03. Garmin Other/garmin_kgen_15.exe\n./GPS Navigacije/01. Garmin/03. Garmin Other/test.txt\nThis output is OK, doesn't work good if I put wider time span. (notice I use -ctime and not -mtime because some uploaded files are modified few years ago)Problem is that files can be uploaded once a month, or once in a year, and I still need to get 10 latest files, regardless of time span.If it can't be done, does tail only limit output, or somehow just fetches number specified without huge performance impact on large number of files.By using command from one answer on SO, I was able to get the files but some files were missing...find . -type f -printf '%T@ %p\\n' | sort -n | tail -10 | cut -f2- -d\" \"\nResult:./Mobilni Telefoni/11. Samsung/1. FLASH FILES/1. SRPSKI HRVATSKI JEZICI/E/E2330/E2330_OXFKE2.rar\n./Mobilni Telefoni/11. Samsung/1. FLASH FILES/1. SRPSKI HRVATSKI JEZICI/E/E2330/FlashTool_E2_R6.zip\n./Mobilni Telefoni/11. Samsung/1. FLASH FILES/1. SRPSKI HRVATSKI JEZICI/E/E210/E210_XFGH2.rar\n./Mobilni Telefoni/05. iPhone/07. iFaith/iFaith-v1.4.1_windows-final.zip\n./Mobilni Telefoni/05. iPhone/09. iPhone Browser/SetupiPhoneBrowser.1.93.exe\n./Mobilni Telefoni/05. iPhone/10. iPhone_PC_Suite/iPhone_PC_Suite_Eng_v0.2.1.rar\n./Mobilni Telefoni/05. iPhone/10. iPhone_PC_Suite/iPhone_PC_Suite_Ok.rar\n./test\n./Mobilni Telefoni/11. Samsung/1. FLASH FILES/1. SRPSKI HRVATSKI JEZICI/E/E2152/E2152_XXJH4_OXFJI2.zip.filepart\n./GPS Navigacije/01. Garmin/03. Garmin Other/test.txt\nFile garmin_kgen_15.exe is missing because it was created in 2008, but it was uploaded in last 24 hours.", "I am tailing a file using Putty.I have this code:tail -f /srv/ppp/ppp*.log | perl -pe 's/(TransactionID)/\\e[4;38;5;255m$&\\e[0m/g';\nThe following code makes the string \"TransactionID\" underlined and adds a color.\nMy question is how can I also make the \"TransactionID\" string blink?I couldn't find practical solutions to my issue in other similar posts...", "I want to show the 3 first lines and the 2 last lines that contain a word. \nI tried a grep command but it's not showing what I want.grep -w it /usr/include/stdio.h | head -3 | tail -2It only display the 2nd and 3nd lines that contain \"it\" in it.", "I want to show the 3 first lines and the 2 last lines that contain a word. \nI tried a grep command but it's not showing what I want.grep -w it /usr/include/stdio.h | head -3 | tail -2It only display the 2nd and 3nd lines that contain \"it\" in it.", "I want to show the 3 first lines and the 2 last lines that contain a word. \nI tried a grep command but it's not showing what I want.grep -w it /usr/include/stdio.h | head -3 | tail -2It only display the 2nd and 3nd lines that contain \"it\" in it."], "chosen": ["\nFound a way. ojblass with the capital F parameter suggestion helped.\nActually I created a link to the latest log file by the following command after each service restart:\nln -n service-blabla.log log_lnk\n\nand changed the tail command like this:\ntail -v -F -s 1 -n  100 log_lnk\n\nNote the capital F in the tail command. Lowercase f doesn't work in this situation.\ndone.\n", "\nYou're just not patient enough.  That will work, and it will write to the gzip file.  It will take a while to accumulate enough input to write the first compressed block.  Especially if the input is highly compressible, e.g. the log entries are very similar to each other.\nThis has a problem though, in that the gzip file will never be properly terminated, since gzip will never get an end-of-file.\n", "\nYou can't do this, because gzip utility doesn't read input line by line, it expects EOF.\nBut you can write your on wrapper using any programming language which has zlib implementation.\n", "\nPoke around the uclinux site. Since they distributed the software, they are required to make the source available one way or another.\nOr, you could read man fseek and guess at how it might be done. \nNB-- See William's comments below, there are cases when you can't use seek.\n", "\nThe tail utility is part of the coreutils on linux.\n\nSource tarball: ftp://ftp.gnu.org/gnu/coreutils/coreutils-7.4.tar.gz\nSource file: https://git.savannah.gnu.org/cgit/coreutils.git/tree/src/tail.c (original http link)\n\nI've always found FreeBSD to have far clearer source code than the gnu utilities. So here's tail.c in the FreeBSD project:\n\nhttp://svnweb.freebsd.org/csrg/usr.bin/tail/tail.c?view=markup\n\n", "\nYou might find it an interesting exercise to write your own. The vast majority of the Unix command-line tools are a page or so of fairly straightforward C code. \nTo just look at the code, the GNU CoreUtils sources are easily found on gnu.org or your favorite Linux mirror site. \n", "\nA simple solution should be to have two arrays of lines pointers (note that the memory won't be duplicated)\n\na circular buffer to read the file without other difficulty than using a mod op %\na linear buffer reordering the read line to be used elsewhere:\n\nvoid lastnumlines(FILE *fp, unsigned int num)   \n{\n    /* variable names have been made more expressive */\n\n    int i; \n    size_t size = 1024;\n    char **tailbuf=calloc(num, sizeof(char *));\n    char **circbuf=calloc(num, sizeof(char *));\n    \n    int index_in_buff = 0;\n    int line_no = 0;\n    \n    for (i = 0; i < num; ++i) {\n        circbuf[i] = malloc(size);\n    }\n\n    /* get lines in circular buffer */\n    while (getline(&circbuf[index_in_buff % num], &size, fp) != EOF)\n    {\n        ++index_in_buff;\n        ++line_no;\n    }\n\n    /* reorder lines from circular to linear buffer */\n    for (i = 0; i < num; ++i) {\n        printf(\"%d --> %d\\n\", (line_no+i)%num, i);\n        tailbuf[i] = circbuf[(line_no+i)%num];\n    } \n\n    /* display lines, warning, some may be null if num > line_no */\n    for (i = 0; i < num; ++i) {\n        if (tailbuf[i])\n            printf(\"%s\", tailbuf[i]);\n    }\n\n    /* cleanup memory */\n    for (i = 0; i < num; ++i) {\n        free(tailbuf[i]);\n    }\n\n    free(tailbuf);    \n    free(circbuf);    \n}\n\n\nNote that the circbuf can be deleted at the end of function, and tailbuf can be returned to be used in other functions. Both tailbuf and circbuf point to line memory, but there is no deep bind.\n", "\nUse the command \"ls *.log | sort -V | tail -n {number}\", where number is the number of output files from the end.\nFor example, \"ls *.log | sort -V | tail -n 5\" will output in a directory with ten log files only:\nfile6.log\nfile7.log\nfile8.log\nfile9.log\nfile10.log\nWithout the insert \"sort -V\" in the middle there will be not a natural sort, but a machine sort, that is, \"ls *.log | tail -n 10\" will output:\nfile10.log\nfile1.log\nfile2.log\nfile3.log\nfile4.log\nfile5.log\nfile6.log\nfile7.log\nfile8.log\nfile9.log\n", "\n[Edit: after a quick googling for a tool]\nYou might want to try out multitail - http://www.vanheusden.com/multitail/\nIf you want to stick with Dennis Williamson's answer (and I've +1'ed him accordingly) here are the blanks filled in for you.\nIn your shell, run the following script (or it's zsh equivalent, I whipped this up in bash before I saw the zsh tag):\n#!/bin/bash\n\nTARGET_DIR=\"some/logfiles/\"\nSYMLINK_FILE=\"SoftwareLog.latest\"\nSYMLINK_PATH=\"$TARGET_DIR/$SYMLINK_FILE\"\n\nfunction getLastModifiedFile {\n    echo $(ls -t \"$TARGET_DIR\" | grep -v \"$SYMLINK_FILE\" | head -1)\n}\n\nfunction getCurrentlySymlinkedFile {\n    if [[ -h $SYMLINK_PATH ]]\n    then\n        echo $(ls -l $SYMLINK_PATH | awk '{print $NF}')\n    else\n        echo \"\"\n    fi\n}\n\nsymlinkedFile=$(getCurrentlySymlinkedFile)\nwhile true\ndo\n    sleep 10\n    lastModified=$(getLastModifiedFile)\n    if [[ $symlinkedFile != $lastModified ]]\n    then\n        ln -nsf $lastModified $SYMLINK_PATH\n        symlinkedFile=$lastModified\n    fi\ndone\n\nBackground that process using the normal method (again, I don't know zsh, so it might be different)... \n./updateSymlink.sh 2>&1 > /dev/null\nThen tail -F $SYMLINK_PATH so that the tail hands the changing of the symbolic link or a rotation of the file.\nThis is slightly convoluted, but I don't know of another way to do this with tail.  If anyone else knows of a utility that handles this, then let them step forward because I'd love to see it myself too - applications like Jetty by default do logs this way and I always script up a symlinking script run on a cron to compensate for it.\n[Edit: Removed an erroneous 'j' from the end of one of the lines. You also had a bad variable name \"lastModifiedFile\" didn't exist, the proper name that you set is \"lastModified\"]\n", "\nI believe the simplest solution is as follows:\ntail -f `ls -tr | tail -n 1`\n\nNow, if your directory contains other log files like \"SystemLog\" and you only want the latest \"SoftwareLog\" file, then you would simply include a grep as follows:\ntail -f `ls -tr | grep SoftwareLog | tail -n 1`\n\n", "\nI haven't tested this, but an approach that may work would be to run a background process that creates and updates a symlink to the latest log file and then you would tail -f (or tail -F) the symlink.\n", "\n#!/bin/bash\n\nPATTERN=\"$1\"\n\n# Try to make sure sub-shells exit when we do.\ntrap \"kill -9 -- -$BASHPID\" SIGINT SIGTERM EXIT\n\nPID=0\nOLD_FILES=\"\"\nwhile true; do\n  FILES=\"$(echo $PATTERN)\"\n  if test \"$FILES\" != \"$OLD_FILES\"; then\n    if test \"$PID\" != \"0\"; then\n      kill $PID\n      PID=0\n    fi\n    if test \"$FILES\" != \"$PATTERN\" || test -f \"$PATTERN\"; then\n      tail --pid=$$ -n 0 -F $PATTERN &\n      PID=$!\n    fi\n  fi\n  OLD_FILES=\"$FILES\"\n  sleep 1\ndone\n\nThen run it as: tail.sh 'SoftwareLog*'\nThe script will lose some log lines if the logs are written to between checks. But at least it's a single script, with no symlinks required.\n", "\nWe have daily rotating log files as: /var/log/grails/customer-2020-01-03.log. To tail the latest one, the following command worked fine for me:\ntail -f /var/log/grails/customer-`date +'%Y-%m-%d'`.log\n\n(NOTE: no space after the + sign in the expression)\nSo, for you, the following should work (if you are in the same directory of the logs):\ntail -f SoftwareLog.`date +'%Y-%m-%d-%H'`\n\n", "\nI use the tail -f <file> | grep <pattern> all the time.\nIt will wait till grep flushes, not till it finishes (I'm using Ubuntu).\n", "\nTurn on grep's line buffering mode when using BSD grep (FreeBSD, Mac OS X etc.)\ntail -f file | grep --line-buffered my_pattern\n\nIt looks like a while ago --line-buffered didn't matter for GNU grep (used on pretty much any Linux) as it flushed by default (YMMV for other Unix-likes such as SmartOS, AIX or QNX). However, as of November 2020, --line-buffered is needed (at least with GNU grep 3.5 in openSUSE, but it seems generally needed based on comments below).\n", "\nI think that your problem is that grep uses some output buffering. Try \ntail -f file | stdbuf -o0 grep my_pattern\n\nit will set output buffering mode of grep to unbuffered.\n", "\nIf you want to find matches in the entire file (not just the tail), and you want it to sit and wait for any new matches, this works nicely:\ntail -c +0 -f <file> | grep --line-buffered <pattern>\n\nThe -c +0 flag says that the output should start 0 bytes (-c) from the beginning (+) of the file.\n", "\nIn most cases, you can tail -f /var/log/some.log |grep foo and it will work just fine.\nIf you need to use multiple greps on a running log file and you find that you get no output, you may need to stick the --line-buffered switch into your middle grep(s), like so:\ntail -f /var/log/some.log | grep --line-buffered foo | grep bar\n\n", "\nyou may consider this answer as enhancement .. usually I am using \ntail -F <fileName> | grep --line-buffered  <pattern> -A 3 -B 5\n\n-F is better in case of file rotate (-f will not work properly  if file rotated)\n-A and -B is useful to get lines just before and after the pattern occurrence .. these blocks will appeared between dashed line separators\nBut For me I prefer doing the following\ntail -F <file> | less\n\nthis is very useful if you want to search inside streamed logs. I mean go back and forward and look deeply\n", "\nDidn't see anyone offer my usual go-to for this:\nless +F <file>\nctrl + c\n/<search term>\n<enter>\nshift + f\n\nI prefer this, because you can use ctrl + c to stop and navigate through the file whenever, and then just hit shift + f to return to the live, streaming search.\n", "\nsed would be a better choice (stream editor)\ntail -n0 -f <file> | sed -n '/search string/p'\nand then if you wanted the tail command to exit once you found a particular string:\ntail --pid=$(($BASHPID+1)) -n0 -f <file> | sed -n '/search string/{p; q}'\nObviously a bashism: $BASHPID will be the process id of the tail command.  The sed command is next after tail in the pipe, so the sed process id will be $BASHPID+1.\n", "\nComing some late on this question, considering this kind of work as an important part of monitoring job, here is my (not so short) answer...\nFollowing logs using bash\n1. Command tail\nThis command is a little more porewfull than read on already published answer\n\nDifference between follow option tail -f and tail -F, from manpage:\n\n   -f, --follow[={name|descriptor}]\n          output appended data as the file grows;\n...\n   -F     same as --follow=name --retry\n...\n   --retry\n          keep trying to open a file if it is inaccessible\n\n\nThis mean: by using -F instead of -f, tail will re-open file(s) when removed (on log rotation, for sample).\nThis is usefull for watching logfile over many days.\n\nAbility of following more than one file simultaneously\nI've already used:\ntail -F /var/www/clients/client*/web*/log/{error,access}.log /var/log/{mail,auth}.log \\\n           /var/log/apache2/{,ssl_,other_vhosts_}access.log \\\n           /var/log/pure-ftpd/transfer.log\n\nFor following events through hundreds of files... (consider rest of this answer to understand how to make it readable... ;)\n\nUsing switches -n (Don't use -c for line buffering!).By default tail will show 10 last lines. This can be tunned:\ntail -n 0 -F file\n\nWill follow file, but only new lines will be printed\ntail -n +0 -F file\n\nWill print whole file before following his progression.\n\n\n2. Buffer issues when piping:\nIf you plan to filter ouptuts, consider buffering! See -u option for sed, --line-buffered for grep, or stdbuf command:\ntail -F /some/files | sed -une '/Regular Expression/p'\n\nIs (a lot more efficient than using grep) a lot more reactive than if you does'nt use -u switch in sed command.\ntail -F /some/files |\n    sed -une '/Regular Expression/p' |\n    stdbuf -i0 -o0 tee /some/resultfile\n\n3. Recent journaling system\nOn recent system, instead of tail -f /var/log/syslog you have to run journalctl -xf, in near same way...\njournalctl -axf | sed -une '/Regular Expression/p'\n\nBut read man page, this tool was built for log analyses!\n4. Integrating this in a bash script\n\nColored output of two files (or more)\nHere is a sample of script watching for many files, coloring ouptut differently for 1st file than others:\n#!/bin/bash\n\ntail -F \"$@\" |\n    sed -une \"\n        /^==> /{h;};\n        //!{\n            G;\n            s/^\\\\(.*\\\\)\\\\n==>.*${1//\\//\\\\\\/}.*<==/\\\\o33[47m\\\\1\\\\o33[0m/;\n            s/^\\\\(.*\\\\)\\\\n==> .* <==/\\\\o33[47;31m\\\\1\\\\o33[0m/;\n            p;}\"\n\nThey work fine on my host, running:\nsudo ./myColoredTail /var/log/{kern.,sys}log\n\n\nInteractive script\nYou may be watching logs for reacting on events?\nHere is a little script playing some sound when some USB device appear or disappear, but same script could send mail, or any other interaction, like powering on coffe machine...\n#!/bin/bash\n\nexec {tailF}< <(tail -F /var/log/kern.log)\ntailPid=$!\n\nwhile :;do\n    read -rsn 1 -t .3 keyboard\n    [ \"${keyboard,}\" = \"q\" ] && break\n    if read -ru $tailF -t 0 _ ;then\n        read -ru $tailF line\n        case $line in\n            *New\\ USB\\ device\\ found* ) play /some/sound.ogg ;;\n            *USB\\ disconnect* ) play /some/othersound.ogg ;;\n        esac\n        printf \"\\r%s\\e[K\" \"$line\"\n    fi\ndone\n\necho\nexec {tailF}<&-\nkill $tailPid\n\nYou could quit by pressing Q key.\n\n\n", "\nYes, this will actually work just fine. Grep and most Unix commands operate on streams one line at a time. Each line that comes out of tail will be analyzed and passed on if it matches.\n", "\nThis one command workes for me (Suse): \nmail-srv:/var/log # tail -f /var/log/mail.info |grep --line-buffered LOGIN  >> logins_to_mail\n\ncollecting logins to mail service\n", "\nyou certainly won't succeed with\ntail -f /var/log/foo.log |grep --line-buffered string2search\n\nwhen you use \"colortail\" as an alias for tail, eg. in bash\nalias tail='colortail -n 30'\n\nyou can check by\n    type alias\nif this outputs something like\n    tail isan alias of colortail -n 30.\nthen you have your culprit :)\nSolution:\nremove the alias with\nunalias tail\n\nensure that you're using the 'real' tail binary by this command\ntype tail\n\nwhich should output something like:\ntail is /usr/bin/tail\n\nand then you can run your command\ntail -f foo.log |grep --line-buffered something\n\nGood luck.\n", "\n#!/bin/bash\ntail -f logfile | grep 'certain_word' | read -t 1200 dummy_var\n[ $? -eq 0 ]  && echo 'ok'  || echo 'server not up'\n\nThis reads anything written to logfile, searches for certain_word, echos ok if all is good, otherwise after waiting 1200 seconds (20 minutes) it complains.\n", "\nYou can do it like this:\nstart_time=$(date +\"%s\")\nwhile true\ndo\n    elapsed_time=$(($(date +\"%s\") - $start_time))\n    if [[ \"$elapsed_time\" -gt 1200 ]]; then\n        break\n    fi\n    sleep 1\n    if [[ $(grep -c \"specific string\" /path/to/log/file.log) -ge 1 ]]; then\n        break\n    fi\ndone\n\n", "\nYou can use signal handlers from shell scripts (see http://www.ibm.com/developerworks/aix/library/au-usingtraps/index.html).\nBasically, you'd define a function to be called on, say, signal 17, then put a sub-script in the background that will send that signal at some later time:\ntimeout(pid) {\n   sleep 1200\n   kill -SIGUSR1 $pid\n}\n\nwatch_for_input() {\n   tail -f file | grep item\n}\n\ntrap 'echo \"Not found\"; exit' SIGUSR1\ntimeout($$) &\nwatch_for_input\n\nThen if you reach 1200 seconds, your function is called and you can choose what to do (like signal your tail/grep combo that is watching for your pattern in order to kill it)\n", "\ntime=0\nfound=0\nwhile [ $time -lt 1200 ]; do\n  out=$(tail logfile)\n  if [[ $out =~ specificString ]]; then\n    found=1\n    break;\n  fi  \n  let time++\n  sleep 1\ndone\necho $found\n\n", "\nThe mistake I made was that I displayed only the non-empty lines in the file, which was wrong.\nIt's better to use...\nnl -ba [FILE]\n\nto number all lines in the file. Then look up the lines of interest and use the head and tail commands (with piping) to get the final results.\nExample:\ntail -n +539 [FILE] | tail -n 6\ntail -n +539 [FILE] | head -n -212\nhead -n 544 [FILE] | tail -n 6\nhead -n 544 [FILE] | tail -n +539\n\nAll commands lead to the same result.\nAnother mistake I made was the syntax. There should be a space between -n and +NUM.\nBy the way, the line numbers in my OP are wrong, because I used the wrong numbering line command. The line I refer to is 544 not 459.\n", "\nI needed a solution to get the x latest modified files in a directory and use it afterwards in a loop to process them further:\nfind \"/mnt/user/Movie\" -iname '*.mkv' -printf \"%C@ %p\\n\" | sort -n | cut -f2- -d\" \" | tail -10 | tr '\\n' '\\0' | \n    while IFS= read -r -d '' file; do \n        echo \"$file\"\n    done\n\nreturns:\n/mnt/user/Movie/IJ/I (2014)/I (2014).mkv\n/mnt/user/Movie/AB/B (2010)/B (2010).mkv\n/mnt/user/Movie/MN/N (1993)/N (1993).mkv\n/mnt/user/Movie/MN/M (2016)/M (2016).mkv\n/mnt/user/Movie/KL/K (1984)/K (1984).mkv\n/mnt/user/Movie/MN/M (1999)/M (1999).mkv\n/mnt/user/Movie/GH/G (2014)/G (2014).mkv\n/mnt/user/Movie/MN/M (2002)/M (2002).mkv\n/mnt/user/Movie/AB/B (2017)/B (2017).mkv\n/mnt/user/Movie/CD/D (1997)/D (1997).mkv\n\nChange tail -10 to the amount of files that should be returned. Of course you could replace -iname '*.mkv' against -type f to cover all files.\n", "\nI was told that this is the solution:\nfind . -type f -printf \"%C@ %p\\n\" | sort -rn | head -n 10\n\nThe key point is the printf %C@ placeholder, which is the -ctime one. I found it by reading man find.\nResult:\n1336992789.0000000000 ./Mobilni Telefoni/05. iPhone/03. iPhone 4G Firmware/5.1.1/iPhone3,1_5.1.1_9B206_Restore.ipsw.filepart\n1336928538.0000000000 ./GPS Navigacije/01. Garmin/03. Garmin Other/test.txt\n1336922295.0000000000 ./GPS Navigacije/01. Garmin/03. Garmin Other/garmin_kgen_15.exe\n1336868365.0000000000 ./Mobilni Telefoni/11. Samsung/1. FLASH FILES/1. SRPSKI HRVATSKI JEZICI/E/E2152/E2152_XXJH4_OXFJI2.zip.filepart\n1336867426.0000000000 ./Mobilni Telefoni/11. Samsung/1. FLASH FILES/1. SRPSKI HRVATSKI JEZICI/E/E210/E210_XFGH2.rar\n1336866301.0000000000 ./Mobilni Telefoni/11. Samsung/1. FLASH FILES/1. SRPSKI HRVATSKI JEZICI/E/E2330/FlashTool_E2_R6.zip\n1336865921.0000000000 ./Mobilni Telefoni/11. Samsung/1. FLASH FILES/1. SRPSKI HRVATSKI JEZICI/E/E2330/E2330_OXFKE2.rar\n1336865409.0000000000 ./Mobilni Telefoni/11. Samsung/1. FLASH FILES/1. SRPSKI HRVATSKI JEZICI/E/E2230/E2230_XXKC1_CDS.zip\n1336865398.0000000000 ./Mobilni Telefoni/11. Samsung/1. FLASH FILES/1. SRPSKI HRVATSKI JEZICI/E/E2230/E2230_XXKC1_BIN.zip\n1336864949.0000000000 ./Mobilni Telefoni/11. Samsung/1. FLASH FILES/1. SRPSKI HRVATSKI JEZICI/E/E2230/E2230_OXFKC1_CSC.zip\n\n\nFor a very large list of files, sort(1) with pipes might not be optimal for resource usage.\nsort(1) could be replaced with perl(1) and buffer the ten highest entries, only. This has been outlined in unix command: how to get top n records for  three, here an adoption for ten records.\nIt replaces the sort(1) and head(1) filters:\nfind . -type f -printf \"%C@ %p\\n\" | perl -ane '\n    BEGIN {@top = ([-1]) x 10}\n    if ($F[0] > $top[0][0]) {\n        @top = sort {$a->[0] <=> $b->[0]} @top[1..9], [$F[0], $_];\n    }\n    END {print for reverse map {$_->[1]} @top}\n'\n\nThe result is identical.\n", "\nIn putty:\nTERMINAL -> ENABLE BLINKING TEXT\n", "\nThe issue here is that tail never receives the output of grep, but rather only the first 3 lines of the file. To make this work reliably you either need to grep twice, once with head and once with tail or multiplex the stream, e.g.:\ngrep -w it /usr/include/stdio.h |\ntee >(head -n3 > head-of-file) >(tail -n2 > tail-of-file) > /dev/null\ncat head-of-file tail-of-file\n\nOutput here:\n   The GNU C Library is free software; you can redistribute it and/or\n   modify it under the terms of the GNU Lesser General Public\n   The GNU C Library is distributed in the hope that it will be useful,\n   or due to the implementation it is a cancellation point and\n/* Try to acquire ownership of STREAM but do not block if it is not\n\n", "\nYou can simply append the results of head and tail : \n{ head -3 ; tail -2 ;} < /usr/include/stdio.h\n\n", "\nyou should try this \ngrep -A 2 -B 3 \"it\" /usr/include/stdio.h\n\n-A = After context of 2 lines to the matching word \"it\"\n-B = After context of 3 lines to the matching word \"it\"\nyou can also add -W if you really need a regex.\nexpected output:\nline 1\nline 2\nline that contains it\nline 4\nline 5\nline 6\n"], "rejected": ["\nThere are a few ways to achieve this, depending on what exactly you want to achieve.\nAnswer 1: Your posted solution (with improvements)\nWhile your posted solution would work, it would require you to actually set the symlink every time it changed, which would be annoying. Particularly since it looks like you are watching a service, so knowing when a log file will change may be difficult.\nAs a possible improvement to consider, you could put the call to create the sym link in a watch call. This would automatically move the sym link once a new file is created.\nwatch -t -n 1 'ln -s -f  $(ls -1vr service-blabla.log* | head -n 1) log_lnk' &> /dev/null &\n\nThis command will recreate the sym link every second, so you don't need to. Then you can run your tail like normal.\ntail -v -F -s 1 -n  100 log_lnk\n\nIf you're going to be doing this often (I.e. after system restarts), I doubt you are going to want to be running the watch command every time. In that case, I would suggest creating a cron job or its replacement timers to automatically check and create the link at specified intervals.\nAnswer 2: The one liner\nThe cleanest approach would be to loose the -F altogether and instead use watch to achieve the same effect.\nwatch -t -n 1 'tail -v -n 10  $(ls -1vr service-blabla.log* | head -n 1)'\n\nThis will output the last 10 lines of the last file service-blabla.log* when sorted \"naturally\". The display will be a little different than if using tail -f, but I think it's similar enough to be just about what you would want. We aren't creating a link here, so no need for a cron/timer or anything like that. Plus, it's a one-liner, so that's cool.\nAnswer 3: The simpler approach\nOf course, there is always a technically simpler, but slightly longer, solution. If I were to do this at 12 AM and didn't want to mess around with getting the watch call set up just right, I would probably just do this in a loop.\nwhile true; do ln -s -f $(ls -1vr service-blabla.log* | head -n 1) log_lnk; sleep 1; done &\ntail -v -F -s 1 -n  100 log_lnk\n\nOh yea, brute force to the rescue.\n", "\nlogrotate(8) was designed to solve this sort of problem - it rotates and compresses log files. \n", "\nlogrotate(8) was designed to solve this sort of problem - it rotates and compresses log files. \n", "\n/`*This example implements the option n of tail command.*/`\n\n    #define _FILE_OFFSET_BITS 64\n    #include <stdio.h>\n    #include <stdlib.h>\n    #include <fcntl.h>\n    #include <errno.h>\n    #include <unistd.h>\n    #include <getopt.h>\n\n    #define BUFF_SIZE 4096\n\n    FILE *openFile(const char *filePath)\n    {\n      FILE *file;\n      file= fopen(filePath, \"r\");\n      if(file == NULL)\n      {\n        fprintf(stderr,\"Error opening file: %s\\n\",filePath);\n        exit(errno);\n      }\n      return(file);\n    }\n\n    void printLine(FILE *file, off_t startline)\n    {\n      int fd;\n      fd= fileno(file);\n      int nread;\n      char buffer[BUFF_SIZE];\n      lseek(fd,(startline + 1),SEEK_SET);\n      while((nread= read(fd,buffer,BUFF_SIZE)) > 0)\n      {\n        write(STDOUT_FILENO, buffer, nread);\n      }\n    }\n\n    void walkFile(FILE *file, long nlines)\n    {\n      off_t fposition;\n      fseek(file,0,SEEK_END);\n      fposition= ftell(file);\n      off_t index= fposition;\n      off_t end= fposition;\n      long countlines= 0;\n      char cbyte;\n\n      for(index; index >= 0; index --)\n      {\n        cbyte= fgetc(file);\n        if (cbyte == '\\n' && (end - index) > 1)\n        {\n          countlines ++;\n          if(countlines == nlines)\n          {\n        break;\n          }\n         }\n        fposition--;\n        fseek(file,fposition,SEEK_SET);\n      }\n      printLine(file, fposition);\n      fclose(file);\n    }\n\n    int main(int argc, char *argv[])\n    {\n      FILE *file;\n      file= openFile(argv[2]);\n      walkFile(file, atol(argv[1]));\n      return 0;\n    }\n\n    /*Note: take in mind that i not wrote code to parse input options and arguments, neither code to check if the lines number argument is really a number.*/\n\n", "\n/`*This example implements the option n of tail command.*/`\n\n    #define _FILE_OFFSET_BITS 64\n    #include <stdio.h>\n    #include <stdlib.h>\n    #include <fcntl.h>\n    #include <errno.h>\n    #include <unistd.h>\n    #include <getopt.h>\n\n    #define BUFF_SIZE 4096\n\n    FILE *openFile(const char *filePath)\n    {\n      FILE *file;\n      file= fopen(filePath, \"r\");\n      if(file == NULL)\n      {\n        fprintf(stderr,\"Error opening file: %s\\n\",filePath);\n        exit(errno);\n      }\n      return(file);\n    }\n\n    void printLine(FILE *file, off_t startline)\n    {\n      int fd;\n      fd= fileno(file);\n      int nread;\n      char buffer[BUFF_SIZE];\n      lseek(fd,(startline + 1),SEEK_SET);\n      while((nread= read(fd,buffer,BUFF_SIZE)) > 0)\n      {\n        write(STDOUT_FILENO, buffer, nread);\n      }\n    }\n\n    void walkFile(FILE *file, long nlines)\n    {\n      off_t fposition;\n      fseek(file,0,SEEK_END);\n      fposition= ftell(file);\n      off_t index= fposition;\n      off_t end= fposition;\n      long countlines= 0;\n      char cbyte;\n\n      for(index; index >= 0; index --)\n      {\n        cbyte= fgetc(file);\n        if (cbyte == '\\n' && (end - index) > 1)\n        {\n          countlines ++;\n          if(countlines == nlines)\n          {\n        break;\n          }\n         }\n        fposition--;\n        fseek(file,fposition,SEEK_SET);\n      }\n      printLine(file, fposition);\n      fclose(file);\n    }\n\n    int main(int argc, char *argv[])\n    {\n      FILE *file;\n      file= openFile(argv[2]);\n      walkFile(file, atol(argv[1]));\n      return 0;\n    }\n\n    /*Note: take in mind that i not wrote code to parse input options and arguments, neither code to check if the lines number argument is really a number.*/\n\n", "\n/`*This example implements the option n of tail command.*/`\n\n    #define _FILE_OFFSET_BITS 64\n    #include <stdio.h>\n    #include <stdlib.h>\n    #include <fcntl.h>\n    #include <errno.h>\n    #include <unistd.h>\n    #include <getopt.h>\n\n    #define BUFF_SIZE 4096\n\n    FILE *openFile(const char *filePath)\n    {\n      FILE *file;\n      file= fopen(filePath, \"r\");\n      if(file == NULL)\n      {\n        fprintf(stderr,\"Error opening file: %s\\n\",filePath);\n        exit(errno);\n      }\n      return(file);\n    }\n\n    void printLine(FILE *file, off_t startline)\n    {\n      int fd;\n      fd= fileno(file);\n      int nread;\n      char buffer[BUFF_SIZE];\n      lseek(fd,(startline + 1),SEEK_SET);\n      while((nread= read(fd,buffer,BUFF_SIZE)) > 0)\n      {\n        write(STDOUT_FILENO, buffer, nread);\n      }\n    }\n\n    void walkFile(FILE *file, long nlines)\n    {\n      off_t fposition;\n      fseek(file,0,SEEK_END);\n      fposition= ftell(file);\n      off_t index= fposition;\n      off_t end= fposition;\n      long countlines= 0;\n      char cbyte;\n\n      for(index; index >= 0; index --)\n      {\n        cbyte= fgetc(file);\n        if (cbyte == '\\n' && (end - index) > 1)\n        {\n          countlines ++;\n          if(countlines == nlines)\n          {\n        break;\n          }\n         }\n        fposition--;\n        fseek(file,fposition,SEEK_SET);\n      }\n      printLine(file, fposition);\n      fclose(file);\n    }\n\n    int main(int argc, char *argv[])\n    {\n      FILE *file;\n      file= openFile(argv[2]);\n      walkFile(file, atol(argv[1]));\n      return 0;\n    }\n\n    /*Note: take in mind that i not wrote code to parse input options and arguments, neither code to check if the lines number argument is really a number.*/\n\n", "\nHere's a sketch of how you could do this with a single array of pointers.\nUp to 10 lines populate pArr pointers, then memmove will \"scroll-up\" the array so that the 'next' read is always to the final pointer.\nconst int n = 10; // Want last 10 lines. (fewer if short input).\nchar *pArr[ n ];\n\nfor( int i = 0; i < n; i++ )\n    pArr[ i ] = calloc( 128, sizeof(char) );\n\nint lcnt = 0, retCode = 0;\nwhile( retCode != EOF ) {\n    if( lcnt == n - 1 ) {\n        char *hold = pArr[0];\n        memmove( pArr, pArr + 1, (n - 1) * sizeof(pArr[0]) );\n        pArr[ lcnt ] = hold;\n    }\n    retCode = getline( pArr[ lcnt ], size, fp );\n    if( ++lcnt == n )\n        lcnt--;\n}\n\nfor( i = 0; i <= lcnt; i++ )\n    printf( ... );\n\nfor( i = 0; i < n; i++ )\n    free( pArr[ i ] );\n\n", "\nA for loop is not the best, since it will not support all cases.  Ex. if you have spaces in your filenames.\nTo avoid all issues, use:\nfind . -type f -name \"*.log\" -exec tail -5 {} \\; -print\n\n\n.: is the current directory.  If your log files are not in the current directory, you can replace the . by the directory containing the files.\n-name \"*.log\" can be modified to filter your files more precisely.  Ex. file*.log.\ntail -5 {} will print the last 5 lines.  Change the number as you require.\nthe -print option will print the filenames of logs found.   But you can omit it if you do not need that information in your display.\n\n", "\nI believe the easiest way is to use tail with ls and head, try something like this\ntail -f `ls -t SoftwareLog* | head -1`\n\n", "\nI believe the easiest way is to use tail with ls and head, try something like this\ntail -f `ls -t SoftwareLog* | head -1`\n\n", "\nI believe the easiest way is to use tail with ls and head, try something like this\ntail -f `ls -t SoftwareLog* | head -1`\n\n", "\nI believe the easiest way is to use tail with ls and head, try something like this\ntail -f `ls -t SoftwareLog* | head -1`\n\n", "\nI believe the easiest way is to use tail with ls and head, try something like this\ntail -f `ls -t SoftwareLog* | head -1`\n\n", "\nUse awk(another great bash utility) instead of grep where you dont have the line buffered option! It will continuously stream your data from tail.\nthis is how you use grep \ntail -f <file> | grep pattern\n\nThis is how you would use awk\ntail -f <file> | awk '/pattern/{print $0}'\n\n", "\nUse awk(another great bash utility) instead of grep where you dont have the line buffered option! It will continuously stream your data from tail.\nthis is how you use grep \ntail -f <file> | grep pattern\n\nThis is how you would use awk\ntail -f <file> | awk '/pattern/{print $0}'\n\n", "\nUse awk(another great bash utility) instead of grep where you dont have the line buffered option! It will continuously stream your data from tail.\nthis is how you use grep \ntail -f <file> | grep pattern\n\nThis is how you would use awk\ntail -f <file> | awk '/pattern/{print $0}'\n\n", "\nUse awk(another great bash utility) instead of grep where you dont have the line buffered option! It will continuously stream your data from tail.\nthis is how you use grep \ntail -f <file> | grep pattern\n\nThis is how you would use awk\ntail -f <file> | awk '/pattern/{print $0}'\n\n", "\nUse awk(another great bash utility) instead of grep where you dont have the line buffered option! It will continuously stream your data from tail.\nthis is how you use grep \ntail -f <file> | grep pattern\n\nThis is how you would use awk\ntail -f <file> | awk '/pattern/{print $0}'\n\n", "\nUse awk(another great bash utility) instead of grep where you dont have the line buffered option! It will continuously stream your data from tail.\nthis is how you use grep \ntail -f <file> | grep pattern\n\nThis is how you would use awk\ntail -f <file> | awk '/pattern/{print $0}'\n\n", "\nUse awk(another great bash utility) instead of grep where you dont have the line buffered option! It will continuously stream your data from tail.\nthis is how you use grep \ntail -f <file> | grep pattern\n\nThis is how you would use awk\ntail -f <file> | awk '/pattern/{print $0}'\n\n", "\nUse awk(another great bash utility) instead of grep where you dont have the line buffered option! It will continuously stream your data from tail.\nthis is how you use grep \ntail -f <file> | grep pattern\n\nThis is how you would use awk\ntail -f <file> | awk '/pattern/{print $0}'\n\n", "\nUse awk(another great bash utility) instead of grep where you dont have the line buffered option! It will continuously stream your data from tail.\nthis is how you use grep \ntail -f <file> | grep pattern\n\nThis is how you would use awk\ntail -f <file> | awk '/pattern/{print $0}'\n\n", "\nUse awk(another great bash utility) instead of grep where you dont have the line buffered option! It will continuously stream your data from tail.\nthis is how you use grep \ntail -f <file> | grep pattern\n\nThis is how you would use awk\ntail -f <file> | awk '/pattern/{print $0}'\n\n", "\nUse awk(another great bash utility) instead of grep where you dont have the line buffered option! It will continuously stream your data from tail.\nthis is how you use grep \ntail -f <file> | grep pattern\n\nThis is how you would use awk\ntail -f <file> | awk '/pattern/{print $0}'\n\n", "\nUse awk(another great bash utility) instead of grep where you dont have the line buffered option! It will continuously stream your data from tail.\nthis is how you use grep \ntail -f <file> | grep pattern\n\nThis is how you would use awk\ntail -f <file> | awk '/pattern/{print $0}'\n\n", "\nThe accepted answer doesn't work and will never exit (because althouth read -t exits, the prior pipe commands (tail -f | grep) will only be notified of read -t exit when they try to write to output, which never happens until the string matches).\nA one-liner is probably feasible, but here are scripted (working) approaches.\nLogic is the same for each one, they use kill to terminate the current script after the timeout.\nPerl is probably more widely available than gawk/read -t\n#!/bin/bash\n\nFILE=\"$1\"\nMATCH=\"$2\"\n\n# Uses read -t, kill after timeout\n#tail -f \"$FILE\" | grep \"$MATCH\" | (read -t 1 a ; kill $$)\n\n# Uses gawk read timeout ability (not available in awk)\n#tail -f \"$FILE\" | grep \"$MATCH\" | gawk \"BEGIN {PROCINFO[\\\"/dev/stdin\\\", \\\"READ_TIMEOUT\\\"] = 1000;getline < \\\"/dev/stdin\\\"; system(\\\"kill $$\\\")}\"\n\n# Uses perl & alarm signal\n#tail -f \"$FILE\" | grep \"$MATCH\" | perl -e \"\\$SIG{ALRM} = sub { `kill $$`;exit; };alarm(1);<>;\"\n\n", "\nThe accepted answer doesn't work and will never exit (because althouth read -t exits, the prior pipe commands (tail -f | grep) will only be notified of read -t exit when they try to write to output, which never happens until the string matches).\nA one-liner is probably feasible, but here are scripted (working) approaches.\nLogic is the same for each one, they use kill to terminate the current script after the timeout.\nPerl is probably more widely available than gawk/read -t\n#!/bin/bash\n\nFILE=\"$1\"\nMATCH=\"$2\"\n\n# Uses read -t, kill after timeout\n#tail -f \"$FILE\" | grep \"$MATCH\" | (read -t 1 a ; kill $$)\n\n# Uses gawk read timeout ability (not available in awk)\n#tail -f \"$FILE\" | grep \"$MATCH\" | gawk \"BEGIN {PROCINFO[\\\"/dev/stdin\\\", \\\"READ_TIMEOUT\\\"] = 1000;getline < \\\"/dev/stdin\\\"; system(\\\"kill $$\\\")}\"\n\n# Uses perl & alarm signal\n#tail -f \"$FILE\" | grep \"$MATCH\" | perl -e \"\\$SIG{ALRM} = sub { `kill $$`;exit; };alarm(1);<>;\"\n\n", "\nThe accepted answer doesn't work and will never exit (because althouth read -t exits, the prior pipe commands (tail -f | grep) will only be notified of read -t exit when they try to write to output, which never happens until the string matches).\nA one-liner is probably feasible, but here are scripted (working) approaches.\nLogic is the same for each one, they use kill to terminate the current script after the timeout.\nPerl is probably more widely available than gawk/read -t\n#!/bin/bash\n\nFILE=\"$1\"\nMATCH=\"$2\"\n\n# Uses read -t, kill after timeout\n#tail -f \"$FILE\" | grep \"$MATCH\" | (read -t 1 a ; kill $$)\n\n# Uses gawk read timeout ability (not available in awk)\n#tail -f \"$FILE\" | grep \"$MATCH\" | gawk \"BEGIN {PROCINFO[\\\"/dev/stdin\\\", \\\"READ_TIMEOUT\\\"] = 1000;getline < \\\"/dev/stdin\\\"; system(\\\"kill $$\\\")}\"\n\n# Uses perl & alarm signal\n#tail -f \"$FILE\" | grep \"$MATCH\" | perl -e \"\\$SIG{ALRM} = sub { `kill $$`;exit; };alarm(1);<>;\"\n\n", "\nThe accepted answer doesn't work and will never exit (because althouth read -t exits, the prior pipe commands (tail -f | grep) will only be notified of read -t exit when they try to write to output, which never happens until the string matches).\nA one-liner is probably feasible, but here are scripted (working) approaches.\nLogic is the same for each one, they use kill to terminate the current script after the timeout.\nPerl is probably more widely available than gawk/read -t\n#!/bin/bash\n\nFILE=\"$1\"\nMATCH=\"$2\"\n\n# Uses read -t, kill after timeout\n#tail -f \"$FILE\" | grep \"$MATCH\" | (read -t 1 a ; kill $$)\n\n# Uses gawk read timeout ability (not available in awk)\n#tail -f \"$FILE\" | grep \"$MATCH\" | gawk \"BEGIN {PROCINFO[\\\"/dev/stdin\\\", \\\"READ_TIMEOUT\\\"] = 1000;getline < \\\"/dev/stdin\\\"; system(\\\"kill $$\\\")}\"\n\n# Uses perl & alarm signal\n#tail -f \"$FILE\" | grep \"$MATCH\" | perl -e \"\\$SIG{ALRM} = sub { `kill $$`;exit; };alarm(1);<>;\"\n\n", "\nuse this command :\nhead -n $(grep -n \"Step #6: Configure output plugins\" /path/to/a/file | awk -F ':' '{print $1}') /path/to/a/file | tail -n 5 \n\nnote:\nthat command has two part\na) found line number:\ngrep -n \"Step #6: Configure output plugins\" /path/to/a/file | awk -F ':' '{print $1}'\n\nb) filter lines you want :\nhead -n [LINE NUMBER] /path/to/a/file | tail -n 5 \n\n", "\nEasier:\nfilename=$(ls -t . | head -10)\n\n", "\nEasier:\nfilename=$(ls -t . | head -10)\n\n", "\nIs it possible that your PuTTY configuration needs a switch to enable blinking text?  I ask because the PuTTY Configuration on a Windows system has an explicit checkbox to \"Enable Blinking text\" in its \"Terminal\" configuration settings.\n", "\ncat /usr/include/stdio.h | grep -w it | head -3 | tail -2\n\n", "\ncat /usr/include/stdio.h | grep -w it | head -3 | tail -2\n\n", "\ncat /usr/include/stdio.h | grep -w it | head -3 | tail -2\n\n"]}